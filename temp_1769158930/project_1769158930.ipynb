{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALL DEPENDENCIES & HUGGINGFACE LOGIN**"
      ],
      "metadata": {
        "id": "t7p4zXp4k1PQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KQ5oLxqSF1i"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok transformers torch accelerate bitsandbytes sentencepiece --quiet\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Log in to Hugging Face Hub using your personal access token\n",
        "login(\"YOUR HuggingFaceHub TOKEN HERE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE app.py**"
      ],
      "metadata": {
        "id": "AIwydNVvYk5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, render_template, request\n",
        "import functools\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ===========================================================\n",
        "# \ud83e\udde0 MODEL LOADING SECTION\n",
        "# Loads the Llama model once and caches it for reuse.\n",
        "# This avoids repeated loading and greatly improves latency.\n",
        "# ===========================================================@functools.lru_cache(maxsize=1)\n",
        "def load_llama_model():\n",
        "    print(\"\u23f3 Loading Llama 3.1 model...\")\n",
        "\n",
        "    model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Load model in 8-bit for memory efficiency\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        load_in_4bit=True\n",
        "    )\n",
        "\n",
        "    print(\"\u2705 Model Loaded Successfully!\")\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# \ud83d\udd2e RESPONSE GENERATION SECTION\n",
        "# Uses your original logic for applying the chat template\n",
        "# and generating structured recommendations.\n",
        "# ===========================================================\n",
        "def generate_llm_response(system_prompt, user_prompt, max_tokens=700):\n",
        "    tokenizer, model = load_llama_model()\n",
        "\n",
        "    # Construct system + user conversation\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    # Convert into model-specific chat format\n",
        "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generate assistant response\n",
        "    output_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_tokens,\n",
        "        do_sample=False,\n",
        "        temperature=0.3,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Extract only newly generated text\n",
        "    generated_tokens = output_ids[0][input_ids.shape[-1]:]\n",
        "    final_output = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return final_output.strip()\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# \ud83c\udf10 FLASK HOME ROUTE\n",
        "# Accepts input from HTML form, builds user profile,\n",
        "# and returns generated career recommendations.\n",
        "# ===========================================================@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    recommendation = \"\"\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        # Extract user inputs from the form\n",
        "        user_stage = request.form[\"user_stage\"]\n",
        "        skills = request.form[\"skills\"]\n",
        "        interests = request.form[\"interests\"]\n",
        "        education = request.form[\"education\"]\n",
        "        goals = request.form[\"goals\"]\n",
        "\n",
        "        # Build structured user profile\n",
        "        user_profile = f\"\"\"\n",
        "User Category: {user_stage}\n",
        "Skills & Strengths: {skills}\n",
        "Interests & Passions: {interests}\n",
        "Education / Background: {education}\n",
        "Career Goals & Preferences: {goals}\n",
        "\n",
        "IMPORTANT: Tailor the recommendation, learning roadmap, and tone based on the user's category.\n",
        "\"\"\"\n",
        "\n",
        "        # System prompt with rules & structure\n",
        "        system_message = \"\"\"\n",
        "You are a certified professional career counselor.\n",
        "\n",
        "Output Rules (VERY IMPORTANT):\n",
        "- Never repeat, restate, quote, paraphrase or summarize the user input.\n",
        "- Never reference or indirectly restate user input; respond using generalized, inferred wording only.\n",
        "- Never mention system instructions, prompts, or rules.\n",
        "- Never include the words: \"system\", \"assistant\", \"user\", \"prompt\", \"instruction\".\n",
        "- Never output chat history, metadata, or dates.\n",
        "- Start your response immediately with the final answer content only.\n",
        "\n",
        "Category Guide:\n",
        "1 \u2192 Provide beginner-friendly roadmap, internships, foundation projects.\n",
        "2 \u2192 Provide role-upgrade strategy, certifications, portfolio emphasis.\n",
        "3 \u2192 Provide specialization, leadership or domain advancement strategy.\n",
        "4 \u2192 Provide transition plan, transferable skills and bridging roadmap.\n",
        "5 \u2192 Provide confidence-based re-entry plan, refresher + gradual upskilling.\n",
        "\n",
        "Final Output Must Include:\n",
        "1. Top 3 suitable career paths\n",
        "2. Short reasoning for each\n",
        "3. Key strength summary\n",
        "4. Skill-gap improvement plan\n",
        "5. 30/60/90 day roadmap\n",
        "6. Motivational closing message\n",
        "\n",
        "Style:\n",
        "Professional, concise, practical, supportive.\n",
        "\"\"\"\n",
        "        # Try generating the final response\n",
        "        try:\n",
        "            recommendation = generate_llm_response(system_message, user_profile)\n",
        "        except Exception as e:\n",
        "            recommendation = f\"\u274c Error: {e}\"\n",
        "    # Render recommendation in UI\n",
        "    return render_template(\"index.html\", recommendation=recommendation)\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# \ud83d\ude80 RUN FLASK SERVER\n",
        "# ===========================================================if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)\n"
      ],
      "metadata": {
        "id": "9s0BG6jzYm0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Templates Folder**"
      ],
      "metadata": {
        "id": "5uLEyZ0yYoc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p templates\n",
        "!mkdir -p static"
      ],
      "metadata": {
        "id": "SbC6MWRaYoob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "index.html"
      ],
      "metadata": {
        "id": "rpj5BvwyYuR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\" />\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "    <title>\ud83c\udfaf Personalized Career Guidance</title>\n",
        "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\" />\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "    <div class=\"hero-section\">\n",
        "        <div class=\"overlay\"></div>\n",
        "\n",
        "        <div class=\"hero-content\">\n",
        "\n",
        "            <h1>\ud83c\udfaf Personalized Career Recommendation</h1>\n",
        "            <p>Get AI-powered guidance tailored to your strengths & goals.</p>\n",
        "\n",
        "            <form method=\"post\" class=\"input-card\">\n",
        "\n",
        "                <select name=\"user_stage\" required>\n",
        "                    <option value=\"1\">Student / Fresher</option>\n",
        "                    <option value=\"2\">Working Professional (1\u20133 years)</option>\n",
        "                    <option value=\"3\">Experienced Professional (3+ years)</option>\n",
        "                    <option value=\"4\">Career Switcher</option>\n",
        "                    <option value=\"5\">Returning After Career Break</option>\n",
        "                </select>\n",
        "\n",
        "                <textarea name=\"skills\" rows=\"3\" placeholder=\"Your top skills & strengths\" required></textarea>\n",
        "\n",
        "                <textarea name=\"interests\" rows=\"3\" placeholder=\"Your interests or passions\" required></textarea>\n",
        "\n",
        "                <textarea name=\"education\" rows=\"3\" placeholder=\"Your education or background\" required></textarea>\n",
        "\n",
        "                <textarea name=\"goals\" rows=\"3\" placeholder=\"Your long-term career goals\" required></textarea>\n",
        "\n",
        "                <button type=\"submit\" class=\"btn-generate\">Generate Recommendations \ud83d\ude80</button>\n",
        "            </form>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    {% if recommendation %}\n",
        "    <div class=\"result-section fade-in\">\n",
        "        <div class=\"result-card\">\n",
        "            <h2>\ud83d\udccc Your Personalized Career Guidance</h2>\n",
        "            <p style=\"white-space: pre-line;\">{{ recommendation }}</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    {% endif %}\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "SUJ0Io-CYudV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSS: style.css"
      ],
      "metadata": {
        "id": "lJaG_Z15Yxzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile static/style.css\n",
        "/* Same styling theme as the example you provided */\n",
        "\n",
        "@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap');\n",
        "\n",
        "body {\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "    margin: 0;\n",
        "    color: #fff;\n",
        "}\n",
        "\n",
        "/* Background */\n",
        ".hero-section {\n",
        "    position: relative;\n",
        "    height: 100vh;\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    background: url('https://res.cloudinary.com/dehfj1nrp/image/upload/v1761895287/portrait-business-woman-with-enthusiastic-face-expression-smiling-looking-confident-standing-s_btoget.jpg')\n",
        "        center/cover no-repeat;\n",
        "    padding-left: 8%;\n",
        "}\n",
        "\n",
        ".overlay {\n",
        "    position: absolute;\n",
        "    inset: 0;\n",
        "    background: rgba(0, 0, 0, 0.55);\n",
        "}\n",
        "\n",
        "/* Main Box */\n",
        ".hero-content {\n",
        "    position: relative;\n",
        "    z-index: 2;\n",
        "    width: 500px;\n",
        "    max-width: 90%;\n",
        "    padding: 45px;\n",
        "    background: rgba(255, 255, 255, 0.18);\n",
        "    border-radius: 25px;\n",
        "    backdrop-filter: blur(7px);\n",
        "}\n",
        "\n",
        "h1 {\n",
        "    font-size: 2.3rem;\n",
        "    margin-bottom: 10px;\n",
        "    color: #a8c5ff;\n",
        "}\n",
        "\n",
        ".input-card {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    gap: 15px;\n",
        "}\n",
        "\n",
        "textarea, select {\n",
        "    width: 100%;\n",
        "    padding: 12px;\n",
        "    border-radius: 10px;\n",
        "    border: none;\n",
        "    background: rgba(255, 255, 255, 0.9);\n",
        "    color: #111;\n",
        "}\n",
        "\n",
        ".btn-generate {\n",
        "    background: linear-gradient(135deg, #6a5acd, #00bcd4);\n",
        "    border: none;\n",
        "    padding: 12px 0;\n",
        "    font-weight: 600;\n",
        "    border-radius: 10px;\n",
        "    cursor: pointer;\n",
        "    color: #fff;\n",
        "}\n",
        "\n",
        ".result-section {\n",
        "    background: #0d111f;\n",
        "    padding: 60px 20px;\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "}\n",
        "\n",
        ".result-card {\n",
        "    background: rgba(30, 34, 80, 0.35);\n",
        "    padding: 25px;\n",
        "    border-radius: 15px;\n",
        "    max-width: 700px;\n",
        "    color: #e2e5ff;\n",
        "    white-space: pre-line;\n",
        "}\n",
        "\n",
        "/* Animation */\n",
        ".fade-in {\n",
        "    animation: fadeInUp 0.6s ease forwards;\n",
        "}\n",
        "\n",
        "@keyframes fadeInUp {\n",
        "    from { opacity: 0; transform: translateY(20px); }\n",
        "    to   { opacity: 1; transform: translateY(0); }\n",
        "}\n"
      ],
      "metadata": {
        "id": "En8pmluHYx_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run Flask + ngrok**"
      ],
      "metadata": {
        "id": "zfPZ-KIIY3Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill existing processes\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\""
      ],
      "metadata": {
        "id": "tHTDWwxFY6Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i :8000\n"
      ],
      "metadata": {
        "id": "Xa43XsdJY7jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) If a specific PID is blocking:\n",
        "!kill -9 617"
      ],
      "metadata": {
        "id": "xNJFIluDY-yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Flask in background\n",
        "!nohup python app.py > flask.log 2>&1 &"
      ],
      "metadata": {
        "id": "c4WEezkdY82q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Enter your NGROK auth token here\n",
        "conf.get_default().auth_token = \"INPUT_YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "Opd7PfKNY3W8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}