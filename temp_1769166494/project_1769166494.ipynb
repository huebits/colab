{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13567701,
          "sourceType": "datasetVersion",
          "datasetId": 8618727
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in kaggle"
      ],
      "metadata": {
        "id": "nFLYZEc6EWFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcd8 How to Use Kaggle (Upload Dataset & Notebook)\n",
        "\n",
        "### \u2705 Step 1: Create Kaggle Account\n",
        "- Go to \ud83d\udc49 https://www.kaggle.com  \n",
        "- Sign in using Google / Email\n",
        "\n",
        "---\n",
        "\n",
        "### \u2705 Step 2: Upload Your Dataset\n",
        "1. Click **Datasets** \u2192 **Create New Dataset**\n",
        "2. Upload your **dataset folder or ZIP file**\n",
        "3. Add:\n",
        "   - Dataset name\n",
        "   - Short description\n",
        "4. Set visibility \u2192 **Public / Private**\n",
        "5. Click **Create**\n",
        "\n",
        "\u2705 After upload, Kaggle gives a dataset path like:\n"
      ],
      "metadata": {
        "id": "kJ-GggN1EaMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \ud83e\udec1 Lung Cancer Detection using CNN + Transfer Learning + Ensemble\n",
        "\n",
        "This project compares a **custom CNN**, a **MobileNetV2 transfer learning model**, and a **final ensemble model** for lung cancer classification.\n"
      ],
      "metadata": {
        "id": "3QfNKMLWEM9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 1: Data Loading & Preprocessing\n",
        "- Loads lung cancer images from **train, validation, and test folders**\n",
        "- Rescales images to **0\u20131 range**\n",
        "- Converts folders into **categorical generators**\n",
        "- Image Size: **224\u00d7224**, Batch Size: **32**\n",
        "\n",
        " Prepares data for both CNN and Transfer Learning models."
      ],
      "metadata": {
        "id": "vyVOOZh9EM90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Path\n",
        "https://www.kaggle.com/datasets/huebitsvizg/lung-cancer-dataset"
      ],
      "metadata": {
        "id": "BuQ8i04qEM93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading (same for both CNN & TL(Transfer Learning))\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = \"/kaggle/input/combined-lung-cancer/Lung cancer Dataset/LungCancer_Final/train\"\n",
        "VALID_DIR = \"/kaggle/input/combined-lung-cancer/Lung cancer Dataset/LungCancer_Final/valid\"\n",
        "TEST_DIR  = \"/kaggle/input/combined-lung-cancer/Lung cancer Dataset/LungCancer_Final/test\"\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.0)\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.0)\n",
        "test_datagen  = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    VALID_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "biLztyLaEM93"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 2: Basic CNN Model\n",
        "- Builds a **custom CNN** with:\n",
        "  - 3 Convolution blocks\n",
        "  - Dense layer with Dropout\n",
        "- Output layer uses **Softmax for 3-class classification**\n",
        "- Optimizer: **Adam**\n",
        "- Loss: **Categorical Crossentropy**\n",
        "\n",
        "Acts as the **baseline deep learning model**.\n"
      ],
      "metadata": {
        "id": "9r_x5ag6EM95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\ufe0f\u20e3 BASIC CNN MODEL\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EsP7aoCsEM97"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 3: CNN Training\n",
        "- Trains CNN for **20 epochs**\n",
        "- Uses:\n",
        "  -  **ModelCheckpoint** \u2192 Saves best model\n",
        "  -  **EarlyStopping** \u2192 Prevents overfitting\n",
        "\n",
        " Learns core lung cancer features.\n"
      ],
      "metadata": {
        "id": "3dEoTsfpEM97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\ufe0f\u20e3 Train CNN\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "cnn_checkpoint = ModelCheckpoint(\"cnn_best.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "early = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_gen, epochs=20, validation_data=valid_gen,\n",
        "    callbacks=[cnn_checkpoint, early]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7ouDFb8FEM98"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 4: CNN Evaluation\n",
        "- Generates:\n",
        "  -  **Classification Report**\n",
        "  -  **Confusion Matrix**\n",
        "- Evaluates CNN on **unseen test data**\n",
        "\n",
        " Measures CNN performance clearly.\n"
      ],
      "metadata": {
        "id": "c4MYFzW2EM98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\ufe0f\u20e3 Evaluate CNN\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "cnn_preds = cnn_model.predict(test_gen)\n",
        "cnn_pred_labels = np.argmax(cnn_preds, axis=1)\n",
        "\n",
        "print(\"\\nCNN Classification Report:\")\n",
        "print(classification_report(test_gen.classes, cnn_pred_labels, target_names=test_gen.class_indices.keys()))\n",
        "\n",
        "print(\"\\nCNN Confusion Matrix:\")\n",
        "print(confusion_matrix(test_gen.classes, cnn_pred_labels))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "F9YKWZhcEM99"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 5: Transfer Learning (MobileNetV2)\n",
        "- Loads **pretrained ImageNet MobileNetV2**\n",
        "- Freezes base layers for fast training\n",
        "- Adds:\n",
        "  - Global Average Pooling\n",
        "  - Dense + Dropout\n",
        "  - Softmax output\n",
        "\n",
        " Uses **pretrained visual knowledge** for better accuracy.\n"
      ],
      "metadata": {
        "id": "zZjkjTqTEM99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\ufe0f\u20e3 TRANSFER LEARNING MODEL (MobileNetV2)\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False   # Freeze for speed\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "tl_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "tl_model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Jn1AO5XBEM99"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 6: Transfer Learning Training\n",
        "- Trains MobileNetV2 for **15 epochs**\n",
        "- Uses same **checkpoint & early stopping**\n",
        "\n",
        " Makes training faster & more accurate.\n"
      ],
      "metadata": {
        "id": "ytngZcuQEM9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\ufe0f\u20e3 Train Transfer Learning Model\n",
        "tl_checkpoint = ModelCheckpoint(\"mobilenet_best.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "tl_history = tl_model.fit(\n",
        "    train_gen, epochs=15, validation_data=valid_gen,\n",
        "    callbacks=[tl_checkpoint, early]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "-xBkmmOREM9-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 7: Transfer Learning Evaluation\n",
        "- Generates:\n",
        "  -  Classification Report\n",
        "  -  Confusion Matrix\n",
        "- Compares TL model vs CNN\n",
        "\n",
        " Shows why Transfer Learning often outperforms CNN."
      ],
      "metadata": {
        "id": "XtoaA6T9EM9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\ufe0f\u20e3 Evaluate Transfer Learning\n",
        "tl_preds = tl_model.predict(test_gen)\n",
        "tl_pred_labels = np.argmax(tl_preds, axis=1)\n",
        "\n",
        "print(\"\\nMobileNetV2 Classification Report:\")\n",
        "print(classification_report(test_gen.classes, tl_pred_labels, target_names=test_gen.class_indices.keys()))\n",
        "\n",
        "print(\"\\nMobileNetV2 Confusion Matrix:\")\n",
        "print(confusion_matrix(test_gen.classes, tl_pred_labels))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "etyg2TDWEM9_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell : Load Both Models\n",
        "- Reloads:\n",
        "  -  Best CNN model\n",
        "  -  Best MobileNetV2 model\n",
        "\n",
        " Prepares models for ensemble."
      ],
      "metadata": {
        "id": "3h-yW653EM9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\ufe0f\u20e3 Load Both Models\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cnn_model = load_model(\"cnn_best.keras\")\n",
        "tl_model  = load_model(\"mobilenet_best.keras\")\n",
        "\n",
        "print(\"Models Loaded Successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "tZ4MCrEzEM9_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell : Ensemble Prediction Function\n",
        "- Combines predictions using:\n",
        "  - **CNN weight = 0.5**\n",
        "  - **MobileNet weight = 0.5**\n",
        "- Produces **final weighted prediction**\n",
        "\n",
        " Improves accuracy using **model fusion**."
      ],
      "metadata": {
        "id": "7TAxKY1REM9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\ufe0f\u20e3 Function to Make Ensemble Predictions\n",
        "import numpy as np\n",
        "\n",
        "def ensemble_predict(images, w1=0.5, w2=0.5):\n",
        "    cnn_pred = cnn_model.predict(images, verbose=0)\n",
        "    tl_pred = tl_model.predict(images, verbose=0)\n",
        "\n",
        "    final_pred = (w1 * cnn_pred) + (w2 * tl_pred)\n",
        "    return np.argmax(final_pred, axis=1), final_pred\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "e--uqIoDEM9_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell 10: Ensemble Evaluation\n",
        "- Runs ensemble on test set\n",
        "- Displays:\n",
        "  -  **Final Classification Report**\n",
        "  -  **Ensemble Confusion Matrix (Heatmap)**\n",
        "\n",
        " Shows **best overall system performance**."
      ],
      "metadata": {
        "id": "2yOCYhZfEM-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\ufe0f\u20e3 Run Ensemble on Test Set\n",
        "test_gen.reset()\n",
        "y_true = test_gen.classes\n",
        "\n",
        "y_pred, probs = ensemble_predict(test_gen)\n",
        "\n",
        "print(\"Prediction complete!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "fXWDVgT9EM-A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udd17 Official Documentation (Used Once)\n",
        "\n",
        "- Keras ImageDataGenerator  \n",
        "  https://keras.io/api/preprocessing/image/\n",
        "\n",
        "- CNN Layers (Conv2D)  \n",
        "  https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "\n",
        "- MobileNetV2 (Transfer Learning)  \n",
        "  https://keras.io/api/applications/mobilenet/\n",
        "\n",
        "- Model Training (`fit`)  \n",
        "  https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "- Classification Report  \n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n"
      ],
      "metadata": {
        "id": "B0UpNvl-EM-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\ufe0f\u20e3 Classification Report + Confusion Matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels_list = list(test_gen.class_indices.keys())\n",
        "\n",
        "print(\"\\n\ud83d\udcca Ensemble Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels_list))\n",
        "\n",
        "print(\"\\n\ud83d\udccc Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=labels_list, yticklabels=labels_list)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Ensemble Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "D8DxFUmAEM-B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cell : Save Final Models & Config\n",
        "- Saves:\n",
        "  -  CNN model\n",
        "  -  MobileNet model\n",
        "  -  Ensemble configuration (JSON)\n",
        "- Stores:\n",
        "  - Image size\n",
        "  - Class labels\n",
        "  - Ensemble weights\n",
        "\n",
        " Makes the project **deployment-ready**."
      ],
      "metadata": {
        "id": "rHwhH5mdEM-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Save the CNN model\n",
        "cnn_model.save(\"ensemble_cnn.keras\")\n",
        "\n",
        "# Save the Transfer Learning model\n",
        "tl_model.save(\"ensemble_mobilenet.keras\")\n",
        "\n",
        "# Save ensemble weights\n",
        "ensemble_config = {\n",
        "    \"w1\": 0.5,   # CNN weight\n",
        "    \"w2\": 0.5,   # MobileNet weight\n",
        "    \"img_size\": [224, 224],\n",
        "    \"labels\": [\"Benign\", \"Malignant\", \"Normal\"]\n",
        "}\n",
        "\n",
        "with open(\"ensemble_config.json\", \"w\") as f:\n",
        "    json.dump(ensemble_config, f)\n",
        "\n",
        "print(\"Ensemble model files saved successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wgwz5_-3EM-C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UHZfeHN3EM-D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Ex4U3MotEM-D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in colab"
      ],
      "metadata": {
        "id": "iklBzyjrERad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w5x2equEPwK"
      },
      "source": [
        "Install Dependencies\n",
        "\n",
        "This step installs:\n",
        "\n",
        "- Flask \u2192 backend web framework  \n",
        "- pyngrok \u2192 public sharing URL   \n",
        "- Folder creation for templates, static, uploads  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXvA78PK00vS"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iveT4heVs0qR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyLO5lG2tfQB"
      },
      "outputs": [],
      "source": [
        "!mkdir -p templates static static/uploads\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upT9ICW9EPwP"
      },
      "source": [
        "##  Backend: Lung Cancer Ensemble Prediction (app.py)\n",
        "\n",
        "This Flask app runs a **lung disease screening system** using an **ensemble of CNN + MobileNet models**.\n",
        "\n",
        "###  Key Functions\n",
        "- Loads:\n",
        "  - CNN model  \n",
        "  - MobileNet model  \n",
        "  - `ensemble_config.json` (weights, labels, image size)\n",
        "- Uploads X-ray images to `static/uploads`\n",
        "- Preprocesses image (resize + normalize)\n",
        "- Predicts using:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN3QzKMptxtn"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, request, redirect, url_for, flash\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# ----------------------------\n",
        "# FIXED PROJECT ROOT (Colab)\n",
        "# ----------------------------\n",
        "APP_ROOT = os.getcwd()\n",
        "UPLOAD_DIR = os.path.join(APP_ROOT, \"static\", \"uploads\")\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.secret_key = \"lung_detection_secret_2025\"\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# FIXED GOOGLE DRIVE MODEL PATHS\n",
        "# ----------------------------\n",
        "DRIVE_ROOT = \"/content/drive/My Drive/Lung Cancer(CNN+TL)\"\n",
        "\n",
        "def load_resources():\n",
        "\n",
        "    cfg_path = os.path.join(DRIVE_ROOT, \"ensemble_config.json\")\n",
        "    try:\n",
        "        with open(cfg_path, \"r\") as f:\n",
        "            cfg = json.load(f)\n",
        "    except:\n",
        "        cfg = {\"w1\": 0.5, \"w2\": 0.5, \"labels\": [\"Normal\", \"Pneumonia\", \"Lung Cancer\"], \"img_size\": [224, 224]}\n",
        "\n",
        "    model_a_path = os.path.join(DRIVE_ROOT, \"ensemble_cnn.keras\")\n",
        "    model_b_path = os.path.join(DRIVE_ROOT, \"ensemble_mobilenet.keras\")\n",
        "\n",
        "    model_a = None\n",
        "    model_b = None\n",
        "\n",
        "    try:\n",
        "        print(\"Loading Model A from:\", model_a_path)\n",
        "        model_a = load_model(model_a_path)\n",
        "    except Exception as e:\n",
        "        print(\"Model A not loaded:\", e)\n",
        "\n",
        "    try:\n",
        "        print(\"Loading Model B from:\", model_b_path)\n",
        "        model_b = load_model(model_b_path)\n",
        "    except Exception as e:\n",
        "        print(\"Model B not loaded:\", e)\n",
        "\n",
        "    return model_a, model_b, cfg\n",
        "\n",
        "\n",
        "MODEL_A, MODEL_B, CONFIG = load_resources()\n",
        "W1 = CONFIG.get(\"w1\", 0.5)\n",
        "W2 = CONFIG.get(\"w2\", 0.5)\n",
        "LABELS = CONFIG.get(\"labels\", [\"Normal\", \"Abnormal\"])\n",
        "IMG_SIZE = tuple(CONFIG.get(\"img_size\", [224, 224]))\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Helper functions\n",
        "# ----------------------------\n",
        "def prepare_image(path):\n",
        "    img = image.load_img(path, target_size=IMG_SIZE)\n",
        "    arr = image.img_to_array(img)\n",
        "    arr = np.expand_dims(arr, axis=0) / 255.0\n",
        "    return arr\n",
        "\n",
        "\n",
        "def ensemble_predict(path):\n",
        "    x = prepare_image(path)\n",
        "\n",
        "    if MODEL_A is None or MODEL_B is None:\n",
        "        probs = np.array([0.7, 0.2, 0.1])\n",
        "        idx = np.argmax(probs)\n",
        "        return LABELS[idx], float(probs[idx])\n",
        "\n",
        "    p_a = MODEL_A.predict(x, verbose=0)[0]\n",
        "    p_b = MODEL_B.predict(x, verbose=0)[0]\n",
        "\n",
        "    final = (W1 * p_a) + (W2 * p_b)\n",
        "    idx = np.argmax(final)\n",
        "    return LABELS[idx], float(final[idx])\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Routes\n",
        "# ----------------------------\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    hero_local_path = \"/mnt/data/a37bd896-6bd7-42f9-8d5e-8341b343c1e1.png\"\n",
        "    return render_template(\"home.html\", hero_image=hero_local_path)\n",
        "\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"GET\", \"POST\"])\n",
        "def predict():\n",
        "    prediction = None\n",
        "    confidence = None\n",
        "    img_rel_path = None\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "\n",
        "        f = request.files.get(\"file\")\n",
        "        if not f:\n",
        "            flash(\"Please select an image file.\", \"error\")\n",
        "            return redirect(url_for(\"predict\"))\n",
        "\n",
        "        filename = f.filename\n",
        "        save_path = os.path.join(UPLOAD_DIR, filename)\n",
        "        f.save(save_path)\n",
        "\n",
        "        label, conf = ensemble_predict(save_path)\n",
        "        prediction = label\n",
        "        confidence = f\"{conf*100:.2f}%\"\n",
        "\n",
        "        img_rel_path = \"uploads/\" + filename\n",
        "\n",
        "    return render_template(\n",
        "        \"predict.html\",\n",
        "        prediction=prediction,\n",
        "        confidence=confidence,\n",
        "        img_url=img_rel_path\n",
        "    )\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Run server\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Lung Screening UI\u2026\")\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q26lRBBPEPwR"
      },
      "source": [
        "##  Frontend: Home Page (home.html)\n",
        "\n",
        "This is the **landing page** of the AI Lung Screening web app.\n",
        "\n",
        "###  What It Does\n",
        "- Displays:\n",
        "  - App title (**AI Lung Screening**)\n",
        "  - Short project description\n",
        "- Provides two main buttons:\n",
        "  - **Start Diagnosis** \u2192 Opens prediction page\n",
        "  - **About** \u2192 Explains how the system works\n",
        "- Shows a **hero image** related to lung screening\n",
        "\n",
        "###  Purpose\n",
        "- Introduces the project\n",
        "- Guides users to start diagnosis easily\n",
        "\n",
        "### \ud83d\udd17 Official Reference\n",
        "- HTML Structure \u2192 https://developer.mozilla.org/en-US/docs/Web/HTML  \n",
        "\n",
        " This page acts as the **entry point of your lung cancer detection system**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSwwT27CuAVa"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/home.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\" />\n",
        "  <title>AI Lung Screening \u2014 Home</title>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "<body class=\"dm-body\">\n",
        "\n",
        "  <main class=\"hero\">\n",
        "    <div class=\"hero-inner\">\n",
        "      <div class=\"hero-text\">\n",
        "        <h1>\ud83e\udec1 AI Lung Screening</h1>\n",
        "        <p class=\"lead\">Fast, reliable lung image analysis using an ensemble of CNN + MobileNetV2.</p>\n",
        "\n",
        "        <div class=\"cta-row\">\n",
        "          <a class=\"btn primary\" href=\"{{ url_for('predict') }}\">Start Diagnosis</a>\n",
        "          <a class=\"btn ghost\" href=\"#about\">About</a>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <div class=\"hero-media\">\n",
        "        <!-- developer-supplied local path (will be transformed to served url externally) -->\n",
        "        <img class=\"hero-img\" src=\"{{ hero_image }}\" alt=\"\">\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <section id=\"about\" class=\"about\">\n",
        "      <h3>How it works</h3>\n",
        "      <p>Upload a chest X-ray on the Prediction page. The system runs an ensemble inference and returns a diagnostic label with a confidence score.</p>\n",
        "    </section>\n",
        "  </main>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cSEmlwdEPwR"
      },
      "source": [
        "##  Frontend: Prediction Page (predict.html)\n",
        "\n",
        "This page allows users to **upload a lung X-ray image and view the AI prediction**.\n",
        "\n",
        "###  Key Features\n",
        "- **File upload form** to select X-ray images\n",
        "- **Instant image preview** before submission\n",
        "- **AI result display**:\n",
        "  - Predicted label (e.g., Normal / Cancer)\n",
        "  - Confidence score (%)\n",
        "- **Dynamic result styling**:\n",
        "  - Red \u2192 Cancer risk\n",
        "  - Green \u2192 Normal case\n",
        "- **Safety note** reminding users this is a pre-screening tool only\n",
        "\n",
        "###  Navigation\n",
        "- Top bar with:\n",
        "  - App title\n",
        "  - **Home button** for quick navigation\n",
        "\n",
        "###  JavaScript Role\n",
        "- Shows **live preview of uploaded image** before prediction\n",
        "\n",
        "### \ud83d\udd17 Official Reference\n",
        "- HTML Forms \u2192 https://developer.mozilla.org/en-US/docs/Web/HTML/Element/form\n",
        "\n",
        " This page is the **core user interaction screen** for lung cancer prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOr2qRfscJXa"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/predict.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\" />\n",
        "  <title>AI Lung Screening \u2014 Predict</title>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "<body class=\"dm-body\">\n",
        "\n",
        "  <header class=\"dm-topbar\">\n",
        "    <div class=\"topbar-left\">\n",
        "      <h2>\ud83e\udec1 AI Lung Screening</h2>\n",
        "      <p class=\"sub\">Ensemble CNN + MobileNetV2</p>\n",
        "    </div>\n",
        "    <nav class=\"top-actions\">\n",
        "      <a class=\"small-btn\" href=\"{{ url_for('home') }}\">Home</a>\n",
        "    </nav>\n",
        "  </header>\n",
        "\n",
        "  <div class=\"dm-container\">\n",
        "    <section class=\"panel upload-panel\">\n",
        "      <h3>Upload X-Ray</h3>\n",
        "\n",
        "      <form method=\"post\" enctype=\"multipart/form-data\" class=\"upload-form\">\n",
        "        <label class=\"file-chooser\">\n",
        "          <input type=\"file\" name=\"file\" accept=\"image/*\" onchange=\"preview(event)\" required>\n",
        "          <span>Select Image</span>\n",
        "        </label>\n",
        "\n",
        "        <button class=\"btn primary\" type=\"submit\">Analyze</button>\n",
        "      </form>\n",
        "\n",
        "      <div class=\"preview\">\n",
        "        {% if img_url %}\n",
        "          <img id=\"previewImg\" src=\"{{ url_for('static', filename=img_url) }}\" alt=\"uploaded image\">\n",
        "        {% else %}\n",
        "          <div id=\"previewPlaceholder\" class=\"preview-placeholder\">Preview will appear here</div>\n",
        "        {% endif %}\n",
        "      </div>\n",
        "    </section>\n",
        "\n",
        "    <aside class=\"panel result-panel\">\n",
        "      <h3>Result</h3>\n",
        "\n",
        "      {% if prediction %}\n",
        "        <div class=\"result-pill {{ 'danger' if 'cancer' in prediction|lower else 'ok' }}\">\n",
        "          <div class=\"label\">{{ prediction }}</div>\n",
        "          <div class=\"score\">Confidence: <strong>{{ confidence }}</strong></div>\n",
        "        </div>\n",
        "      {% else %}\n",
        "        <div class=\"no-result\">No result yet \u2014 upload an X-ray to analyze.</div>\n",
        "      {% endif %}\n",
        "\n",
        "      <div class=\"notes\">\n",
        "        <h4>Notes</h4>\n",
        "        <p>This tool is intended for research and pre-screening only. Always consult a qualified clinician for final diagnosis.</p>\n",
        "      </div>\n",
        "    </aside>\n",
        "  </div>\n",
        "\n",
        "<script>\n",
        "function preview(e){\n",
        "  const target = document.getElementById('previewImg');\n",
        "  const placeholder = document.getElementById('previewPlaceholder');\n",
        "  if(e.target.files && e.target.files[0]){\n",
        "    const url = URL.createObjectURL(e.target.files[0]);\n",
        "    if(target){\n",
        "      target.src = url;\n",
        "      target.style.display = 'block';\n",
        "    } else {\n",
        "      // create an inline preview if none rendered by server\n",
        "      const img = document.createElement('img');\n",
        "      img.id = 'previewImg';\n",
        "      img.src = url;\n",
        "      img.alt = 'preview';\n",
        "      img.style.maxWidth = '100%';\n",
        "      const container = document.querySelector('.preview');\n",
        "      container.innerHTML = '';\n",
        "      container.appendChild(img);\n",
        "    }\n",
        "    if(placeholder) placeholder.style.display = 'none';\n",
        "  }\n",
        "}\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trcj4-YOEPwS"
      },
      "source": [
        "## \ud83c\udfa8 Frontend Styling: Dark Medical Theme (style.css)\n",
        "\n",
        "This file defines the **entire dark UI theme** for both Home and Prediction pages.\n",
        "\n",
        "###  What It Controls\n",
        "- **Dark medical color palette** using CSS variables (`:root`)\n",
        "- **Hero section layout** (Home page)\n",
        "- **Upload panel & result panel UI** (Prediction page)\n",
        "- **Buttons, file upload box, image preview**\n",
        "- **Prediction status styling**:\n",
        "  -  Green \u2192 Normal\n",
        "  -  Red \u2192 Cancer risk\n",
        "- **Responsive layout** for mobile & desktop\n",
        "\n",
        "###  Key Features\n",
        "- Glassmorphism cards\n",
        "- Gradient medical buttons\n",
        "- Dynamic result highlighting\n",
        "- Fully responsive design\n",
        "\n",
        "### \ud83d\udd17 Official Reference\n",
        "- CSS Variables \u2192 https://developer.mozilla.org/en-US/docs/Web/CSS/Using_CSS_custom_properties  \n",
        "- Flexbox Layout \u2192 https://developer.mozilla.org/en-US/docs/Web/CSS/flex\n",
        "\n",
        " This stylesheet gives your lung screening system a **professional, clinical UI appearance**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhOogmxYuEUV"
      },
      "outputs": [],
      "source": [
        "%%writefile static/style.css\n",
        "/* DARK MEDICAL THEME - style.css */\n",
        ":root{\n",
        "  --bg: #0f1113;\n",
        "  --card: #121417;\n",
        "  --muted: #9aa8b2;\n",
        "  --accent: #00e0c6;\n",
        "  --accent-2: #00a38a;\n",
        "  --danger: #ff6b6b;\n",
        "  --glass: rgba(255,255,255,0.03);\n",
        "  --panel-shadow: 0 6px 30px rgba(0,0,0,0.6);\n",
        "}\n",
        "\n",
        "* { box-sizing: border-box; }\n",
        "body.dm-body {\n",
        "  margin: 0;\n",
        "  font-family: Inter, \"Segoe UI\", Roboto, system-ui, Arial;\n",
        "  background: radial-gradient(1200px 600px at 10% 20%, rgba(0,160,138,0.06), transparent),\n",
        "              radial-gradient(900px 500px at 90% 80%, rgba(0,224,198,0.03), transparent),\n",
        "              var(--bg);\n",
        "  color: #e6eef1;\n",
        "  -webkit-font-smoothing: antialiased;\n",
        "  -moz-osx-font-smoothing: grayscale;\n",
        "  min-height: 100vh;\n",
        "}\n",
        "\n",
        "/* HERO */\n",
        ".hero {\n",
        "  padding: 60px 24px;\n",
        "}\n",
        ".hero-inner {\n",
        "  display: flex;\n",
        "  gap: 32px;\n",
        "  align-items: center;\n",
        "  justify-content: center;\n",
        "  max-width: 1100px;\n",
        "  margin: 0 auto;\n",
        "}\n",
        ".hero-text {\n",
        "  max-width: 540px;\n",
        "  text-align: left;\n",
        "}\n",
        ".hero-text h1 {\n",
        "  margin: 0 0 8px 0;\n",
        "  font-size: 40px;\n",
        "  color: #dffcf4;\n",
        "  letter-spacing: -0.5px;\n",
        "}\n",
        ".lead {\n",
        "  color: var(--muted);\n",
        "  margin: 0 0 18px 0;\n",
        "  font-size: 16px;\n",
        "}\n",
        ".cta-row { display:flex; gap:12px; align-items:center; }\n",
        ".btn {\n",
        "  display:inline-block;\n",
        "  padding: 10px 18px;\n",
        "  border-radius: 10px;\n",
        "  text-decoration: none;\n",
        "  color: #041014;\n",
        "  font-weight: 700;\n",
        "  cursor: pointer;\n",
        "  border: none;\n",
        "}\n",
        ".btn.primary {\n",
        "  background: linear-gradient(180deg, var(--accent), var(--accent-2));\n",
        "  color: #041014;\n",
        "  box-shadow: 0 6px 20px rgba(0,224,198,0.12), 0 2px 6px rgba(0,0,0,0.6);\n",
        "}\n",
        ".btn.ghost {\n",
        "  background: transparent;\n",
        "  color: var(--accent);\n",
        "  border: 1px solid rgba(0,224,198,0.16);\n",
        "}\n",
        "\n",
        "/* HERO MEDIA */\n",
        ".hero-media { width: 420px; display:flex; align-items:center; justify-content:center; }\n",
        ".hero-img {\n",
        "  width: 100%;\n",
        "  border-radius: 14px;\n",
        "  box-shadow: 0 10px 40px rgba(0,0,0,0.6);\n",
        "  border: 1px solid rgba(255,255,255,0.03);\n",
        "  display: block;\n",
        "}\n",
        "\n",
        "/* ABOUT */\n",
        ".about {\n",
        "  margin-top: 28px;\n",
        "  max-width: 1100px;\n",
        "  margin-left: auto;\n",
        "  margin-right: auto;\n",
        "  color: var(--muted);\n",
        "  padding: 18px;\n",
        "  border-radius: 10px;\n",
        "  background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));\n",
        "  border: 1px solid rgba(255,255,255,0.02);\n",
        "}\n",
        "\n",
        "/* TOPBAR for Predict page */\n",
        ".dm-topbar {\n",
        "  display:flex;\n",
        "  justify-content:space-between;\n",
        "  align-items:center;\n",
        "  gap: 12px;\n",
        "  padding: 18px 28px;\n",
        "  background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));\n",
        "  border-bottom: 1px solid rgba(255,255,255,0.02);\n",
        "  box-shadow: var(--panel-shadow);\n",
        "}\n",
        ".dm-topbar h2 { margin:0; font-size:18px; color: #dffcf4; }\n",
        ".dm-topbar .sub { margin:0; color: var(--muted); font-size:13px; }\n",
        "\n",
        "/* Layout for predict */\n",
        ".dm-container {\n",
        "  display: flex;\n",
        "  gap: 28px;\n",
        "  max-width: 1100px;\n",
        "  margin: 28px auto;\n",
        "  padding: 0 18px;\n",
        "}\n",
        ".panel {\n",
        "  background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));\n",
        "  padding: 20px;\n",
        "  border-radius: 12px;\n",
        "  box-shadow: var(--panel-shadow);\n",
        "  border: 1px solid rgba(255,255,255,0.02);\n",
        "}\n",
        "\n",
        "/* upload panel */\n",
        ".upload-panel { flex: 1.1; min-height: 360px; }\n",
        ".upload-panel h3 { margin-top:0; color: #dffcf4; }\n",
        ".file-chooser {\n",
        "  display:inline-block;\n",
        "  width:100%;\n",
        "  padding: 14px;\n",
        "  background: rgba(0,0,0,0.25);\n",
        "  border-radius: 10px;\n",
        "  border: 1px dashed rgba(0,224,198,0.12);\n",
        "  color: var(--muted);\n",
        "  cursor: pointer;\n",
        "  text-align: center;\n",
        "}\n",
        ".file-chooser input { display:none; }\n",
        "\n",
        ".upload-form { margin-top: 16px; display:flex; gap:12px; align-items:center; }\n",
        "\n",
        "/* preview */\n",
        ".preview {\n",
        "  margin-top: 18px;\n",
        "  min-height: 220px;\n",
        "  display:flex;\n",
        "  align-items:center;\n",
        "  justify-content:center;\n",
        "  border-radius: 10px;\n",
        "  border: 1px solid rgba(255,255,255,0.02);\n",
        "  background: rgba(0,0,0,0.18);\n",
        "}\n",
        ".preview img { max-width:100%; max-height:360px; border-radius:8px; }\n",
        "\n",
        "/* result panel */\n",
        ".result-panel { width: 360px; min-height: 360px; }\n",
        ".result-panel h3 { margin-top:0; color: #dffcf4; }\n",
        "\n",
        ".result-pill {\n",
        "  margin-top: 14px;\n",
        "  padding: 18px;\n",
        "  border-radius: 10px;\n",
        "  background: linear-gradient(180deg, rgba(0,224,198,0.08), rgba(0,160,138,0.06));\n",
        "  border: 1px solid rgba(0,224,198,0.12);\n",
        "}\n",
        ".result-pill.ok { border-left: 6px solid #00e0c6; }\n",
        ".result-pill.danger { background: linear-gradient(180deg, rgba(255,107,107,0.06), rgba(255,80,80,0.04)); border-left: 6px solid var(--danger); }\n",
        "\n",
        ".result-pill .label { font-size: 20px; font-weight: 700; color: #dffcf4; }\n",
        ".result-pill .score { color: var(--muted); margin-top:8px; }\n",
        "\n",
        "/* notes */\n",
        ".notes { margin-top: 22px; color: var(--muted); font-size: 13px; }\n",
        "\n",
        "/* small helpers */\n",
        ".small-btn { color: var(--muted); text-decoration:none; padding:8px 12px; border-radius:8px; border:1px solid rgba(255,255,255,0.03); }\n",
        "\n",
        ".preview-placeholder {\n",
        "  color: var(--muted);\n",
        "  text-align:center;\n",
        "}\n",
        "\n",
        "/* responsive */\n",
        "@media (max-width: 900px) {\n",
        "  .hero-inner, .dm-container { flex-direction: column; padding: 0 12px; }\n",
        "  .hero-media { width: 100%; }\n",
        "  .result-panel { width: 100%; }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epZK6xaJEPwT"
      },
      "source": [
        "Kill Previous Processes\n",
        "\n",
        "This ensures Flask and ngrok do not conflict:\n",
        "\n",
        "- Stops earlier Flask sessions  \n",
        "- Stops older ngrok tunnels  \n",
        "- Prevents \"port already in use\" errors  \n",
        "\n",
        "Safe to run every time before starting server.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZklGyEOUvKAu"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 6\ufe0f\u20e3 Kill any previous processes\n",
        "# ===============================\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD1iIelOEPwU"
      },
      "source": [
        "Checking Port 5000 (User Instructions)\n",
        "\n",
        "If server fails, port 8000 may be occupied.\n",
        "\n",
        "Run:\n",
        "!lsof -i :5000\n",
        "\n",
        "If you see:\n",
        "python   12345 LISTEN\n",
        "\n",
        "Kill it with:\n",
        "!kill -9 12345\n",
        "\n",
        "Then launch Flask again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzib0VwOuP6I"
      },
      "outputs": [],
      "source": [
        "!lsof -i :5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdrvlSXGvTTB"
      },
      "outputs": [],
      "source": [
        "!kill -9 28005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE2fJZC2EPwV"
      },
      "source": [
        " Run Flask App in Background\n",
        "\n",
        "Starts backend without blocking the notebook:\n",
        "\n",
        "!nohup python app.py > flask.log 2>&1 &\n",
        "\n",
        "Logs are stored in flask.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lwB5xyLvZzA"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 7\ufe0f\u20e3 Run Flask in the background\n",
        "# ===============================\n",
        "!nohup python app.py > flask.log 2>&1 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4-PBpDEPwV"
      },
      "source": [
        " Ngrok Setup\n",
        "\n",
        "Ngrok provides a public HTTPS link.\n",
        "\n",
        "Your ngrok token was removed for safety.\n",
        "\n",
        "To use ngrok:\n",
        "1. Get token \u2192 https://dashboard.ngrok.com/get-started/your-authtoken  \n",
        "2. Add inside notebook:\n",
        "\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "3. Start tunnel:\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "\n",
        "Shareable app link appears here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9_46HwpugDy"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 8\ufe0f\u20e3 Start ngrok tunnel\n",
        "# ===============================\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"\"  # \ud83d\udd11 replace with your token\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ_0B80pEPwV"
      },
      "source": [
        " View Logs\n",
        "\n",
        "To debug backend:\n",
        "\n",
        "!tail -n 20 flask.log\n",
        "\n",
        "Shows:\n",
        "- Model loading issues  \n",
        "- Prompt errors  \n",
        "- Script formatting errors  \n",
        "- Runtime crashes  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjwTQbR6vfia"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 9\ufe0f\u20e3 Check logs (optional)\n",
        "# ===============================\n",
        "!sleep 3 && tail -n 20 flask.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKwnLHg7vxFQ"
      },
      "outputs": [],
      "source": []
    }
  ]
}