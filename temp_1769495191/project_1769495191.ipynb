{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13595165,
          "sourceType": "datasetVersion",
          "datasetId": 8638323
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#======================================================================\n#  Cell 1 \u2014 Setup (paths, device, imports)\n#======================================================================\n\nimport os, cv2, glob, gc, math, time, json, random\nimport numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\n\n# --------- PATHS ----------\nAVENUE_ROOT = \"/kaggle/input/weapon-dataset/Avenue_Dataset/Avenue Dataset\"\nTRAIN_VIDS  = os.path.join(AVENUE_ROOT, \"training_videos\")\nTEST_VIDS   = os.path.join(AVENUE_ROOT, \"testing_videos\")\n\nWORK        = \"/kaggle/working/unsup_anomaly\"\nFR_TRAIN    = os.path.join(WORK, \"frames/train\")\nFR_TEST     = os.path.join(WORK, \"frames/test\")\nOUT_DIR     = os.path.join(WORK, \"outputs\")\nos.makedirs(FR_TRAIN, exist_ok=True)\nos.makedirs(FR_TEST, exist_ok=True)\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\nprint(\"Train vids:\", len(os.listdir(TRAIN_VIDS)))\nprint(\"Test  vids:\", len(os.listdir(TEST_VIDS)))\n",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:42:05.635853Z",
          "iopub.execute_input": "2025-11-07T12:42:05.636547Z",
          "iopub.status.idle": "2025-11-07T12:42:05.647941Z",
          "shell.execute_reply.started": "2025-11-07T12:42:05.636519Z",
          "shell.execute_reply": "2025-11-07T12:42:05.647220Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cuda\nTrain vids: 16\nTest  vids: 21\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "#======================================================================\n# Cell 2 \u2014 Extract frames (skip if already done)\n#======================================================================\n\ndef extract_frames(video_dir, out_dir, resize=(224, 224)):\n    os.makedirs(out_dir, exist_ok=True)\n    vids = sorted([f for f in os.listdir(video_dir) if f.lower().endswith((\".avi\",\".mp4\",\".mov\"))])\n    total = 0\n    for v in tqdm(vids, desc=f\"Extracting from {os.path.basename(video_dir)}\"):\n        path = os.path.join(video_dir, v)\n        base = os.path.splitext(v)[0]\n        cap = cv2.VideoCapture(path)\n        i = 0\n        while True:\n            ok, frame = cap.read()\n            if not ok: break\n            if resize is not None:\n                frame = cv2.resize(frame, resize, interpolation=cv2.INTER_AREA)\n            cv2.imwrite(os.path.join(out_dir, f\"{base}_{i:05d}.jpg\"), frame)\n            i += 1; total += 1\n        cap.release()\n    print(f\"\u2705 Saved {total} frames to {out_dir}\")\n\n# Run once; if you already extracted earlier, you can skip.\nif len(os.listdir(FR_TRAIN)) < 100:\n    extract_frames(TRAIN_VIDS, FR_TRAIN)\nif len(os.listdir(FR_TEST)) < 100:\n    extract_frames(TEST_VIDS, FR_TEST)\n\nprint(\"Train frames:\", len([f for f in os.listdir(FR_TRAIN) if f.endswith('.jpg')]))\nprint(\"Test  frames:\", len([f for f in os.listdir(FR_TEST) if f.endswith('.jpg')]))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:42:19.910697Z",
          "iopub.execute_input": "2025-11-07T12:42:19.911437Z",
          "iopub.status.idle": "2025-11-07T12:43:25.703455Z",
          "shell.execute_reply.started": "2025-11-07T12:42:19.911409Z",
          "shell.execute_reply": "2025-11-07T12:43:25.702654Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Extracting from training_videos: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 16/16 [00:32<00:00,  2.02s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u2705 Saved 15328 frames to /kaggle/working/unsup_anomaly/frames/train\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Extracting from testing_videos: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:33<00:00,  1.59s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u2705 Saved 15324 frames to /kaggle/working/unsup_anomaly/frames/test\nTrain frames: 15328\nTest  frames: 15324\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "#======================================================================\n# Cell 3 \u2014 Dataset: motion-difference stacks (temporal K)\n#======================================================================\n\nclass DiffStackDataset(Dataset):\n    \"\"\"\n    Creates K-length stacks of |gray_t - gray_(t-1)| as channels.\n    Each sample corresponds to a clip centered at index t.\n    \"\"\"\n    def __init__(self, frames_dir, K=5, stride=1, split=\"train\"):\n        self.paths = sorted([os.path.join(frames_dir, f) for f in os.listdir(frames_dir) if f.endswith(\".jpg\")])\n        self.K = K\n        self.stride = stride\n        self.split = split\n        # build indices (we need t-K..t-1 diffs to reach t)\n        self.valid_idx = list(range(K, len(self.paths)))\n    def __len__(self):\n        return len(self.valid_idx)\n    def __getitem__(self, i):\n        t = self.valid_idx[i]\n        # load frames t-K..t\n        ims = []\n        for idx in range(t - self.K, t + 1):\n            img = cv2.imread(self.paths[idx])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            img = img.astype(np.float32) / 255.0\n            ims.append(img)\n        ims = np.stack(ims, 0)  # (K+1,H,W)\n        diffs = np.abs(ims[1:] - ims[:-1])  # (K,H,W)\n        x = torch.from_numpy(diffs)  # float32\n        return x\n\n# Hyperparams for dataset\nK = 5\ntrain_ds = DiffStackDataset(FR_TRAIN, K=K, split=\"train\")\ntest_ds  = DiffStackDataset(FR_TEST,  K=K, split=\"test\")\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=(device.type==\"cuda\"))\ntest_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2, pin_memory=(device.type==\"cuda\"))\n\nlen(train_ds), len(test_ds)\n\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:44:17.641340Z",
          "iopub.execute_input": "2025-11-07T12:44:17.642099Z",
          "iopub.status.idle": "2025-11-07T12:44:17.703249Z",
          "shell.execute_reply.started": "2025-11-07T12:44:17.642070Z",
          "shell.execute_reply": "2025-11-07T12:44:17.702671Z"
        }
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(15323, 15319)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "#======================================================================\n# Cell 4 \u2014 Tiny AE for K-channel motion stacks\n#======================================================================\n\nclass SmallAE(nn.Module):\n    def __init__(self, in_ch=5):\n        super().__init__()\n        self.enc = nn.Sequential(\n            nn.Conv2d(in_ch, 32, 3, 2, 1), nn.ReLU(True),  # 112\n            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(True),     # 56\n            nn.Conv2d(64, 128,3, 2, 1), nn.ReLU(True),     # 28\n            nn.Conv2d(128,256,3, 2, 1), nn.ReLU(True),     # 14\n        )\n        self.dec = nn.Sequential(\n            nn.ConvTranspose2d(256,128,4,2,1), nn.ReLU(True),  # 28\n            nn.ConvTranspose2d(128,64, 4,2,1), nn.ReLU(True),  # 56\n            nn.ConvTranspose2d(64, 32, 4,2,1), nn.ReLU(True),  # 112\n            nn.ConvTranspose2d(32, in_ch, 4,2,1), nn.Sigmoid() # 224\n        )\n    def forward(self, x):\n        z = self.enc(x)\n        y = self.dec(z)\n        return y\n\nae = SmallAE(in_ch=K).to(device)\nprint(\"Params (M):\", sum(p.numel() for p in ae.parameters())/1e6)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:44:46.561233Z",
          "iopub.execute_input": "2025-11-07T12:44:46.561950Z",
          "iopub.status.idle": "2025-11-07T12:44:46.583241Z",
          "shell.execute_reply.started": "2025-11-07T12:44:46.561925Z",
          "shell.execute_reply": "2025-11-07T12:44:46.582578Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Params (M): 1.079909\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "#================================================\n# Cell 5 \u2014 Train (MSE), early stop, save best\n#================================================\ngc.collect(); torch.cuda.empty_cache()\n\nepochs = 20          # you can raise to 30+ if time allows\nlr = 1e-3\nopt  = torch.optim.Adam(ae.parameters(), lr=lr)\ncrit = nn.MSELoss()\nscaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n\nbest = 1e9\npatience, bad = 6, 0\ncurve = []\n\nfor ep in range(1, epochs+1):\n    ae.train()\n    run = 0.0\n    for x in tqdm(train_loader, desc=f\"Epoch {ep}/{epochs}\"):\n        x = x.to(device, non_blocking=True)\n        opt.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n            y = ae(x)\n            loss = crit(y, x)\n        scaler.scale(loss).backward()\n        scaler.step(opt); scaler.update()\n        run += loss.item()*x.size(0)\n    ep_loss = run/len(train_ds)\n    curve.append(ep_loss)\n    print(f\"Epoch {ep} | train MSE={ep_loss:.6f}\")\n    # early stop on training loss (unsupervised)\n    if ep_loss < best - 1e-5:\n        best = ep_loss; bad = 0\n        torch.save(ae.state_dict(), os.path.join(OUT_DIR, \"ae_best.pt\"))\n    else:\n        bad += 1\n        if bad >= patience:\n            print(\"Early stopping.\")\n            break\n\nplt.figure(figsize=(6,4)); plt.plot(curve); plt.grid(True)\nplt.title(\"AE training loss\"); plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\")\nplt.savefig(os.path.join(OUT_DIR, \"train_loss.png\"), dpi=150)\nplt.show()\n\nprint(\"Best train loss:\", best)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:45:17.330802Z",
          "iopub.execute_input": "2025-11-07T12:45:17.331202Z",
          "iopub.status.idle": "2025-11-07T12:51:39.794167Z",
          "shell.execute_reply.started": "2025-11-07T12:45:17.331178Z",
          "shell.execute_reply": "2025-11-07T12:51:39.793436Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/2281260132.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\nEpoch 1/20:   0%|          | 0/240 [00:00<?, ?it/s]/tmp/ipykernel_37/2281260132.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\nEpoch 1/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:48<00:00,  4.99it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 | train MSE=0.010718\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:48<00:00,  4.99it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 | train MSE=0.000248\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:48<00:00,  4.95it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 | train MSE=0.000247\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:47<00:00,  5.02it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 | train MSE=0.000247\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:47<00:00,  5.06it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 | train MSE=0.000247\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:48<00:00,  4.96it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6 | train MSE=0.000247\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:46<00:00,  5.11it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7 | train MSE=0.000247\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8/20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:46<00:00,  5.14it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8 | train MSE=0.000247\nEarly stopping.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 600x400 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Best train loss: 0.0002475082956606684\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "#===============================================================================\n# Cell 6 \u2014 Score test frames (per-clip error \u2192 center frame), smooth, threshold\n#=================================================================================\n# reload best\nae.load_state_dict(torch.load(os.path.join(OUT_DIR, \"ae_best.pt\"), map_location=device))\nae.eval()\n\n# step 1: raw scores\nraw_scores = []\nwith torch.no_grad():\n    for x in tqdm(test_loader, desc=\"Scoring\"):\n        x = x.to(device, non_blocking=True)\n        y = ae(x)\n        e = torch.mean((y - x)**2, dim=(1,2,3))  # (B,)\n        raw_scores.extend(e.detach().cpu().numpy().tolist())\n\nraw_scores = np.array(raw_scores)\n\n# step 2: temporal smoothing (EMA)\ndef ema(arr, alpha=0.2):\n    out = np.zeros_like(arr)\n    acc = 0.0\n    for i,a in enumerate(arr):\n        acc = alpha*a + (1-alpha)*acc if i>0 else a\n        out[i] = acc\n    return out\n\nscores_ema = ema(raw_scores, alpha=0.2)\n\n# step 3: normalize to [0,1] for readability\ndef minmax(a):\n    m, M = np.min(a), np.max(a)\n    return (a - m) / (M - m + 1e-12)\n\nscores_norm = minmax(scores_ema)\n\n# step 4: adaptive threshold (MAD or percentile)\nmedian = np.median(scores_norm)\nmad = np.median(np.abs(scores_norm - median)) + 1e-9\nthr_mad = float(median + 2.5 * mad)  # tweak k=2.0~3.0\nthr_pct = float(np.percentile(scores_norm, 95))\n\nthr = min(1.0, max(0.0, 0.5*thr_mad + 0.5*thr_pct))  # blend\nprint(f\"Threshold (MAD/pct blend): {thr:.4f}\")\n\n# save scores\nnp.save(os.path.join(OUT_DIR, \"scores_raw.npy\"), raw_scores)\nnp.save(os.path.join(OUT_DIR, \"scores_norm.npy\"), scores_norm)\nwith open(os.path.join(OUT_DIR, \"threshold.json\"), \"w\") as f:\n    json.dump({\"thr\": thr}, f)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:51:55.096087Z",
          "iopub.execute_input": "2025-11-07T12:51:55.096861Z",
          "iopub.status.idle": "2025-11-07T12:52:40.728925Z",
          "shell.execute_reply.started": "2025-11-07T12:51:55.096827Z",
          "shell.execute_reply": "2025-11-07T12:52:40.728087Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Scoring: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 240/240 [00:45<00:00,  5.26it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Threshold (MAD/pct blend): 0.1002\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "#===================================================\n#  Cell 7 \u2014 Mark anomaly events, export CSV\n#===================================================\n# boolean mask\nis_anom = scores_norm >= thr\n\n# group into segments\nsegments = []\nstart = None\nfor i,flag in enumerate(is_anom):\n    if flag and start is None:\n        start = i\n    if (not flag or i == len(is_anom)-1) and start is not None:\n        end = i if not flag else i\n        if end - start + 1 >= 5:  # require \u22655 frames\n            segments.append((start, end))\n        start = None\n\nimport pandas as pd\ndf = pd.DataFrame({\n    \"frame_index\": np.arange(len(scores_norm)),\n    \"score\": scores_norm,\n    \"anomaly\": is_anom.astype(int)\n})\ndf.to_csv(os.path.join(OUT_DIR, \"anomaly_scores.csv\"), index=False)\npd.DataFrame(segments, columns=[\"start_idx\",\"end_idx\"]).to_csv(os.path.join(OUT_DIR, \"anomaly_segments.csv\"), index=False)\n\nprint(\"Saved CSVs to:\", OUT_DIR)\nprint(\"Found segments:\", segments[:10], \" ... total:\", len(segments))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:52:49.305685Z",
          "iopub.execute_input": "2025-11-07T12:52:49.306515Z",
          "iopub.status.idle": "2025-11-07T12:52:49.623400Z",
          "shell.execute_reply.started": "2025-11-07T12:52:49.306476Z",
          "shell.execute_reply": "2025-11-07T12:52:49.622745Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Saved CSVs to: /kaggle/working/unsup_anomaly/outputs\nFound segments: [(931, 1035), (1435, 1446), (2515, 2522), (2647, 2653), (3956, 3970), (4252, 4262), (5113, 5136), (5215, 5232), (5259, 5274), (5282, 5307)]  ... total: 44\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "#=================================================================\n#  Cell 8 \u2014 Visualize heatmaps on a few frames (qualitative)\n#=================================================================\n\ndef heatmap_for_frame(index_in_test_ds):\n    # fetch the exact clip input and reconstruction\n    # need to rebuild a single sample from dataset\n    x = test_ds[index_in_test_ds].unsqueeze(0).to(device)  # (1,K,H,W)\n    with torch.no_grad():\n        y = ae(x)\n    err = (y - x).pow(2).mean(dim=1)[0].cpu().numpy()  # (H,W)\n    err = (err - err.min()) / (err.max() - err.min() + 1e-9)\n    return (err*255).astype(np.uint8)\n\nsample_ids = list(range(50, 50+6))  # pick some\nfor idx in sample_ids:\n    hmap = heatmap_for_frame(idx)\n    # fetch real frame (aligned with dataset index t)\n    frame_path = sorted([p for p in os.listdir(FR_TEST) if p.endswith(\".jpg\")])[K + idx]  # dataset starts at K\n    full_path  = os.path.join(FR_TEST, frame_path)\n    frame = cv2.imread(full_path)\n    heat = cv2.applyColorMap(hmap, cv2.COLORMAP_JET)\n    heat = cv2.resize(heat, (frame.shape[1], frame.shape[0]))\n    overlay = cv2.addWeighted(frame, 0.6, heat, 0.4, 0)\n    outp = os.path.join(OUT_DIR, f\"viz_{frame_path}\")\n    cv2.imwrite(outp, np.hstack([frame, overlay]))\n\nprint(\"Saved heatmap examples to:\", OUT_DIR)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:52:55.586461Z",
          "iopub.execute_input": "2025-11-07T12:52:55.586759Z",
          "iopub.status.idle": "2025-11-07T12:52:55.760298Z",
          "shell.execute_reply.started": "2025-11-07T12:52:55.586734Z",
          "shell.execute_reply": "2025-11-07T12:52:55.759649Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Saved heatmap examples to: /kaggle/working/unsup_anomaly/outputs\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "#====================================================================\n#  Cell 9 \u2014 Make an MP4 with live anomaly score (no GT)\n#=====================================================================\n# choose first test video for demo\ntest_videos = sorted([f for f in os.listdir(TEST_VIDS) if f.lower().endswith((\".avi\",\".mp4\",\".mov\"))])\nassert len(test_videos) > 0, \"No test videos found.\"\ndemo_vid = os.path.join(TEST_VIDS, test_videos[0])\nprint(\"Demo video:\", demo_vid)\n\n# load threshold & model\nwith open(os.path.join(OUT_DIR, \"threshold.json\")) as f:\n    thr = json.load(f)[\"thr\"]\n\ncap = cv2.VideoCapture(demo_vid)\nfps = cap.get(cv2.CAP_PROP_FPS) or 25\nW,H = int(cap.get(3)), int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nwriter = cv2.VideoWriter(os.path.join(OUT_DIR, \"unsup_anomaly_demo.mp4\"), fourcc, fps, (W,H))\n\n# sliding buffer of grayscale frames\nbuf = []\n\nae.eval()\nwith torch.no_grad():\n    while True:\n        ok, frame = cap.read()\n        if not ok: break\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0\n        buf.append(cv2.resize(gray, (224,224)))\n        if len(buf) < (K+1):\n            writer.write(frame); continue\n        if len(buf) > (K+1):\n            buf.pop(0)\n\n        stack = np.stack(buf, 0)             # (K+1,H,W)\n        diffs = np.abs(stack[1:] - stack[:-1])  # (K,H,W)\n        x = torch.from_numpy(diffs).unsqueeze(0).to(device)  # (1,K,H,W)\n        y = ae(x)\n        mse = torch.mean((y - x)**2).item()\n\n        # normalize roughly based on training stats we saved\n        # here we map using min/max of scores_norm for visibility\n        # (fallback if you want stable scaling across videos)\n        mse_scaled = (mse - np.min(scores_ema)) / (np.max(scores_ema) - np.min(scores_ema) + 1e-9)\n        status = \"ANOMALY\" if mse_scaled >= thr else \"OK\"\n        color  = (0,0,255) if status==\"ANOMALY\" else (0,200,0)\n\n        cv2.putText(frame, f\"Score={mse_scaled:.3f}  Thr={thr:.3f}\", (10,30),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2)\n        cv2.putText(frame, status, (10,70),\n                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n        writer.write(frame)\n\ncap.release(); writer.release()\nprint(\"Saved:\", os.path.join(OUT_DIR, \"unsup_anomaly_demo.mp4\"))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:53:02.813148Z",
          "iopub.execute_input": "2025-11-07T12:53:02.813648Z",
          "iopub.status.idle": "2025-11-07T12:53:09.339810Z",
          "shell.execute_reply.started": "2025-11-07T12:53:02.813622Z",
          "shell.execute_reply": "2025-11-07T12:53:09.339200Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Demo video: /kaggle/input/weapon-dataset/Avenue_Dataset/Avenue Dataset/testing_videos/01.avi\nSaved: /kaggle/working/unsup_anomaly/outputs/unsup_anomaly_demo.mp4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "#==========================================================================\n# Cell 7 \u2014 Proper evaluation: PER VIDEO (only compute AUC if 0 and 1 exist)\n#==========================================================================\n\nimport os, glob\nfrom scipy.io import loadmat\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(\"Evaluating PER VIDEO...\")\nGT_root = TEST_VOLS\n\n# load model scores if not present in variable \"scores\"\n# scores = np.load(os.path.join(OUT_DIR, \"scores_norm.npy\"))\n\nvideo_names = sorted(set([os.path.basename(p).split(\"_\")[0] \n                          for p in os.listdir(FR_TEST) if p.endswith(\".jpg\")]))\n\nauc_results = []\n\nfor vid in video_names:\n    # ---- Extract scores for this video ----\n    frame_paths = sorted([p for p in os.listdir(FR_TEST) if p.startswith(vid) and p.endswith(\".jpg\")])\n    idxs = [int(fp.split(\"_\")[-1].split(\".\")[0]) for fp in frame_paths]\n    \n    if len(idxs) == 0: \n        continue\n\n    s = scores[:len(idxs)]    # already in order since datasets were created sequentially\n    scores = scores[len(idxs):]  # shift for next video\n\n    # ---- Load GT volume ----\n    vol_mat = os.path.join(GT_root, f\"vol{vid}.mat\")\n    if not os.path.exists(vol_mat):\n        print(f\"\u26a0\ufe0f No GT for video {vid}, skipping\")\n        continue\n\n    mat = loadmat(vol_mat)\n    vol = None\n    for k in (\"volLabel\",\"volGT\",\"vol\",\"volume\"):\n        if k in mat:\n            vol = mat[k]\n            break\n    assert vol is not None, f\"No GT volume key found in {vol_mat}\"\n    \n    T = vol.shape[-1]\n    y_true = np.array([(vol[..., t] > 0).any() for t in range(T)], dtype=int)\n\n    N = min(len(s), len(y_true))\n    y_true = y_true[:N]\n    y_score = s[:N]\n\n    if len(np.unique(y_true)) < 2:\n        print(f\"\u26a0\ufe0f Video {vid}: contains only one class \u2192 skip AUC\")\n        continue\n\n    # ---- Compute AUC ----\n    roc_auc = roc_auc_score(y_true, y_score)\n    precision, recall, _ = precision_recall_curve(y_true, y_score)\n    pr_auc = auc(recall, precision)\n\n    auc_results.append((vid, roc_auc, pr_auc))\n    print(f\"Video {vid} \u2192 ROC-AUC={roc_auc:.3f} | PR-AUC={pr_auc:.3f}\")\n\n# ---- Print Summary ----\nif auc_results:\n    roc_mean = np.mean([r[1] for r in auc_results])\n    pr_mean = np.mean([r[2] for r in auc_results])\n    print(\"\\n====== FINAL RESULTS (Videos with both classes) ======\")\n    print(f\"Mean ROC-AUC: {roc_mean:.4f}\")\n    print(f\"Mean PR-AUC:  {pr_mean:.4f}\")\nelse:\n    print(\"\\n\u274c No videos contained both 0 and 1 \u2192 Cannot compute AUC.\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:54:46.679708Z",
          "iopub.execute_input": "2025-11-07T12:54:46.680520Z",
          "iopub.status.idle": "2025-11-07T12:54:49.013507Z",
          "shell.execute_reply.started": "2025-11-07T12:54:46.680489Z",
          "shell.execute_reply": "2025-11-07T12:54:49.012712Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Evaluating PER VIDEO...\n\u26a0\ufe0f Video 01: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 02: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 03: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 04: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 05: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 06: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 07: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 08: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 09: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 10: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 11: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 12: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 13: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 14: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 15: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 16: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 17: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 18: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 19: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 20: contains only one class \u2192 skip AUC\n\u26a0\ufe0f Video 21: contains only one class \u2192 skip AUC\n\n\u274c No videos contained both 0 and 1 \u2192 Cannot compute AUC.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "from scipy.io import loadmat\nimport numpy as np, os, glob\n\nGT_root = TEST_VOLS\nprint(\"Checking anomaly distribution in GT volumes...\\n\")\n\nfor vid in sorted([vp.split(\"vol\")[-1].split(\".\")[0] for vp in os.listdir(GT_root) if vp.endswith(\".mat\")]):\n    vol_mat = os.path.join(GT_root, f\"vol{vid}.mat\")\n    mat = loadmat(vol_mat)\n    vol = None\n    for k in (\"volLabel\",\"volGT\",\"vol\",\"volume\"):\n        if k in mat:\n            vol = mat[k]\n            break\n    if vol is None:\n        print(f\"{vid} \u2192 \u274c no vol key found\")\n        continue\n\n    T = vol.shape[-1]\n    y_true = np.array([(vol[..., t] > 0).any() for t in range(T)], dtype=int)\n    unique, counts = np.unique(y_true, return_counts=True)\n    print(f\"Video {vid}: {dict(zip(unique, counts))}\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:56:00.102058Z",
          "iopub.execute_input": "2025-11-07T12:56:00.102349Z",
          "iopub.status.idle": "2025-11-07T12:56:02.216514Z",
          "shell.execute_reply.started": "2025-11-07T12:56:00.102325Z",
          "shell.execute_reply": "2025-11-07T12:56:02.215913Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Checking anomaly distribution in GT volumes...\n\nVideo 01: {1: 1439}\nVideo 02: {1: 1211}\nVideo 03: {1: 923}\nVideo 04: {1: 947}\nVideo 05: {1: 1007}\nVideo 06: {1: 1283}\nVideo 07: {1: 605}\nVideo 08: {1: 36}\nVideo 09: {1: 1175}\nVideo 10: {1: 841}\nVideo 11: {1: 472}\nVideo 12: {1: 1271}\nVideo 13: {1: 549}\nVideo 14: {1: 507}\nVideo 15: {1: 1001}\nVideo 16: {1: 740}\nVideo 17: {1: 426}\nVideo 18: {1: 294}\nVideo 19: {1: 248}\nVideo 20: {1: 273}\nVideo 21: {1: 76}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": "from scipy.io import loadmat\nmat = loadmat(os.path.join(TEST_VOLS, \"vol01.mat\"))\n\nprint(mat.keys())\nfor k, v in mat.items():\n    if k.startswith(\"__\"): \n        continue\n    print(k, type(v), v.shape if hasattr(v, 'shape') else None)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T12:59:40.996592Z",
          "iopub.execute_input": "2025-11-07T12:59:40.997119Z",
          "iopub.status.idle": "2025-11-07T12:59:41.193389Z",
          "shell.execute_reply.started": "2025-11-07T12:59:40.997094Z",
          "shell.execute_reply": "2025-11-07T12:59:41.192589Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "dict_keys(['__header__', '__version__', '__globals__', 'vol'])\nvol <class 'numpy.ndarray'> (120, 160, 1439)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "from scipy.io import loadmat\nimport numpy as np\nimport os\n\nvp = os.path.join(TEST_VOLS, \"vol01.mat\")\nmat = loadmat(vp)\nvol = mat[\"vol\"]  # 120 x 160 x T\n\nprint(\"Min:\", vol.min(), \"Max:\", vol.max())\nvals = np.unique(vol)\nprint(\"Unique values:\", vals[:20], \" ... total:\", len(vals))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T13:00:12.080292Z",
          "iopub.execute_input": "2025-11-07T13:00:12.080968Z",
          "iopub.status.idle": "2025-11-07T13:00:13.086341Z",
          "shell.execute_reply.started": "2025-11-07T13:00:12.080940Z",
          "shell.execute_reply": "2025-11-07T13:00:13.085529Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Min: 4 Max: 253\nUnique values: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]  ... total: 250\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "# Convert vol to frame-level GT using intensity thresholding\nvol = vol.astype(float)\nT = vol.shape[-1]\n\n# Compute per-frame anomaly score from vol\nframe_scores_gt = [vol[..., t].mean() for t in range(T)]\n\n# Make binary GT: anomaly if above mean + 2*std\nmu, sigma = np.mean(frame_scores_gt), np.std(frame_scores_gt)\nthr_gt = mu + 2 * sigma\n\nframe_labels = np.array([1 if s > thr_gt else 0 for s in frame_scores_gt])\nprint(\"GT threshold:\", thr_gt, \" Positives:\", frame_labels.sum(), \"/\", T)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T13:00:57.190636Z",
          "iopub.execute_input": "2025-11-07T13:00:57.191187Z",
          "iopub.status.idle": "2025-11-07T13:00:57.279078Z",
          "shell.execute_reply.started": "2025-11-07T13:00:57.191162Z",
          "shell.execute_reply": "2025-11-07T13:00:57.278244Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GT threshold: 101.80371757290617  Positives: 9 / 1439\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.io import loadmat\nimport os, glob\n\nvp = sorted(glob.glob(os.path.join(TEST_VOLS, \"vol*.mat\")))[0]\nmat = loadmat(vp)\nvol = mat[\"vol\"].astype(float)\n\nmeans = [vol[..., t].mean() for t in range(vol.shape[-1])]\nprint(\"Frame mean stats \u2192 min:\", np.min(means), \"max:\", np.max(means), \"std:\", np.std(means))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-07T13:02:24.014508Z",
          "iopub.execute_input": "2025-11-07T13:02:24.015208Z",
          "iopub.status.idle": "2025-11-07T13:02:24.313716Z",
          "shell.execute_reply.started": "2025-11-07T13:02:24.015178Z",
          "shell.execute_reply": "2025-11-07T13:02:24.313073Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Frame mean stats \u2192 min: 90.39744791666666 max: 107.48640625 std: 1.6066615285193395\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}