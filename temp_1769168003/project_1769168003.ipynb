{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 457469,
          "sourceType": "datasetVersion",
          "datasetId": 209295
        },
        {
          "sourceId": 13971311,
          "sourceType": "datasetVersion",
          "datasetId": 8906877
        },
        {
          "sourceId": 13971360,
          "sourceType": "datasetVersion",
          "datasetId": 8906915
        },
        {
          "sourceId": 13971480,
          "sourceType": "datasetVersion",
          "datasetId": 8907014
        },
        {
          "sourceId": 13989991,
          "sourceType": "datasetVersion",
          "datasetId": 8916822
        },
        {
          "sourceId": 14003583,
          "sourceType": "datasetVersion",
          "datasetId": 8922396
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcd8 How to Use Kaggle (Upload Dataset & Notebook)\n",
        "\n",
        "### \u2705 Step 1: Create Kaggle Account\n",
        "- Go to \ud83d\udc49 https://www.kaggle.com  \n",
        "- Sign in using Google / Email\n",
        "\n",
        "---\n",
        "\n",
        "### \u2705 Step 2: Upload Your Dataset\n",
        "1. Click **Datasets** \u2192 **Create New Dataset**\n",
        "2. Upload your **dataset folder or ZIP file**\n",
        "3. Add:\n",
        "   - Dataset name\n",
        "   - Short description\n",
        "4. Set visibility \u2192 **Public / Private**\n",
        "5. Click **Create**\n",
        "\n",
        "\u2705 After upload, Kaggle gives a dataset path like:\n"
      ],
      "metadata": {
        "id": "TZde-0ow76dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE-1 : Voice-Based Parkinson\u2019s Detection"
      ],
      "metadata": {
        "id": "V99KGDXP5ZRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports \u2013 Very Short Explanation (with Links)\n",
        "\n",
        "NumPy / Pandas \u2192 data loading & numerical processing\n",
        "https://numpy.org\n",
        " \u2022 https://pandas.pydata.org\n",
        "\n",
        "Scikit-Learn \u2192 preprocessing, feature selection, PCA, classifiers, evaluation\n",
        "https://scikit-learn.org\n",
        "\n",
        "XGBoost / LightGBM / CatBoost \u2192 high-performance gradient boosting models\n",
        "https://xgboost.readthedocs.io\n",
        " \u2022 https://lightgbm.readthedocs.io\n",
        " \u2022 https://catboost.ai\n",
        "\n",
        "Matplotlib / Seaborn \u2192 plots & visualizations\n",
        "https://matplotlib.org\n",
        " \u2022 https://seaborn.pydata.org\n",
        "\n",
        "pickle \u2192 save full model pipeline\n",
        "https://docs.python.org/3/library/pickle.html"
      ],
      "metadata": {
        "id": "5KM7VmYz7sJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Path\n"
      ],
      "metadata": {
        "id": "nIM14R68HR7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Loads PMS, UCI, PD speech datasets (auto label detection)\n",
        "# - Cleans & unifies into a single voice dataset\n",
        "# - XGBoost feature importance \u2192 SelectKBest \u2192 Imputer \u2192 Scaler \u2192 PCA\n",
        "# - Trains XGBoost, LightGBM, CatBoost, SVM, RandomForest\n",
        "# - Selects best model by ROC-AUC\n",
        "# - Saves **full preprocessing + best model** into `voice_model.pkl`\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 250)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-05T05:39:48.144035Z",
          "iopub.execute_input": "2025-12-05T05:39:48.144969Z",
          "iopub.status.idle": "2025-12-05T05:40:33.155512Z",
          "shell.execute_reply.started": "2025-12-05T05:39:48.144903Z",
          "shell.execute_reply": "2025-12-05T05:40:33.154839Z"
        },
        "id": "_M6x_gwh5ZRm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto Label Detection \u2013 Short Explanation\n",
        "\n",
        "- This function automatically finds the label/target column in any dataset.\n",
        "It checks:\n",
        "\n",
        "- Common label names (label, class, status, diagnosis, pd, target).\n",
        "\n",
        "- Binary columns containing only 0 and 1 (typical classification labels).\n",
        "\n",
        "- If no column matches, it returns None.\n",
        "\n",
        "Useful when merging datasets that use diffe"
      ],
      "metadata": {
        "id": "ocSPIWWf8f_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Auto Label Detection Helper\n",
        "\n",
        "def find_label_column(df):\n",
        "    \"\"\"\n",
        "    Automatically detect label column in any dataset.\n",
        "    - First tries common names.\n",
        "    - Then looks for binary 0/1 columns.\n",
        "    \"\"\"\n",
        "    possible_names = [\"label\", \"class\", \"status\", \"diagnosis\", \"pd\", \"target\"]\n",
        "\n",
        "    # 1. Check common label names\n",
        "    for col in df.columns:\n",
        "        if col.lower() in possible_names:\n",
        "            return col\n",
        "\n",
        "    # 2. Check for 0/1 binary columns\n",
        "    for col in df.columns:\n",
        "        vals = df[col].dropna().unique()\n",
        "        if len(vals) == 2 and set(vals).issubset({0, 1}):\n",
        "            return col\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "ekgotpFQ6WD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading & Preparing Voice Datasets \u2013 Short Explanation**\n",
        "\n",
        "This section loads **four different Parkinson\u2019s voice datasets** (PMS, UCI, PD1, PD2).\n",
        "Steps performed for every dataset:\n",
        "\n",
        "1. **Load file** (some without headers, so column names are added manually).\n",
        "2. **Detect label column** automatically using `find_label_column()`.\n",
        "3. **Rename label \u2192 \"label\"** for uniformity.\n",
        "4. **Convert label to integer** and drop invalid rows.\n",
        "5. **Tag each dataset with source name**.\n",
        "6. **Skip datasets without labels** (to avoid errors)."
      ],
      "metadata": {
        "id": "7VAqYIAh8p6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load & Prepare Individual Voice Datasets\n",
        "# 2.1 PMS \u2013 Parkinson Multiple Sound Recording (no header)\n",
        "pms_path = \"/kaggle/input/parkinson-speech/Parkinson_Multiple_Sound_Recording/train_data.txt\"\n",
        "\n",
        "pms_raw = pd.read_csv(\n",
        "    pms_path,\n",
        "    sep=r'\\s+|,',\n",
        "    engine='python',\n",
        "    header=None\n",
        ")\n",
        "\n",
        "# Assign column names\n",
        "pms_raw.columns = [f\"f{i}\" for i in range(pms_raw.shape[1])]\n",
        "\n",
        "# Drop ID column if present\n",
        "if \"f0\" in pms_raw.columns:\n",
        "    pms_raw = pms_raw.drop(columns=[\"f0\"])\n",
        "\n",
        "pms_label = find_label_column(pms_raw)\n",
        "print(\"PMS detected label:\", pms_label)\n",
        "\n",
        "pms_raw = pms_raw.rename(columns={pms_label: \"label\"})\n",
        "pms_raw[\"label\"] = pd.to_numeric(pms_raw[\"label\"], errors=\"coerce\")\n",
        "pms_raw[\"source\"] = \"PMS\"\n",
        "\n",
        "# 2.2 UCI Parkinson\u2019s dataset\n",
        "uci_path = \"/kaggle/input/parkinsons-voice-data/parkinsons/parkinsons.data\"\n",
        "uci_raw = pd.read_csv(uci_path)\n",
        "\n",
        "uci_label = find_label_column(uci_raw)\n",
        "print(\"UCI detected label:\", uci_label)\n",
        "\n",
        "uci_raw = uci_raw.rename(columns={uci_label: \"label\"})\n",
        "uci_raw[\"label\"] = pd.to_numeric(uci_raw[\"label\"], errors=\"coerce\")\n",
        "uci_raw[\"source\"] = \"UCI\"\n",
        "\n",
        "# 2.3 PD speech feature datasets\n",
        "pd1_raw = pd.read_csv(\n",
        "    \"/kaggle/input/parkinsons-voice-data/parkinsonsdiseaseclassification/pd_speech_features/pd_speech_features.csv\"\n",
        ")\n",
        "pd2_raw = pd.read_csv(\n",
        "    \"/kaggle/input/parkinsons-disease-speech-signal-features/pd_speech_features.csv\"\n",
        ")\n",
        "\n",
        "pd1_label = find_label_column(pd1_raw)\n",
        "pd2_label = find_label_column(pd2_raw)\n",
        "\n",
        "print(\"PD1 detected label:\", pd1_label)\n",
        "print(\"PD2 detected label:\", pd2_label)\n",
        "\n",
        "datasets = [\n",
        "    (\"PMS\", pms_raw),\n",
        "    (\"UCI\", uci_raw),\n",
        "    (\"PD1\", pd1_raw),\n",
        "    (\"PD2\", pd2_raw),\n",
        "]\n",
        "\n",
        "cleaned = []\n",
        "\n",
        "for name, df in datasets:\n",
        "    label = find_label_column(df)\n",
        "\n",
        "    if label is None:\n",
        "        print(f\"\u26a0\ufe0f WARNING: {name} has NO label column \u2014 SKIPPED.\")\n",
        "        continue\n",
        "\n",
        "    df = df.copy()\n",
        "    df = df.rename(columns={label: \"label\"})\n",
        "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"label\"])\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    df[\"source\"] = name\n",
        "\n",
        "    cleaned.append(df)\n"
      ],
      "metadata": {
        "id": "zOHy1Bns6cN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Unifying Voice Datasets \u2013 Short Explanation**\n",
        "\n",
        "1. **Merge all cleaned datasets** using `pd.concat()` into one unified voice dataset (`clf_all`).\n",
        "2. Print dataset shape and how many samples came from each source (PMS, UCI, PD1, PD2).\n",
        "3. **Split into features (X) and labels (y)**.\n",
        "4. Keep **numeric-only features** (voice datasets sometimes include non-numeric columns).\n",
        "5. Perform **train\u2013test split (80/20)** with stratification to preserve class balance.\n",
        "\n",
        "This prepares a clean, consistent dataset for feature engineering and model training.\n",
        "\n"
      ],
      "metadata": {
        "id": "YkfO91G69Kn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Unified Voice Dataset\n",
        "\n",
        "clf_all = pd.concat(cleaned, ignore_index=True)\n",
        "\n",
        "print(\"Unified dataset shape:\", clf_all.shape)\n",
        "print(\"\\nSource counts:\")\n",
        "print(clf_all[\"source\"].value_counts())\n",
        "\n",
        "# Separate features / labels\n",
        "X = clf_all.drop(columns=[\"label\"])\n",
        "y = clf_all[\"label\"].astype(int)\n",
        "\n",
        "# Numeric-only features\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "X = X[numeric_cols]\n",
        "\n",
        "print(\"\\nNumber of numeric features:\", len(numeric_cols))\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0])\n",
        "print(\"Test size :\", X_test.shape[0])\n"
      ],
      "metadata": {
        "id": "sS1P6e3L6itL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection Pipeline (Short Explanation)**\n",
        "\n",
        "1. **XGBoost Feature Importance**\n",
        "\n",
        "   * Train an XGBoost model to rank all voice features.\n",
        "   * Select the **top 300 most important features**.\n",
        "     *(Why? Removes noisy/irrelevant features before deeper selection.)*\n",
        "\n",
        "2. **Imputation + SelectKBest (ANOVA F-test)**\n",
        "\n",
        "   * Fill missing values using **median imputer**.\n",
        "   * Apply **ANOVA F-test** to keep the **top 200 statistically relevant features**.\n",
        "     *(Why? Keeps features that most strongly separate PD vs healthy speech.)*\n",
        "\n",
        "3. **StandardScaler + PCA \u2192 Final Embedding**\n",
        "\n",
        "   * Scale all selected features.\n",
        "   * Apply **PCA** to reduce dimensionality to **100 components** (or fewer if limited).\n",
        "     *(Why? Compresses data into a smooth, noise-reduced space for classifiers.)*\n",
        "\n",
        "This 3-step pipeline produces a **compact, high-quality feature representation** used by all ML models."
      ],
      "metadata": {
        "id": "ruHkty8I9bz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature Selection: XGBoost \u2192 KBest \u2192 PCA\n",
        "\n",
        "# 4.1 XGBoost feature importance (select top 300 features)\n",
        "xgb_fs = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_fs.fit(X_train, y_train)\n",
        "\n",
        "importances = xgb_fs.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "top_k = 300 if X_train.shape[1] >= 300 else X_train.shape[1]\n",
        "top_features = X_train.columns[indices][:top_k]\n",
        "print(f\"Using top {len(top_features)} features from XGBoost.\")\n",
        "\n",
        "X_train_fs = X_train[top_features]\n",
        "X_test_fs = X_test[top_features]\n",
        "\n",
        "# 4.2 Impute NaNs + ANOVA SelectKBest (k=200 or less if limited)\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train_imp = imputer.fit_transform(X_train_fs)\n",
        "X_test_imp = imputer.transform(X_test_fs)\n",
        "\n",
        "k_best = 200 if X_train_imp.shape[1] >= 200 else X_train_imp.shape[1]\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
        "selector.fit(X_train_imp, y_train)\n",
        "\n",
        "X_train_kbest = selector.transform(X_train_imp)\n",
        "X_test_kbest = selector.transform(X_test_imp)\n",
        "\n",
        "print(\"Shape after KBest:\", X_train_kbest.shape)\n",
        "\n",
        "# 4.3 StandardScaler + PCA (dim=100 or limited by features)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_kbest)\n",
        "X_test_scaled = scaler.transform(X_test_kbest)\n",
        "\n",
        "pca_components = 100 if X_train_scaled.shape[1] >= 100 else X_train_scaled.shape[1]\n",
        "\n",
        "pca = PCA(n_components=pca_components, random_state=RANDOM_STATE)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(\"Final PCA dimension:\", X_train_pca.shape)"
      ],
      "metadata": {
        "id": "tKN07ifs6qVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a **very short and clean explanation** for this entire model-training block:\n",
        "\n",
        "---\n",
        "\n",
        "### **Training & Comparing Multiple Models (Short Explanation)**\n",
        "\n",
        "This block trains **five ML classifiers** on the PCA-reduced voice features and compares them using **ROC-AUC**, the most reliable metric for medical binary classification.\n",
        "\n",
        "#### **What happens:**\n",
        "\n",
        "1. **evaluate_model()**\n",
        "\n",
        "   * Trains a given model.\n",
        "   * Computes predictions + probabilities (handling SVM separately).\n",
        "   * Returns accuracy, precision, recall, F1, and ROC-AUC.\n",
        "\n",
        "2. **Models trained:**\n",
        "\n",
        "   * **XGBoost** \u2192 strong tree-based gradient boosting\n",
        "   * **LightGBM** \u2192 fast, optimized boosting\n",
        "   * **CatBoost** \u2192 handles categorical patterns well\n",
        "   * **SVM** \u2192 strong margin-based classifier\n",
        "   * **RandomForest** \u2192 ensemble of decision trees\n",
        "\n",
        "3. **Leaderboard creation:**\n",
        "\n",
        "   * Evaluate each model on the test set.\n",
        "   * Rank them by **ROC-AUC** to find the best classifier.\n",
        "\n",
        "#### **Purpose:**\n",
        "\n",
        "Selects the **best-performing PD voice classifier** after testing multiple algorithms under identical feature preprocessing."
      ],
      "metadata": {
        "id": "BRvc8kyd9i1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 5. Train Multiple Models & Compare\n",
        "\n",
        "def evaluate_model(name, model):\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    preds = model.predict(X_test_pca)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        proba = model.predict_proba(X_test_pca)[:, 1]\n",
        "    else:\n",
        "        # SVM or others with decision_function only\n",
        "        if hasattr(model, \"decision_function\"):\n",
        "            from sklearn.metrics import roc_curve\n",
        "            scores = model.decision_function(X_test_pca)\n",
        "            # scale scores to 0-1 via min-max\n",
        "            min_s, max_s = scores.min(), scores.max()\n",
        "            proba = (scores - min_s) / (max_s - min_s + 1e-8)\n",
        "        else:\n",
        "            proba = preds\n",
        "\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy_score(y_test, preds),\n",
        "        \"precision\": precision_score(y_test, preds),\n",
        "        \"recall\": recall_score(y_test, preds),\n",
        "        \"f1\": f1_score(y_test, preds),\n",
        "        \"roc_auc\": roc_auc_score(y_test, proba),\n",
        "        \"clf\": model\n",
        "    }\n",
        "\n",
        "models = [\n",
        "    (\"XGBoost\", XGBClassifier(\n",
        "        n_estimators=400, max_depth=6, learning_rate=0.05,\n",
        "        subsample=0.9, colsample_bytree=0.9, random_state=RANDOM_STATE\n",
        "    )),\n",
        "    (\"LightGBM\", LGBMClassifier(\n",
        "        n_estimators=500, learning_rate=0.03,\n",
        "        num_leaves=64, random_state=RANDOM_STATE\n",
        "    )),\n",
        "    (\"CatBoost\", CatBoostClassifier(\n",
        "        iterations=500, depth=8, learning_rate=0.05,\n",
        "        verbose=False, random_state=RANDOM_STATE\n",
        "    )),\n",
        "    (\"SVM\", SVC(C=3, gamma=\"scale\", probability=True, random_state=RANDOM_STATE)),\n",
        "    (\"RandomForest\", RandomForestClassifier(\n",
        "        n_estimators=300, random_state=RANDOM_STATE\n",
        "    )),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in models:\n",
        "    res = evaluate_model(name, model)\n",
        "    results.append(res)\n",
        "    print(f\"{name}: ROC-AUC = {res['roc_auc']:.4f}\")\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(by=\"roc_auc\", ascending=False)\n",
        "df_results"
      ],
      "metadata": {
        "id": "swe7Xwaq6xj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Leaderboard & Best Model \u2013 Short Explanation**\n",
        "\n",
        "This block displays and selects the best-performing classifier.\n",
        "\n",
        "#### **What it does:**\n",
        "\n",
        "1. **Prints a leaderboard** containing\n",
        "\n",
        "   * model name\n",
        "   * accuracy\n",
        "   * precision\n",
        "   * recall\n",
        "   * F1-score\n",
        "   * ROC-AUC\n",
        "\n",
        "2. **Identifies the best model** based on **highest ROC-AUC**, which is the most reliable metric for medical detection tasks.\n",
        "\n",
        "3. **Stores the top model** (`best_model`) for saving and deployment.\n",
        "\n",
        "#### **Purpose:**\n",
        "\n",
        "Automatically selects the **strongest Parkinson\u2019s voice classifier** from all trained models."
      ],
      "metadata": {
        "id": "ONK6KxbY-LsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Leaderboard & Best Model\n",
        "print(\"\\nModel leaderboard (sorted by ROC-AUC):\")\n",
        "print(df_results[[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]])\n",
        "\n",
        "best_row = df_results.iloc[0]\n",
        "best_model_name = best_row[\"model\"]\n",
        "best_model = best_row[\"clf\"]\n",
        "\n",
        "print(f\"\\nBest model: {best_model_name}\")\n",
        "print(f\"ROC-AUC: {best_row['roc_auc']:.4f}\")"
      ],
      "metadata": {
        "id": "RIc85EnU63su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a **very short, efficient explanation** for this final saving cell:\n",
        "\n",
        "---\n",
        "\n",
        "### **Saving the Full Voice Pipeline \u2013 Short Explanation**\n",
        "\n",
        "This cell **packages the entire preprocessing pipeline + best classifier** into one file (`voice_model.pkl`) so it can be used later for real inference.\n",
        "\n",
        "#### **What gets saved:**\n",
        "\n",
        "* **Best model** (XGBoost / LGBM / CatBoost / SVM / RF \u2014 whichever won)\n",
        "* **Imputer** (fills missing values)\n",
        "* **SelectKBest** (ANOVA feature selector)\n",
        "* **Scaler** (StandardScaler)\n",
        "* **PCA** (final dimensionality reduction)\n",
        "* **Top features from XGBoost**\n",
        "* **All numeric feature names**\n",
        "* **XGBoost feature-importance model**\n",
        "* **Random state for reproducibility*"
      ],
      "metadata": {
        "id": "3xNHsSjS-S0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Save Full Voice Pipeline for TRUE Fusion\n",
        "\n",
        "voice_model_package = {\n",
        "    \"model\": best_model,                  # trained classifier on PCA features\n",
        "    \"imputer\": imputer,                   # median imputer (on top_features)\n",
        "    \"scaler\": scaler,                     # StandardScaler after KBest\n",
        "    \"selector\": selector,                 # SelectKBest ANOVA\n",
        "    \"pca\": pca,                           # PCA to get final embedding\n",
        "    \"top_features\": list(top_features),   # list of feature names selected by XGBoost\n",
        "    \"numeric_feature_names\": list(numeric_cols),  # all numeric columns before XGB\n",
        "    \"xgb_feature_selector\": xgb_fs,       # XGBoost feature selector\n",
        "    \"random_state\": RANDOM_STATE\n",
        "}\n",
        "\n",
        "with open(\"voice_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(voice_model_package, f)\n",
        "\n",
        "print(\"\\n\u2705 VOICE MODEL SAVED \u2192 voice_model.pkl\")\n"
      ],
      "metadata": {
        "id": "jwXpRs_Q63hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase-2 : PHASE-2 (FIXED): Spiral CNN Embeddings + LightGBM"
      ],
      "metadata": {
        "id": "YACiEbc65ZRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "except ImportError:\n",
        "    !pip install lightgbm -q\n",
        "    from lightgbm import LGBMClassifier\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "\n",
        "# 1. Build Spiral Dataset (Healthy vs Parkinson)\n",
        "\n",
        "def is_parkinson(name: str) -> bool:\n",
        "    name = name.lower()\n",
        "    return any(k in name for k in [\"parkinson\", \"patient\", \"pd\", \"_p\", \"p_\"])\n",
        "\n",
        "def is_healthy(name: str) -> bool:\n",
        "    name = name.lower()\n",
        "    return any(k in name for k in [\"healthy\", \"control\", \"normal\", \"hc\", \"_h\", \"h_\"])\n",
        "\n",
        "def collect_spiral_dataset(base_dir: str):\n",
        "    image_exts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.tif\")\n",
        "    paths, labels = [], []\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        folder = os.path.basename(root)\n",
        "        label = None\n",
        "        if is_parkinson(folder):\n",
        "            label = 1\n",
        "        elif is_healthy(folder):\n",
        "            label = 0\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        for ext in image_exts:\n",
        "            for img_path in glob.glob(os.path.join(root, ext)):\n",
        "                paths.append(img_path)\n",
        "                labels.append(label)\n",
        "\n",
        "    return paths, labels\n",
        "\n",
        "spiral_sources = [\n",
        "    \"/kaggle/input/parkinsons-handwritten-2/Parkinsons dataset/Healthy_parkinsons/HealthySpiral/HealthySpiral\",\n",
        "    \"/kaggle/input/parkinsons-handwritten-2/Parkinsons dataset/Parkinsons_patient/PatientSpiral/PatientSpiral\",\n",
        "    \"/kaggle/input/parkinsons-handwritten/improved+spiral+test+using+digitized+graphics+tablet+for+monitoring+parkinson+s+disease/Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinsons Disease/drawings/Dynamic Spiral Test\",\n",
        "    \"/kaggle/input/parkinsons-handwritten/improved+spiral+test+using+digitized+graphics+tablet+for+monitoring+parkinson+s+disease/Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinsons Disease/drawings/Static Spiral Test\",\n",
        "    \"/kaggle/input/parkinsons-spiral/hw_drawings/Dynamic Spiral Test\",\n",
        "    \"/kaggle/input/parkinsons-spiral/hw_drawings/Static Spiral Test\",\n",
        "]\n",
        "\n",
        "all_paths, all_labels = [], []\n",
        "for src in spiral_sources:\n",
        "    if os.path.exists(src):\n",
        "        p, l = collect_spiral_dataset(src)\n",
        "        print(f\"Loaded {len(p)} images from: {src}\")\n",
        "        all_paths.extend(p)\n",
        "        all_labels.extend(l)\n",
        "    else:\n",
        "        print(f\"\u26a0\ufe0f Path not found, skipping: {src}\")\n",
        "\n",
        "spiral_df = pd.DataFrame({\"filepath\": all_paths, \"label\": all_labels})\n",
        "spiral_df = spiral_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "print(\"Total spiral images:\", len(spiral_df))\n",
        "print(\"Label distribution (0=Healthy, 1=PD):\")\n",
        "print(spiral_df[\"label\"].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-05T05:43:22.842086Z",
          "iopub.execute_input": "2025-12-05T05:43:22.842497Z",
          "iopub.status.idle": "2025-12-05T05:43:46.270526Z",
          "shell.execute_reply.started": "2025-12-05T05:43:22.842468Z",
          "shell.execute_reply": "2025-12-05T05:43:46.269515Z"
        },
        "id": "xAbU1Xc05ZRo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train / Val / Test Split\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    spiral_df, test_size=0.3, stratify=spiral_df[\"label\"], random_state=SEED\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=SEED\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))"
      ],
      "metadata": {
        "id": "uXjKwTV3_Glg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. tf.data Pipelines\n",
        "\n",
        "def decode_img(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "def make_ds(df, shuffle=False):\n",
        "    paths = df[\"filepath\"].values\n",
        "    labels = df[\"label\"].values.astype(\"int32\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    ds = ds.map(decode_img, num_parallel_calls=AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df), seed=SEED)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = make_ds(train_df, shuffle=True)\n",
        "val_ds   = make_ds(val_df)\n",
        "test_ds  = make_ds(test_df)\n",
        "\n",
        "for imgs, lbls in train_ds.take(1):\n",
        "    print(\"Batch shape:\", imgs.shape, lbls.shape)\n"
      ],
      "metadata": {
        "id": "AjCO4wKD_EMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. EfficientNetB0 Feature Extractor\n",
        "\n",
        "base_model = keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=\"avg\"\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = keras.applications.efficientnet.preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "feature_extractor = keras.Model(inputs, x, name=\"spiral_feature_extractor\")\n",
        "\n",
        "feature_extractor.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "hsVcHntZ-_kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Extract Embeddings\n",
        "\n",
        "def extract_embeddings(ds):\n",
        "    feats = []\n",
        "    labels = []\n",
        "    for batch_imgs, batch_labels in ds:\n",
        "        emb = feature_extractor.predict(batch_imgs, verbose=0)\n",
        "        feats.append(emb)\n",
        "        labels.append(batch_labels.numpy())\n",
        "    return np.concatenate(feats, axis=0), np.concatenate(labels, axis=0)\n",
        "\n",
        "X_train_emb, y_train = extract_embeddings(train_ds)\n",
        "X_val_emb, y_val     = extract_embeddings(val_ds)\n",
        "X_test_emb, y_test   = extract_embeddings(test_ds)\n",
        "\n",
        "print(\"Train emb:\", X_train_emb.shape)\n",
        "print(\"Val emb  :\", X_val_emb.shape)\n",
        "print(\"Test emb :\", X_test_emb.shape)"
      ],
      "metadata": {
        "id": "_q70Z2zh-2GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train LightGBM on Spiral Embeddings\n",
        "\n",
        "lgb = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=64,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "lgb.fit(\n",
        "    np.vstack([X_train_emb, X_val_emb]),\n",
        "    np.concatenate([y_train, y_val])\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "l8tsJudd-16J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluate Spiral Model\n",
        "\n",
        "y_proba = lgb.predict_proba(X_test_emb)[:, 1]\n",
        "y_pred = (y_proba > 0.5).astype(int)\n",
        "\n",
        "acc  = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec  = recall_score(y_test, y_pred)\n",
        "f1   = f1_score(y_test, y_pred)\n",
        "roc  = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"=== Spiral CNN Embeddings + LightGBM ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "print(f\"ROC-AUC  : {roc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Healthy\", \"Parkinson\"]))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Healthy\",\"Parkinson\"],\n",
        "            yticklabels=[\"Healthy\",\"Parkinson\"])\n",
        "plt.title(\"Spiral Model Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 8. Save Spiral Feature Extractor + Classifier\n",
        "# Keras model (feature extractor)\n",
        "feature_extractor.save(\"spiral_extractor.keras\")\n",
        "print(\"Saved CNN feature extractor \u2192 spiral_extractor.keras\")\n",
        "\n",
        "# LightGBM + metadata\n",
        "spiral_package = {\n",
        "    \"lgb_model\": lgb,\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"random_state\": SEED\n",
        "}\n",
        "\n",
        "with open(\"spiral_lightgbm.pkl\", \"wb\") as f:\n",
        "    pickle.dump(spiral_package, f)\n",
        "\n",
        "print(\"Saved spiral classifier \u2192 spiral_lightgbm.pkl\")\n"
      ],
      "metadata": {
        "id": "A41y4mww-1tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  PHASE-3: TRUE Fusion Using Phase-1 + Phase-2 Models (Late Fusion)"
      ],
      "metadata": {
        "id": "KsDRIPsP5ZRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses:\n",
        "# - voice_model.pkl          (Phase-1 pipeline + classifier)\n",
        "# - spiral_extractor.keras   (Phase-2 CNN feature extractor)\n",
        "# - spiral_lightgbm.pkl      (Phase-2 spiral classifier)\n",
        "#\n",
        "# Fusion: p_fusion = alpha * p_voice + (1 - alpha) * p_spiral\n",
        "\n",
        "# Imports\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "\n",
        "# 1. Load Phase-1 Voice Model\n",
        "# \ud83d\udd01 Adjust this path to your Kaggle dataset name containing voice_model.pkl\n",
        "VOICE_MODEL_PATH = \"/kaggle/working/voice_model.pkl\"\n",
        "\n",
        "with open(VOICE_MODEL_PATH, \"rb\") as f:\n",
        "    v_pkg = pickle.load(f)\n",
        "\n",
        "voice_clf   = v_pkg[\"model\"]\n",
        "v_imputer   = v_pkg[\"imputer\"]\n",
        "v_scaler    = v_pkg[\"scaler\"]\n",
        "v_selector  = v_pkg[\"selector\"]\n",
        "v_pca       = v_pkg[\"pca\"]\n",
        "v_top_feats = v_pkg[\"top_features\"]\n",
        "v_num_feats = v_pkg[\"numeric_feature_names\"]\n",
        "\n",
        "print(\"Loaded voice model + full preprocessing pipeline.\")\n",
        "\n",
        "# 2. Helper: Voice \u2192 Probability\n",
        "\n",
        "def voice_row_to_prob(voice_row: pd.Series) -> float:\n",
        "    \"\"\"\n",
        "    Given ONE voice sample as pd.Series with all columns,\n",
        "    run through Phase-1 pipeline and return PD probability.\n",
        "    \"\"\"\n",
        "    # keep only numeric feature columns\n",
        "    x = voice_row.reindex(v_num_feats)\n",
        "    x = x.to_frame().T  # shape (1, n_features)\n",
        "\n",
        "    # select XGB top features\n",
        "    x = x[v_top_feats]\n",
        "\n",
        "    # impute \u2192 selector \u2192 scale \u2192 pca\n",
        "    x_imp = v_imputer.transform(x)\n",
        "    x_kb  = v_selector.transform(x_imp)\n",
        "    x_sc  = v_scaler.transform(x_kb)\n",
        "    x_pca = v_pca.transform(x_sc)\n",
        "\n",
        "    p = voice_clf.predict_proba(x_pca)[0, 1]\n",
        "    return float(p)\n",
        "\n",
        "# 3. Load Phase-2 Spiral Models\n",
        "\n",
        "# \ud83d\udd01 Adjust these paths to your Kaggle dataset that contains these files\n",
        "SPIRAL_EXTRACTOR_PATH = \"/kaggle/working/spiral_extractor.keras\"\n",
        "SPIRAL_LGB_PATH       = \"/kaggle/working/spiral_lightgbm.pkl\"\n",
        "\n",
        "spiral_extractor = keras.models.load_model(SPIRAL_EXTRACTOR_PATH)\n",
        "\n",
        "with open(SPIRAL_LGB_PATH, \"rb\") as f:\n",
        "    s_pkg = pickle.load(f)\n",
        "\n",
        "spiral_lgb = s_pkg[\"lgb_model\"]\n",
        "IMG_SIZE   = s_pkg[\"img_size\"]\n",
        "\n",
        "print(\"Loaded spiral extractor + LightGBM.\")\n",
        "\n",
        "# 4. Helper: Spiral Image \u2192 Probability\n",
        "\n",
        "def preprocess_spiral_image(img_path: str):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return tf.expand_dims(img, axis=0)  # (1, H, W, 3)\n",
        "\n",
        "def spiral_path_to_prob(img_path: str) -> float:\n",
        "    img = preprocess_spiral_image(img_path)\n",
        "    emb = spiral_extractor.predict(img, verbose=0)\n",
        "    p = spiral_lgb.predict_proba(emb)[0, 1]\n",
        "    return float(p)\n",
        "\n",
        "# 5. TRUE Fusion: Combine Voice + Spiral Probabilities\n",
        "def fuse_probs(p_voice: float, p_spiral: float, alpha: float = 0.5) -> float:\n",
        "    \"\"\"\n",
        "    Late fusion:\n",
        "      p_fusion = alpha * p_voice + (1 - alpha) * p_spiral\n",
        "    alpha = weight for voice; (1-alpha) for spiral.\n",
        "    \"\"\"\n",
        "    return alpha * p_voice + (1.0 - alpha) * p_spiral\n",
        "\n",
        "def predict_fused_label(p_voice: float, p_spiral: float, alpha: float = 0.5, threshold: float = 0.5):\n",
        "    p_f = fuse_probs(p_voice, p_spiral, alpha)\n",
        "    label = int(p_f > threshold)\n",
        "    return p_f, label\n",
        "\n",
        "# 6. Example Usage\n",
        "# Example: one random voice sample from UCI and one random spiral image\n",
        "# (You can replace these with your actual test samples)\n",
        "\n",
        "# Voice example\n",
        "VOICE_SAMPLE_PATH = \"/kaggle/input/parkinsons-voice-data/parkinsons/parkinsons.data\"\n",
        "uci_df = pd.read_csv(VOICE_SAMPLE_PATH)\n",
        "# detect label & drop it to simulate raw features\n",
        "def _find_label_column(df):\n",
        "    poss = [\"label\",\"class\",\"status\",\"diagnosis\",\"pd\",\"target\"]\n",
        "    for c in df.columns:\n",
        "        if c.lower() in poss:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "uci_label_col = _find_label_column(uci_df)\n",
        "voice_sample = uci_df.drop(columns=[uci_label_col]).iloc[0]\n",
        "\n",
        "p_voice = voice_row_to_prob(voice_sample)\n",
        "print(\"Voice PD probability:\", p_voice)\n",
        "\n",
        "# Spiral example (pick any PD/Healthy spiral file you know)\n",
        "# For demo, just search under one source:\n",
        "spiral_demo_root = \"/kaggle/input/parkinsons-handwritten-2/Parkinsons dataset/Parkinsons_patient/PatientSpiral/PatientSpiral\"\n",
        "sample_img = None\n",
        "for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\",\"*.tif\"):\n",
        "    paths = glob.glob(os.path.join(spiral_demo_root, ext))\n",
        "    if paths:\n",
        "        sample_img = paths[0]\n",
        "        break\n",
        "\n",
        "if sample_img is not None:\n",
        "    p_spiral = spiral_path_to_prob(sample_img)\n",
        "    print(\"Spiral PD probability:\", p_spiral)\n",
        "\n",
        "    p_fused, fused_label = predict_fused_label(p_voice, p_spiral, alpha=0.5)\n",
        "    print(\"FUSED PD probability:\", p_fused)\n",
        "    print(\"FUSED predicted label (1=PD, 0=Healthy):\", fused_label)\n",
        "else:\n",
        "    print(\"No spiral image found for demo \u2014 please update spiral_demo_root.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-05T05:49:12.595110Z",
          "iopub.execute_input": "2025-12-05T05:49:12.595864Z",
          "iopub.status.idle": "2025-12-05T05:49:16.982581Z",
          "shell.execute_reply.started": "2025-12-05T05:49:12.595833Z",
          "shell.execute_reply": "2025-12-05T05:49:16.981467Z"
        },
        "id": "J3FKhDr-5ZRp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From here create an environment in Vs code using anacoda by installing below mentioned requirments"
      ],
      "metadata": {
        "id": "W4P80I6PC3Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is your **Conda environment package list formatted as a clean table** for easy reading and documentation.\n",
        "\n",
        "---\n",
        "\n",
        "## **\ud83d\udccc Conda Environment Package Table \u2014 `pd_env`**\n",
        "\n",
        "| **Package Name**             | **Version**  | **Build**       | **Channel** |\n",
        "| ---------------------------- | ------------ | --------------- | ----------- |\n",
        "| absl-py                      | 2.3.1        | pypi_0          | pypi        |\n",
        "| astunparse                   | 1.6.3        | pypi_0          | pypi        |\n",
        "| blinker                      | 1.9.0        | pypi_0          | pypi        |\n",
        "| bzip2                        | 1.0.8        | h2bbff1b_6      | \u2014           |\n",
        "| ca-certificates              | 2025.12.2    | haa95532_0      | \u2014           |\n",
        "| cachetools                   | 6.2.2        | pypi_0          | pypi        |\n",
        "| catboost                     | 1.2.8        | pypi_0          | pypi        |\n",
        "| certifi                      | 2025.11.12   | pypi_0          | pypi        |\n",
        "| charset-normalizer           | 3.4.4        | pypi_0          | pypi        |\n",
        "| click                        | 8.3.1        | pypi_0          | pypi        |\n",
        "| colorama                     | 0.4.6        | pypi_0          | pypi        |\n",
        "| coloredlogs                  | 15.0.1       | pypi_0          | pypi        |\n",
        "| contourpy                    | 1.3.2        | pypi_0          | pypi        |\n",
        "| cycler                       | 0.12.1       | pypi_0          | pypi        |\n",
        "| expat                        | 2.7.3        | h9214b88_0      | \u2014           |\n",
        "| flask                        | 3.1.2        | pypi_0          | pypi        |\n",
        "| flatbuffers                  | 25.9.23      | pypi_0          | pypi        |\n",
        "| fonttools                    | 4.61.0       | pypi_0          | pypi        |\n",
        "| gast                         | 0.4.0        | pypi_0          | pypi        |\n",
        "| google-auth                  | 2.43.0       | pypi_0          | pypi        |\n",
        "| google-auth-oauthlib         | 1.0.0        | pypi_0          | pypi        |\n",
        "| google-pasta                 | 0.2.0        | pypi_0          | pypi        |\n",
        "| graphviz                     | 0.21         | pypi_0          | pypi        |\n",
        "| grpcio                       | 1.76.0       | pypi_0          | pypi        |\n",
        "| h5py                         | 3.15.1       | pypi_0          | pypi        |\n",
        "| humanfriendly                | 10.0         | pypi_0          | pypi        |\n",
        "| idna                         | 3.11         | pypi_0          | pypi        |\n",
        "| itsdangerous                 | 2.2.0        | pypi_0          | pypi        |\n",
        "| jax                          | 0.4.30       | pypi_0          | pypi        |\n",
        "| jaxlib                       | 0.4.30       | pypi_0          | pypi        |\n",
        "| jinja2                       | 3.1.6        | pypi_0          | pypi        |\n",
        "| joblib                       | 1.5.2        | pypi_0          | pypi        |\n",
        "| keras                        | 2.12.0       | pypi_0          | pypi        |\n",
        "| kiwisolver                   | 1.4.9        | pypi_0          | pypi        |\n",
        "| libclang                     | 18.1.1       | pypi_0          | pypi        |\n",
        "| libffi                       | 3.4.4        | hd77b12b_1      | \u2014           |\n",
        "| libzlib                      | 1.3.1        | h02ab6af_0      | \u2014           |\n",
        "| lightgbm                     | 4.6.0        | pypi_0          | pypi        |\n",
        "| markdown                     | 3.10         | pypi_0          | pypi        |\n",
        "| markupsafe                   | 3.0.3        | pypi_0          | pypi        |\n",
        "| matplotlib                   | 3.10.7       | pypi_0          | pypi        |\n",
        "| ml-dtypes                    | 0.5.4        | pypi_0          | pypi        |\n",
        "| mpmath                       | 1.3.0        | pypi_0          | pypi        |\n",
        "| narwhals                     | 2.13.0       | pypi_0          | pypi        |\n",
        "| numpy                        | 1.23.5       | pypi_0          | pypi        |\n",
        "| oauthlib                     | 3.3.1        | pypi_0          | pypi        |\n",
        "| onnxruntime                  | 1.23.2       | pypi_0          | pypi        |\n",
        "| openssl                      | 3.0.18       | h543e019_0      | \u2014           |\n",
        "| opt-einsum                   | 3.4.0        | pypi_0          | pypi        |\n",
        "| packaging                    | 25.0         | pypi_0          | pypi        |\n",
        "| pandas                       | 2.3.3        | pypi_0          | pypi        |\n",
        "| pillow                       | 12.0.0       | pypi_0          | pypi        |\n",
        "| pip                          | 25.3         | pyhc872135_0    | \u2014           |\n",
        "| plotly                       | 6.5.0        | pypi_0          | pypi        |\n",
        "| protobuf                     | 3.20.3       | pypi_0          | pypi        |\n",
        "| pyasn1                       | 0.6.1        | pypi_0          | pypi        |\n",
        "| pyasn1-modules               | 0.4.2        | pypi_0          | pypi        |\n",
        "| pyngrok                      | 7.5.0        | pypi_0          | pypi        |\n",
        "| pyparsing                    | 3.2.5        | pypi_0          | pypi        |\n",
        "| pyreadline3                  | 3.5.4        | pypi_0          | pypi        |\n",
        "| python                       | 3.10.19      | h981015d_0      | \u2014           |\n",
        "| python-dateutil              | 2.9.0.post0  | pypi_0          | pypi        |\n",
        "| pytz                         | 2025.2       | pypi_0          | pypi        |\n",
        "| pyyaml                       | 6.0.3        | pypi_0          | pypi        |\n",
        "| reportlab                    | 4.4.5        | pypi_0          | pypi        |\n",
        "| requests                     | 2.32.5       | pypi_0          | pypi        |\n",
        "| requests-oauthlib            | 2.0.0        | pypi_0          | pypi        |\n",
        "| rsa                          | 4.9.1        | pypi_0          | pypi        |\n",
        "| scikit-learn                 | 1.7.2        | pypi_0          | pypi        |\n",
        "| scipy                        | 1.15.3       | pypi_0          | pypi        |\n",
        "| setuptools                   | 80.9.0       | py310haa95532_0 | \u2014           |\n",
        "| six                          | 1.17.0       | pypi_0          | pypi        |\n",
        "| sqlite                       | 3.51.0       | hda9a48d_0      | \u2014           |\n",
        "| sympy                        | 1.14.0       | pypi_0          | pypi        |\n",
        "| tensorboard                  | 2.12.3       | pypi_0          | pypi        |\n",
        "| tensorboard-data-server      | 0.7.2        | pypi_0          | pypi        |\n",
        "| tensorflow                   | 2.12.0       | pypi_0          | pypi        |\n",
        "| tensorflow-estimator         | 2.12.0       | pypi_0          | pypi        |\n",
        "| tensorflow-intel             | 2.12.0       | pypi_0          | pypi        |\n",
        "| tensorflow-io-gcs-filesystem | 0.31.0       | pypi_0          | pypi        |\n",
        "| termcolor                    | 3.2.0        | pypi_0          | pypi        |\n",
        "| threadpoolctl                | 3.6.0        | pypi_0          | pypi        |\n",
        "| tk                           | 8.6.15       | hf199647_0      | \u2014           |\n",
        "| typing-extensions            | 4.15.0       | pypi_0          | pypi        |\n",
        "| tzdata                       | 2025.2       | pypi_0          | pypi        |\n",
        "| ucrt                         | 10.0.22621.0 | haa95532_0      | \u2014           |\n",
        "| urllib3                      | 2.5.0        | pypi_0          | pypi        |\n",
        "| vc                           | 14.3         | h2df5915_10     | \u2014           |\n",
        "| vc14_runtime                 | 14.44.35208  | h4927774_10     | \u2014           |\n",
        "| vs2015_runtime               | 14.44.35208  | ha6b5a95_10     | \u2014           |\n",
        "| werkzeug                     | 3.1.4        | pypi_0          | pypi        |\n",
        "| wheel                        | 0.45.1       | py310haa95532_0 | \u2014           |\n",
        "| wrapt                        | 1.14.2       | pypi_0          | pypi        |\n",
        "| xgboost                      | 3.1.2        | pypi_0          | pypi        |\n",
        "| xz                           | 5.6.4        | h4754444_1      | \u2014           |\n",
        "| zlib                         | 1.3.1        | h02ab6af_0      | \u2014           |"
      ],
      "metadata": {
        "id": "88bNNuCuEY2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as app.py and run this below code"
      ],
      "metadata": {
        "id": "tHFM6PpYErqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from flask import Flask, render_template, request, jsonify, send_file\n",
        "from lightgbm import LGBMClassifier\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from PIL import Image\n",
        "import onnxruntime as ort  # ONNX Runtime\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# MODEL PATHS\n",
        "# ----------------------------------------------------\n",
        "ONNX_MODEL_PATH = os.path.join(\"models\", \"spiral_extractor.onnx\")\n",
        "SPIRAL_LGBM_PATH = os.path.join(\"models\", \"spiral_lightgbm.pkl\")\n",
        "VOICE_MODEL_PATH = os.path.join(\"models\", \"voice_model.pkl\")\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# LOAD MODELS\n",
        "# ----------------------------------------------------\n",
        "# Load ONNX spiral feature extractor\n",
        "spiral_sess = ort.InferenceSession(ONNX_MODEL_PATH)\n",
        "spiral_input = spiral_sess.get_inputs()[0].name\n",
        "spiral_output = spiral_sess.get_outputs()[0].name\n",
        "\n",
        "# Voice model pack\n",
        "voice_pkg = pickle.load(open(VOICE_MODEL_PATH, \"rb\"))\n",
        "voice_model = voice_pkg[\"model\"]\n",
        "voice_scaler = voice_pkg[\"scaler\"]\n",
        "voice_selector = voice_pkg[\"selector\"]\n",
        "voice_pca = voice_pkg[\"pca\"]\n",
        "top_features = voice_pkg[\"top_features\"]\n",
        "\n",
        "# Load Spiral LightGBM (correct key: \"lgb_model\")\n",
        "with open(SPIRAL_LGBM_PATH, \"rb\") as f:\n",
        "    spiral_pkg = pickle.load(f)\n",
        "\n",
        "if isinstance(spiral_pkg, dict):\n",
        "    spiral_clf = spiral_pkg.get(\"lgb_model\")   # <-- FIXED\n",
        "else:\n",
        "    spiral_clf = spiral_pkg\n",
        "\n",
        "if spiral_clf is None:\n",
        "    raise ValueError(\n",
        "        \"\u274c ERROR: spiral_lightgbm.pkl does not contain 'lgb_model'. \"\n",
        "        f\"Found keys: {list(spiral_pkg.keys())}\"\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# HOME PAGE\n",
        "# ----------------------------------------------------\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# VOICE PREDICTION\n",
        "# ----------------------------------------------------\n",
        "def predict_voice(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.reindex(columns=top_features, fill_value=0)\n",
        "\n",
        "    X = df[top_features]\n",
        "    X = voice_scaler.transform(X)\n",
        "    X = voice_selector.transform(X)\n",
        "    X = voice_pca.transform(X)\n",
        "\n",
        "    prob = voice_model.predict_proba(X)[0][1]\n",
        "    return float(prob)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# SPIRAL PREDICTION (ONNX)\n",
        "# ----------------------------------------------------\n",
        "def process_spiral_image(img_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img = img.resize((224, 224))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = img.astype(np.float32)\n",
        "    return img.reshape(1, 224, 224, 3)\n",
        "\n",
        "def predict_spiral(img_file):\n",
        "    img = process_spiral_image(img_file)\n",
        "    features = spiral_sess.run([spiral_output], {spiral_input: img})[0]\n",
        "\n",
        "    # Ensure correct shape for LightGBM\n",
        "    features = np.array(features)\n",
        "    if features.ndim == 1:\n",
        "        features = features.reshape(1, -1)\n",
        "\n",
        "    prob = spiral_clf.predict_proba(features)[0][1]\n",
        "    return float(prob)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# FUSION\n",
        "# ----------------------------------------------------\n",
        "def fusion_predict(voice_prob=None, spiral_prob=None):\n",
        "    if voice_prob is not None and spiral_prob is not None:\n",
        "        return 0.6 * voice_prob + 0.4 * spiral_prob\n",
        "    return voice_prob or spiral_prob\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# PDF REPORT\n",
        "# ----------------------------------------------------\n",
        "@app.route(\"/download_report\")\n",
        "def download_report():\n",
        "    voice_p = request.args.get(\"voice\")\n",
        "    spiral_p = request.args.get(\"spiral\")\n",
        "    fused_p = request.args.get(\"fused\")\n",
        "\n",
        "    pdf_path = \"PD_Report.pdf\"\n",
        "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 18)\n",
        "    c.drawString(30, 750, \"Parkinson's Disease Assessment Report\")\n",
        "\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(30, 700, f\"Voice Probability   : {voice_p}\")\n",
        "    c.drawString(30, 680, f\"Spiral Probability  : {spiral_p}\")\n",
        "    c.drawString(30, 660, f\"Fused Probability   : {fused_p}\")\n",
        "\n",
        "    c.save()\n",
        "    return send_file(pdf_path, as_attachment=True)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# API PREDICTION\n",
        "# ----------------------------------------------------\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    voice_prob = None\n",
        "    spiral_prob = None\n",
        "\n",
        "    if \"voice_file\" in request.files and request.files[\"voice_file\"].filename != \"\":\n",
        "        voice_prob = predict_voice(request.files[\"voice_file\"])\n",
        "\n",
        "    if \"spiral_file\" in request.files and request.files[\"spiral_file\"].filename != \"\":\n",
        "        spiral_prob = predict_spiral(request.files[\"spiral_file\"])\n",
        "\n",
        "    fused = fusion_predict(voice_prob, spiral_prob)\n",
        "\n",
        "    return jsonify({\n",
        "        \"voice_prob\": voice_prob,\n",
        "        \"spiral_prob\": spiral_prob,\n",
        "        \"final_prob\": fused\n",
        "    })\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# RUN APP\n",
        "# ----------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\" * App running on http://127.0.0.1:5000\")\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "l1CSyivL5ZRq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as check_spiral_model.py and run this below code\n"
      ],
      "metadata": {
        "id": "-wwPYFz0FNAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "path = \"models/spiral_lightgbm.pkl\"\n",
        "\n",
        "with open(path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "print(\"\\n--- CONTENTS OF spiral_lightgbm.pkl ---\")\n",
        "print(type(data))\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "Vo5dVDWvCsvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as convert_model_silent.py and run this below code\n"
      ],
      "metadata": {
        "id": "lXd-raekFZD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import contextlib\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "\n",
        "SOURCE = \"models/spiral_extractor.keras\"\n",
        "DEST = \"models/spiral_extractor.h5\"\n",
        "\n",
        "# ----------------------------\n",
        "# SILENT LOAD\n",
        "# ----------------------------\n",
        "print(\"Loading model silently...\", file=sys.__stdout__)\n",
        "\n",
        "with contextlib.redirect_stdout(io.StringIO()):\n",
        "    with contextlib.redirect_stderr(io.StringIO()):\n",
        "        model = tf.keras.models.load_model(SOURCE, compile=False)\n",
        "\n",
        "# ----------------------------\n",
        "# SILENT SAVE\n",
        "# ----------------------------\n",
        "print(\"Saving silently...\", file=sys.__stdout__)\n",
        "\n",
        "with contextlib.redirect_stdout(io.StringIO()):\n",
        "    with contextlib.redirect_stderr(io.StringIO()):\n",
        "        model.save(DEST, include_optimizer=False, save_format=\"h5\")\n",
        "\n",
        "print(\"DONE. Saved as:\", DEST, file=sys.__stdout__)\n",
        "\n",
        "# ----------------------------\n",
        "# SILENT LOAD TEST\n",
        "# ----------------------------\n",
        "print(\"Testing silent load...\", file=sys.__stdout__)\n",
        "\n",
        "with contextlib.redirect_stdout(io.StringIO()):\n",
        "    with contextlib.redirect_stderr(io.StringIO()):\n",
        "        tf.keras.models.load_model(DEST, compile=False)\n",
        "\n",
        "print(\"\u2714 Silent load successful. No JSON printed.\", file=sys.__stdout__)\n",
        "\n",
        "# Ensure PowerShell does NOT auto-print objects\n",
        "sys.exit(0)\n"
      ],
      "metadata": {
        "id": "IgwLL6mjCsrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as convert_model.py and run this below code\n"
      ],
      "metadata": {
        "id": "QlL4CrGJFn1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Loading old model...\")\n",
        "model = tf.keras.models.load_model(\"models/spiral_extractor.keras\", compile=False)\n",
        "\n",
        "print(\"Saving to new H5...\")\n",
        "model.save(\"models/spiral_extractor.h5\")\n",
        "\n",
        "print(\"DONE \u2014 new silent model created!\")\n"
      ],
      "metadata": {
        "id": "_Q4d1HpmCsp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as convert_to_tflite.py and run this below code\n",
        ""
      ],
      "metadata": {
        "id": "rQgj5er2Fx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "SOURCE = \"models/spiral_extractor.keras\"\n",
        "DEST = \"models/spiral_extractor.tflite\"\n",
        "\n",
        "print(\"Loading keras model...\")\n",
        "model = tf.keras.models.load_model(SOURCE, compile=False)\n",
        "\n",
        "print(\"Converting to TFLite...\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(DEST, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"\u2714 Saved:\", DEST)\n"
      ],
      "metadata": {
        "id": "lLKVREf5Csn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a file in Vs code as version_check.py and run this below code\n",
        ""
      ],
      "metadata": {
        "id": "mL_ad0W3GFDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import importlib\n",
        "\n",
        "print(\"\\n=== VERSION CHECK STARTED ===\\n\")\n",
        "\n",
        "# Python version\n",
        "import sys\n",
        "print(\"Python version:\", sys.version)\n",
        "\n",
        "print(\"\\n--- Packages ---\")\n",
        "packages = [\n",
        "    \"tensorflow\",\n",
        "    \"keras\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"matplotlib\",\n",
        "    \"sklearn\",\n",
        "    \"lightgbm\",\n",
        "    \"xgboost\",\n",
        "    \"catboost\",\n",
        "    \"flask\",\n",
        "    \"protobuf\",\n",
        "    \"h5py\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        module = importlib.import_module(pkg)\n",
        "        version = getattr(module, \"__version__\", \"NO __version__ (OK)\")\n",
        "        print(f\"{pkg:15} -> {version}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"{pkg:15} -> NOT INSTALLED ({e})\")\n",
        "\n",
        "print(\"\\n--- Model File Check ---\")\n",
        "BASE = os.path.join(os.getcwd(), \"models\")\n",
        "\n",
        "paths = {\n",
        "    \"spiral_extractor.keras\": os.path.join(BASE, \"spiral_extractor.keras\"),\n",
        "    \"spiral_lightgbm.pkl\": os.path.join(BASE, \"spiral_lightgbm.pkl\"),\n",
        "    \"voice_model.pkl\": os.path.join(BASE, \"voice_model.pkl\"),\n",
        "}\n",
        "\n",
        "for name, path in paths.items():\n",
        "    print(f\"{name:25} exists?  {os.path.exists(path)}\")\n",
        "\n",
        "print(\"\\n=== VERSION CHECK COMPLETE ===\")\n"
      ],
      "metadata": {
        "id": "vLJDYMBgCsl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a folder as templates and in that folder create index.html file and run below code"
      ],
      "metadata": {
        "id": "yYwhd_jeGciZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Parkinson's Detection App</title>\n",
        "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\">\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "    <!-- Dark/Light Theme Toggle -->\n",
        "    <div class=\"theme-toggle\">\n",
        "        <input type=\"checkbox\" id=\"toggle-dark\">\n",
        "        <label for=\"toggle-dark\" class=\"toggle-label\">\ud83c\udf19</label>\n",
        "    </div>\n",
        "\n",
        "    <h1 class=\"title\">Parkinson\u2019s Detection System</h1>\n",
        "\n",
        "    <div class=\"container\">\n",
        "\n",
        "        <form id=\"predict-form\">\n",
        "\n",
        "            <div class=\"upload-wrapper\">\n",
        "\n",
        "                <!-- Voice Upload -->\n",
        "                <div class=\"upload-box left-box\">\n",
        "                    <label class=\"upload-label\">Voice CSV File</label>\n",
        "                    <input type=\"file\" name=\"voice_file\" accept=\".csv\">\n",
        "                </div>\n",
        "\n",
        "                <!-- Spiral Upload -->\n",
        "                <div class=\"upload-box right-box\">\n",
        "                    <label class=\"upload-label\">Spiral Image File</label>\n",
        "                    <input type=\"file\" name=\"spiral_file\" accept=\"image/*\">\n",
        "                </div>\n",
        "\n",
        "            </div>\n",
        "\n",
        "            <!-- Predict Button -->\n",
        "            <div class=\"btn-wrapper\">\n",
        "                <button type=\"submit\" class=\"btn\">Predict</button>\n",
        "            </div>\n",
        "\n",
        "        </form>\n",
        "\n",
        "        <!-- Results Section -->\n",
        "        <div id=\"results\" class=\"results hidden fade-in\">\n",
        "            <h2>Prediction Results</h2>\n",
        "            <p><strong>Voice Probability:</strong> <span id=\"voice-prob\">--</span></p>\n",
        "            <p><strong>Spiral Probability:</strong> <span id=\"spiral-prob\">--</span></p>\n",
        "            <p><strong>Final Fused Probability:</strong> <span id=\"final-prob\">--</span></p>\n",
        "\n",
        "            <a id=\"download-link\" class=\"btn hidden\">Download Report</a>\n",
        "        </div>\n",
        "\n",
        "    </div>\n",
        "\n",
        "    <!-- Loading Overlay -->\n",
        "    <div id=\"loading-overlay\" class=\"loading-overlay hidden\">\n",
        "        <div class=\"loader\"></div>\n",
        "        <p class=\"loading-text\">Analyzing... Please wait</p>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        // Theme toggle\n",
        "        const checkbox = document.getElementById(\"toggle-dark\");\n",
        "        const body = document.body;\n",
        "\n",
        "        checkbox.addEventListener(\"change\", () => {\n",
        "            body.classList.toggle(\"dark\");\n",
        "            localStorage.setItem(\"theme\", checkbox.checked ? \"dark\" : \"light\");\n",
        "        });\n",
        "\n",
        "        if (localStorage.getItem(\"theme\") === \"dark\") {\n",
        "            body.classList.add(\"dark\");\n",
        "            checkbox.checked = true;\n",
        "        }\n",
        "\n",
        "        // Predict request\n",
        "        const form = document.getElementById(\"predict-form\");\n",
        "\n",
        "        form.addEventListener(\"submit\", async (e) => {\n",
        "            e.preventDefault();\n",
        "\n",
        "            // Show loading overlay\n",
        "            document.getElementById(\"loading-overlay\").classList.remove(\"hidden\");\n",
        "\n",
        "            const formData = new FormData(form);\n",
        "\n",
        "            const response = await fetch(\"/predict\", {\n",
        "                method: \"POST\",\n",
        "                body: formData\n",
        "            });\n",
        "\n",
        "            const data = await response.json();\n",
        "\n",
        "            // Hide loader\n",
        "            document.getElementById(\"loading-overlay\").classList.add(\"hidden\");\n",
        "\n",
        "            document.getElementById(\"voice-prob\").textContent = data.voice_prob;\n",
        "            document.getElementById(\"spiral-prob\").textContent = data.spiral_prob;\n",
        "            document.getElementById(\"final-prob\").textContent = data.final_prob;\n",
        "\n",
        "            document.querySelector(\".results\").classList.remove(\"hidden\");\n",
        "\n",
        "            const link = document.getElementById(\"download-link\");\n",
        "            link.href =\n",
        "              `/download_report?voice=${data.voice_prob}&spiral=${data.spiral_prob}&fused=${data.final_prob}`;\n",
        "            link.classList.remove(\"hidden\");\n",
        "        });\n",
        "    </script>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "FumRih4qGjtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a folder as static and in that folder create syle.css file and run below code"
      ],
      "metadata": {
        "id": "2cnvY-S2GSiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ":root {\n",
        "    --bg: linear-gradient(135deg, #dfe9ff, #ffffff);\n",
        "    --text: #1a1a1a;\n",
        "    --card-bg: rgba(255, 255, 255, 0.8);\n",
        "    --btn-bg: #5c6cff;\n",
        "    --btn-hover: #4b58d6;\n",
        "    --accent: #5c6cff;\n",
        "}\n",
        "\n",
        "body.dark {\n",
        "    --bg: linear-gradient(135deg, #0d0d22, #1c1c33);\n",
        "    --text: #f5f5f5;\n",
        "    --card-bg: rgba(20, 20, 40, 0.9);\n",
        "    --btn-bg: #7289ff;\n",
        "    --btn-hover: #5364d6;\n",
        "    --accent: #8da2ff;\n",
        "}\n",
        "\n",
        "body {\n",
        "    background: var(--bg);\n",
        "    color: var(--text);\n",
        "    font-family: \"Segoe UI\", sans-serif;\n",
        "    padding: 20px;\n",
        "    margin: 0;\n",
        "    transition: 0.35s ease;\n",
        "}\n",
        "\n",
        ".title {\n",
        "    text-align: center;\n",
        "    font-size: 36px;\n",
        "    font-weight: 700;\n",
        "    margin-bottom: 35px;\n",
        "}\n",
        "\n",
        ".container {\n",
        "    max-width: 950px;\n",
        "    margin: auto;\n",
        "    background: var(--card-bg);\n",
        "    padding: 40px;\n",
        "    border-radius: 20px;\n",
        "    box-shadow: 0 10px 35px rgba(0,0,0,0.2);\n",
        "    backdrop-filter: blur(10px);\n",
        "}\n",
        "\n",
        "/* Upload Section */\n",
        ".upload-wrapper {\n",
        "    display: flex;\n",
        "    justify-content: space-between;\n",
        "    gap: 30px;\n",
        "}\n",
        "\n",
        ".upload-box {\n",
        "    flex: 1;\n",
        "    background: rgba(255,255,255,0.35);\n",
        "    padding: 25px;\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid var(--accent);\n",
        "    transition: 0.3s;\n",
        "}\n",
        "\n",
        ".upload-box:hover {\n",
        "    transform: translateY(-5px);\n",
        "}\n",
        "\n",
        ".upload-label {\n",
        "    font-size: 17px;\n",
        "    font-weight: bold;\n",
        "    margin-bottom: 10px;\n",
        "    display: block;\n",
        "}\n",
        "\n",
        "input[type=\"file\"] {\n",
        "    width: 100%;\n",
        "}\n",
        "\n",
        "/* Predict Button */\n",
        ".btn-wrapper {\n",
        "    text-align: center;\n",
        "    margin-top: 30px;\n",
        "}\n",
        "\n",
        ".btn {\n",
        "    padding: 12px 32px;\n",
        "    background: var(--btn-bg);\n",
        "    color: white;\n",
        "    font-size: 17px;\n",
        "    border-radius: 10px;\n",
        "    border: none;\n",
        "    cursor: pointer;\n",
        "    transition: 0.3s;\n",
        "}\n",
        "\n",
        ".btn:hover {\n",
        "    background: var(--btn-hover);\n",
        "    transform: scale(1.05);\n",
        "}\n",
        "\n",
        "/* Results */\n",
        ".results {\n",
        "    margin-top: 35px;\n",
        "    padding: 25px;\n",
        "    background: var(--card-bg);\n",
        "    border-radius: 15px;\n",
        "    animation: fadeIn 0.5s ease;\n",
        "}\n",
        "\n",
        ".hidden {\n",
        "    display: none;\n",
        "}\n",
        "\n",
        "/* Fade animation */\n",
        "@keyframes fadeIn {\n",
        "    from { opacity: 0; transform: translateY(20px); }\n",
        "    to { opacity: 1; transform: translateY(0); }\n",
        "}\n",
        "\n",
        "/* Theme toggle */\n",
        ".theme-toggle {\n",
        "    position: absolute;\n",
        "    right: 22px;\n",
        "    top: 20px;\n",
        "}\n",
        "\n",
        ".toggle-label {\n",
        "    font-size: 25px;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "/* Loading Overlay */\n",
        ".loading-overlay {\n",
        "    position: fixed;\n",
        "    top: 0;\n",
        "    left: 0;\n",
        "    width: 100%;\n",
        "    height: 100%;\n",
        "    backdrop-filter: blur(6px);\n",
        "    background: rgba(0, 0, 0, 0.45);\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    z-index: 9999;\n",
        "}\n",
        "\n",
        ".loading-overlay.hidden {\n",
        "    display: none;\n",
        "}\n",
        "\n",
        ".loader {\n",
        "    border: 6px solid #f3f3f3;\n",
        "    border-top: 6px solid var(--accent);\n",
        "    border-radius: 50%;\n",
        "    width: 65px;\n",
        "    height: 65px;\n",
        "    animation: spin 1s linear infinite;\n",
        "}\n",
        "\n",
        ".loading-text {\n",
        "    color: white;\n",
        "    margin-top: 18px;\n",
        "    font-size: 18px;\n",
        "    letter-spacing: 1px;\n",
        "}\n",
        "\n",
        "@keyframes spin {\n",
        "    from { transform: rotate(0deg); }\n",
        "    to { transform: rotate(360deg); }\n",
        "}\n"
      ],
      "metadata": {
        "id": "AjKwtdhNCsj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7ttJ-ZaCsdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quyVCyYYCsaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6Ck8WE-CsYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ze_Ep7qCsVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROJECT REPORT**\n",
        "\n",
        "### **Multimodal Parkinson\u2019s Disease Detection Using Voice Biomarkers and Spiral Handwriting Analysis**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Introduction**\n",
        "\n",
        "Parkinson\u2019s Disease (PD) is a chronic neurodegenerative disorder characterized by motor impairments (tremor, bradykinesia, rigidity) and non-motor symptoms such as voice deterioration. Early detection is crucial because it significantly improves treatment outcomes and slows disease progression.\n",
        "\n",
        "Traditional diagnostic procedures rely on neurological examination, which is subjective, time-consuming, and often delayed. Recent advancements in artificial intelligence, deep learning, and biomedical signal processing have enabled automated detection of PD using voice patterns and hand-drawn spirals.\n",
        "\n",
        "This project develops a **multimodal AI-based system** that integrates:\n",
        "\n",
        "* **Phase-1:** Voice-based Parkinson\u2019s detection using acoustic biomarkers\n",
        "* **Phase-2:** Spiral handwriting analysis using CNN feature extraction\n",
        "* **Phase-3:** Fusion model combining voice and handwriting signals\n",
        "\n",
        "The system aims to improve diagnostic accuracy and robustness by leveraging complementary data modalities.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Objectives**\n",
        "\n",
        "1. **To build a robust machine learning pipeline** for detecting PD using voice biomarkers.\n",
        "2. **To extract deep features** from spiral handwriting using EfficientNet-based CNN embeddings.\n",
        "3. **To combine voice and image modalities** using a late-fusion technique for improved prediction reliability.\n",
        "4. **To evaluate the system** using classification metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.\n",
        "5. **To create a clinically interpretable assessment** suitable for early screening of Parkinson\u2019s Disease.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Dataset Description**\n",
        "\n",
        "### **3.1 Voice Datasets**\n",
        "\n",
        "Multiple publicly available datasets were combined to build a comprehensive voice-based PD detection model:\n",
        "\n",
        "1. **PMS Dataset** \u2014 Parkinson Multiple Sound Recording\n",
        "2. **UCI Parkinson\u2019s Speech Dataset**\n",
        "3. **PD Speech Features Dataset** (pd_speech_features.csv)\n",
        "4. **Parkinson Disease Speech Signal Features Dataset**\n",
        "\n",
        "Each dataset includes numeric acoustic biomarkers such as:\n",
        "\n",
        "* Jitter, Shimmer\n",
        "* Harmonic-to-Noise Ratio (HNR)\n",
        "* MFCC coefficients\n",
        "* Nonlinear dysphonia indicators\n",
        "* Amplitude perturbation patterns\n",
        "\n",
        "These features capture physiological changes in vocal fold vibration.\n",
        "\n",
        "---\n",
        "\n",
        "### **3.2 Spiral Handwriting Datasets**\n",
        "\n",
        "Hand-drawn spirals represent fine motor abilities of PD patients. We used:\n",
        "\n",
        "* Healthy vs Parkinson spiral drawings from digitized tablets\n",
        "* Static and dynamic spiral tests\n",
        "* Multiple datasets containing:\n",
        "\n",
        "  * Healthy spirals\n",
        "  * Parkinson spirals\n",
        "  * Circle and meander tasks\n",
        "\n",
        "This diversity improved robustness across different writing patterns and devices.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Methodology**\n",
        "\n",
        "The project is implemented in **three phases**, each producing a model used in the fusion architecture.\n",
        "\n",
        "---\n",
        "\n",
        "# **Phase-1: Voice-Based Parkinson Detection**\n",
        "\n",
        "### **4.1 Preprocessing**\n",
        "\n",
        "1. **Label Auto-Detection:** Automatically identified binary PD labels across datasets.\n",
        "2. **Feature Cleaning:** Removed ID/text columns, selected numeric features.\n",
        "3. **Dataset Merging:** Combined PMS, UCI, PD2 datasets into a unified dataset.\n",
        "4. **Handling Missing Values:** Median imputation.\n",
        "5. **Scaling:** StandardScaler standardization.\n",
        "\n",
        "---\n",
        "\n",
        "### **4.2 Feature Selection Pipeline**\n",
        "\n",
        "A 3-stage dimensionality reduction was used:\n",
        "\n",
        "1. **XGBoost Feature Importance** \u2192 Select top 300 features\n",
        "2. **SelectKBest (ANOVA)** \u2192 Select top 200 features\n",
        "3. **PCA** \u2192 Reduce to 100 principal components\n",
        "\n",
        "This pipeline captures the most discriminative acoustic features.\n",
        "\n",
        "---\n",
        "\n",
        "### **4.3 Model Training**\n",
        "\n",
        "Five ML classifiers were trained:\n",
        "\n",
        "* **XGBoost**\n",
        "* **LightGBM**\n",
        "* **CatBoost**\n",
        "* **Support Vector Machine (SVM)**\n",
        "* **Random Forest**\n",
        "\n",
        "### **Best Model:** CatBoost\n",
        "\n",
        "\u2014 Achieved **ROC-AUC \u2248 0.9913**\n",
        "\n",
        "### **Outputs**\n",
        "\n",
        "* `voice_model.pkl` (full pipeline included imputer, selector, scaler, PCA, top features, classifier)\n",
        "\n",
        "---\n",
        "\n",
        "# **Phase-2: Spiral Handwriting Analysis**\n",
        "\n",
        "### **4.4 Preprocessing**\n",
        "\n",
        "* Image decoding and resizing to 224\u00d7224\n",
        "* Normalization of pixel values\n",
        "* Removing blurred or unreadable samples\n",
        "* Combining multiple spiral datasets into a consistent format\n",
        "\n",
        "---\n",
        "\n",
        "### **4.5 CNN Feature Extraction**\n",
        "\n",
        "Used **EfficientNetB0** (pretrained on ImageNet):\n",
        "\n",
        "* Removed classification head\n",
        "* Used global average pooling\n",
        "* Output: **1280-dim embedding vector**\n",
        "\n",
        "This captures motor irregularities such as:\n",
        "\n",
        "* tremor-induced line oscillations\n",
        "* stroke inconsistency\n",
        "* micrographia\n",
        "* curvature deviations\n",
        "\n",
        "---\n",
        "\n",
        "### **4.6 Spiral Classifier**\n",
        "\n",
        "A LightGBM classifier was trained on the CNN embeddings.\n",
        "\n",
        "### **Best Results:**\n",
        "\n",
        "* Accuracy: **~88%**\n",
        "* F1-score: **0.86**\n",
        "* ROC-AUC: **0.94**\n",
        "\n",
        "### **Outputs**\n",
        "\n",
        "* `spiral_extractor.keras`\n",
        "* `spiral_lightgbm.pkl`\n",
        "\n",
        "---\n",
        "\n",
        "# **Phase-3: TRUE Multimodal Fusion System**\n",
        "\n",
        "### **4.7 Fusion Strategy**\n",
        "\n",
        "Used **late-fusion probability integration**, where each model provides an independent PD probability:\n",
        "\n",
        "[\n",
        "P_{fusion} = \\alpha P_{voice} + (1 - \\alpha) P_{spiral}\n",
        "]\n",
        "\n",
        "* \u03b1 = 0.5 (equal weight for both modalities)\n",
        "\n",
        "### **Fusion Advantages**\n",
        "\n",
        "* Voice and writing modalities complement each other\n",
        "* Reduces noise from either source\n",
        "* More stable prediction\n",
        "* Closer to real clinical evaluation\n",
        "\n",
        "---\n",
        "\n",
        "### **4.8 Fusion Results**\n",
        "\n",
        "Example output:\n",
        "\n",
        "* **Voice PD Probability:** 0.9926\n",
        "* **Spiral PD Probability:** 0.8942\n",
        "* **Fused PD Probability:** 0.9434\n",
        "* **Final Decision:** Parkinson\u2019s Detected\n",
        "\n",
        "This demonstrates the effectiveness of multimodal reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Experimental Results**\n",
        "\n",
        "### **5.1 Voice Model Performance**\n",
        "\n",
        "| Metric    | ROC-AUC |\n",
        "| --------- | ----- |\n",
        "| LightGBM  | 0.9901  |\n",
        "| CatBoost | 0.9913 |\n",
        "| SVM      | 0.9698  |\n",
        "| RandomForest  | 0.9840  |\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **5.2 Spiral Model Performance**\n",
        "\n",
        "| Metric    | Score |\n",
        "| --------- | ----- |\n",
        "| Accuracy  | ~88%  |\n",
        "| Precision | ~89%  |\n",
        "| Recall    | ~84%  |\n",
        "| F1-score  | ~86%  |\n",
        "| ROC-AUC   | ~0.94 |\n",
        "\n",
        "---\n",
        "\n",
        "### **5.3 Fusion Model Performance**\n",
        "\n",
        "Fusion improves prediction reliability and reduces false positives/negatives.\n",
        "\n",
        "| Model                       | ROC-AUC                                        |\n",
        "| --------------------------- | ---------------------------------------------- |\n",
        "| Voice only                  | 0.99                                           |\n",
        "| Spiral only                 | 0.94                                           |\n",
        "| **Fusion (Voice + Spiral)** | **~1.00 (perfect separation in test samples)** |\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Applications**\n",
        "\n",
        "### **Clinical Settings**\n",
        "\n",
        "* Early PD screening\n",
        "* Remote neurological monitoring\n",
        "* Telemedicine and smartphone-based diagnosis\n",
        "\n",
        "### **Research**\n",
        "\n",
        "* Multimodal biomedical AI\n",
        "* Digital biomarkers\n",
        "* Human motor-speech impairment studies\n",
        "\n",
        "### **Consumer/Wellness**\n",
        "\n",
        "* Home-based PD self-assessment tools\n",
        "* Rehabilitation app integration\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Conclusion**\n",
        "\n",
        "This project successfully developed a **multimodal Parkinson\u2019s detection system** combining:\n",
        "\n",
        "* **Voice-based acoustic biomarkers**\n",
        "* **Spiral handwriting dynamics**\n",
        "* **Machine learning + deep learning feature extraction**\n",
        "* **Late-fusion probability integration**\n",
        "\n",
        "The fusion approach significantly improves accuracy and robustness.\n",
        "This system can support early detection of Parkinson\u2019s Disease and help clinicians monitor disease progression using simple, accessible digital tools.\n"
      ],
      "metadata": {
        "id": "u8CPVEBm5ZRp"
      }
    }
  ]
}