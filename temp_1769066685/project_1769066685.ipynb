{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6b4bReGRUZb"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ad06dTbRbwg"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok opencv-python pillow torch torchvision \\\n",
        "    git+https://github.com/openai/CLIP.git \\\n",
        "    git+https://github.com/facebookresearch/segment-anything.git \\\n",
        "    tf2onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p anomaly_ui/templates\n",
        "!mkdir -p anomaly_ui/static\n",
        "!mkdir -p anomaly_ui/uploads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile anomaly_ui/templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<title>Industrial Anomaly Detection</title>\n",
        "\n",
        "<style>\n",
        "body {\n",
        "    font-family: Segoe UI, Arial, sans-serif;\n",
        "    background: #f4f6f9;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        ".header {\n",
        "    background: #111827;\n",
        "    color: white;\n",
        "    padding: 16px;\n",
        "    text-align: center;\n",
        "    font-size: 22px;\n",
        "}\n",
        "\n",
        ".container {\n",
        "    max-width: 1200px;\n",
        "    margin: 30px auto;\n",
        "    background: white;\n",
        "    padding: 25px;\n",
        "    border-radius: 8px;\n",
        "    box-shadow: 0 12px 28px rgba(0,0,0,0.12);\n",
        "}\n",
        "\n",
        ".upload-box {\n",
        "    border: 2px dashed #cbd5e1;\n",
        "    padding: 30px;\n",
        "    text-align: center;\n",
        "    border-radius: 6px;\n",
        "}\n",
        "\n",
        ".file-name {\n",
        "    margin-top: 10px;\n",
        "    color: #2563eb;\n",
        "    font-weight: 500;\n",
        "}\n",
        "\n",
        "button {\n",
        "    background: #2563eb;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    padding: 12px 24px;\n",
        "    border-radius: 6px;\n",
        "    font-size: 15px;\n",
        "    cursor: pointer;\n",
        "    margin-top: 15px;\n",
        "}\n",
        "\n",
        "button:disabled {\n",
        "    background: #94a3b8;\n",
        "    cursor: not-allowed;\n",
        "}\n",
        "\n",
        ".results {\n",
        "    display: grid;\n",
        "    grid-template-columns: 1fr 1fr;\n",
        "    gap: 25px;\n",
        "    margin-top: 25px;\n",
        "}\n",
        "\n",
        ".card {\n",
        "    border: 1px solid #e5e7eb;\n",
        "    padding: 18px;\n",
        "    border-radius: 6px;\n",
        "}\n",
        "\n",
        ".defect { color: #dc2626; font-weight: bold; }\n",
        ".normal { color: #16a34a; font-weight: bold; }\n",
        "\n",
        "img {\n",
        "    width: 100%;\n",
        "    border-radius: 6px;\n",
        "    border: 1px solid #e5e7eb;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "<div class=\"header\">\n",
        "YOLO + SAM + CLIP \u2014 Industrial Anomaly Detection\n",
        "</div>\n",
        "\n",
        "<div class=\"container\">\n",
        "\n",
        "<form method=\"POST\" enctype=\"multipart/form-data\" onsubmit=\"return validateForm()\">\n",
        "    <div class=\"upload-box\">\n",
        "        <h3>Select Product Image</h3>\n",
        "\n",
        "        <input type=\"file\" id=\"imageInput\" name=\"image\" accept=\"image/*\" required>\n",
        "\n",
        "        <div class=\"file-name\" id=\"fileName\">No file selected</div>\n",
        "\n",
        "        <button id=\"analyzeBtn\" type=\"submit\" disabled>Analyze Image</button>\n",
        "    </div>\n",
        "</form>\n",
        "\n",
        "{% if score is not none %}\n",
        "<div class=\"results\">\n",
        "\n",
        "    <div class=\"card\">\n",
        "        <h3>Detection Result</h3>\n",
        "        <p>Status:\n",
        "            <span class=\"{{ 'defect' if status=='DEFECT' else 'normal' }}\">\n",
        "                {{ status }}\n",
        "            </span>\n",
        "        </p>\n",
        "        <p>Anomaly Score: <b>{{ score }}</b></p>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"card\">\n",
        "        <h3>Segmentation Result</h3>\n",
        "        <img src=\"{{ url_for('static', filename='after.png') }}\">\n",
        "    </div>\n",
        "\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "const input = document.getElementById(\"imageInput\");\n",
        "const fileName = document.getElementById(\"fileName\");\n",
        "const button = document.getElementById(\"analyzeBtn\");\n",
        "\n",
        "input.addEventListener(\"change\", () => {\n",
        "    if (input.files.length > 0) {\n",
        "        fileName.innerText = input.files[0].name;\n",
        "        button.disabled = false;\n",
        "    } else {\n",
        "        fileName.innerText = \"No file selected\";\n",
        "        button.disabled = true;\n",
        "    }\n",
        "});\n",
        "\n",
        "function validateForm() {\n",
        "    if (input.files.length === 0) {\n",
        "        alert(\"Please select an image before analyzing.\");\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile anomaly_ui/app.py\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, request\n",
        "from werkzeug.utils import secure_filename\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# =====================================================\n",
        "# PATHS & CONFIG\n",
        "# =====================================================\n",
        "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "UPLOAD_FOLDER = os.path.join(BASE_DIR, \"uploads\")\n",
        "STATIC_FOLDER = os.path.join(BASE_DIR, \"static\")\n",
        "TEMPLATE_FOLDER = os.path.join(BASE_DIR, \"templates\")\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(STATIC_FOLDER, exist_ok=True)\n",
        "\n",
        "# =====================================================\n",
        "# FLASK APP\n",
        "# =====================================================\n",
        "app = Flask(\n",
        "    __name__,\n",
        "    static_folder=STATIC_FOLDER,\n",
        "    template_folder=TEMPLATE_FOLDER\n",
        ")\n",
        "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
        "\n",
        "# =====================================================\n",
        "# LOAD MODELS\n",
        "# =====================================================\n",
        "\n",
        "# ---- YOLO (for box prompt)\n",
        "yolo = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "# ---- CLIP\n",
        "clip_model, _ = clip.load(\"ViT-L/14\", device=DEVICE)\n",
        "clip_model.eval()\n",
        "\n",
        "# ---- SAM\n",
        "SAM_CKPT = os.path.join(BASE_DIR, \"sam_vit_h_4b8939.pth\")\n",
        "if not os.path.exists(SAM_CKPT):\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(\n",
        "        \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
        "        SAM_CKPT\n",
        "    )\n",
        "\n",
        "sam = sam_model_registry[\"vit_h\"](checkpoint=SAM_CKPT)\n",
        "sam.to(DEVICE)\n",
        "sam.eval()\n",
        "sam_predictor = SamPredictor(sam)\n",
        "\n",
        "# =====================================================\n",
        "# UTILS\n",
        "# =====================================================\n",
        "def get_yolo_box(img):\n",
        "    results = yolo.predict(img, conf=0.3, verbose=False)\n",
        "    if len(results[0].boxes) == 0:\n",
        "        return None\n",
        "    box = results[0].boxes[0].xyxy[0].cpu().numpy()\n",
        "    return box.astype(int)\n",
        "\n",
        "def smooth_mask(mask):\n",
        "    kernel = np.ones((7,7), np.uint8)\n",
        "    mask = mask.astype(np.uint8) * 255\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    return mask > 0\n",
        "\n",
        "def refine_edges(mask):\n",
        "    edges = cv2.Canny(mask.astype(np.uint8)*255, 100, 200)\n",
        "    return edges\n",
        "\n",
        "def overlay_mask(img, mask, color=(255,0,0)):\n",
        "    overlay = img.copy()\n",
        "    overlay[mask] = color\n",
        "    return overlay\n",
        "\n",
        "# =====================================================\n",
        "# CLIP FEATURE\n",
        "# =====================================================\n",
        "def extract_clip_feature(img):\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    img = img.astype(np.float32)/255.0\n",
        "    mean = np.array([0.48145466, 0.4578275, 0.40821073])\n",
        "    std  = np.array([0.26862954, 0.26130258, 0.27577711])\n",
        "    img = (img - mean) / std\n",
        "    img = np.transpose(img, (2,0,1))\n",
        "    tensor = torch.tensor(img).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        feat = clip_model.encode_image(tensor)\n",
        "        feat = feat / feat.norm(dim=-1, keepdim=True)\n",
        "    return feat\n",
        "\n",
        "# =====================================================\n",
        "# PATCH EXTRACTION\n",
        "# =====================================================\n",
        "def extract_patches(img, mask, size=64, stride=32):\n",
        "    patches = []\n",
        "    h, w, _ = img.shape\n",
        "    for y in range(0, h-size, stride):\n",
        "        for x in range(0, w-size, stride):\n",
        "            if mask[y:y+size, x:x+size].mean() < 0.05:\n",
        "                continue\n",
        "            patches.append(img[y:y+size, x:x+size])\n",
        "    if not patches:\n",
        "        patches.append(img[h//2-size:h//2+size, w//2-size:w//2+size])\n",
        "    return patches\n",
        "\n",
        "# =====================================================\n",
        "# ROUTE\n",
        "# =====================================================\n",
        "@app.route(\"/\", methods=[\"GET\",\"POST\"])\n",
        "def index():\n",
        "    score, status = None, None\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files[\"image\"]\n",
        "        filename = secure_filename(file.filename)\n",
        "        path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "        file.save(path)\n",
        "\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ---------- BEFORE (Unguided SAM)\n",
        "        sam_predictor.set_image(img)\n",
        "        raw_masks, _, _ = sam_predictor.predict(multimask_output=True)\n",
        "        raw_mask = max(raw_masks, key=lambda x: x.sum())\n",
        "\n",
        "        # ---------- YOLO-GUIDED SAM\n",
        "        box = get_yolo_box(img)\n",
        "        if box is not None:\n",
        "            masks, _, _ = sam_predictor.predict(\n",
        "                box=box,\n",
        "                multimask_output=False\n",
        "            )\n",
        "            mask = masks[0]\n",
        "        else:\n",
        "            mask = raw_mask\n",
        "\n",
        "        # ---------- SMOOTH + REFINE\n",
        "        smooth = smooth_mask(mask)\n",
        "        edges = refine_edges(smooth)\n",
        "\n",
        "        # ---------- VISUALS\n",
        "        before = overlay_mask(img, raw_mask)\n",
        "        after = overlay_mask(img, smooth)\n",
        "\n",
        "        cv2.imwrite(\n",
        "            os.path.join(STATIC_FOLDER, \"before.png\"),\n",
        "            cv2.cvtColor(before, cv2.COLOR_RGB2BGR)\n",
        "        )\n",
        "        cv2.imwrite(\n",
        "            os.path.join(STATIC_FOLDER, \"after.png\"),\n",
        "            cv2.cvtColor(after, cv2.COLOR_RGB2BGR)\n",
        "        )\n",
        "\n",
        "        # ---------- ANOMALY SCORE\n",
        "        patches = extract_patches(img, smooth)\n",
        "        sims = [extract_clip_feature(p).mean().item() for p in patches]\n",
        "        score = round(float(np.mean(sims)), 3)\n",
        "        status = \"DEFECT\" if score > 1.8 else \"NORMAL\"\n",
        "\n",
        "    return render_template(\"index.html\", score=score, status=status)\n",
        "\n",
        "# =====================================================\n",
        "# MAIN\n",
        "# =====================================================\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 6\ufe0f\u20e3 Kill any previous processes\n",
        "# ===============================\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!lsof -i :5000 || echo \"Port 5000 is free\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kill -9 8882"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 7\ufe0f\u20e3 Run Flask in the background\n",
        "# ===============================\n",
        "!nohup python anomaly_ui/app.py > flask.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 8\ufe0f\u20e3 Start ngrok tunnel\n",
        "# ===============================\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "conf.get_default().auth_token = \"replace your token\"\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 9\ufe0f\u20e3 Check logs\n",
        "# ===============================\n",
        "!sleep 3 && tail -n 20 flask.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}