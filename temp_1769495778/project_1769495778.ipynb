{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2844852,
          "sourceType": "datasetVersion",
          "datasetId": 1740766
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# =======================================================\n# Notebook 1 (Corrected) - Early Sepsis Detection - Data Preprocessing\n# Dataset: PhysioNet 2019 (via Kaggle)\n# ======================================================\nimport pandas as pd\nimport numpy as np\nimport glob, os\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# -----------------------------\n# Paths (update if different)\n# -----------------------------\npathA = \"/kaggle/input/prediction-of-sepsis/training_setA/training/\"\npathB = \"/kaggle/input/prediction-of-sepsis/training_setB/training_setB/\"\nfilesA = sorted(glob.glob(os.path.join(pathA, \"*.psv\")))\nfilesB = sorted(glob.glob(os.path.join(pathB, \"*.psv\")))\nall_files = filesA + filesB\n\nprint(f\"Total patients found: {len(all_files)}\")\nassert len(all_files) > 0, \"No patient files found \u2014 check pathA/pathB\"\n\n# -----------------------------\n# 2. Determine global columns to keep (sample subset)\n# -----------------------------\nprint(\"Analyzing global feature coverage across a sample of patients...\")\n\nmissing_ratios = []\nsample_n = min(500, len(all_files))\nfor f in tqdm(all_files[:sample_n]):\n    df = pd.read_csv(f, sep='|')\n    missing_ratios.append(df.isnull().mean())\n\nglobal_missing = pd.concat(missing_ratios, axis=1).mean(axis=1)\n# keep columns that exist in at least 10% of sample patients (i.e. missing < 0.9)\nkeep_cols = global_missing[global_missing < 0.9].index.tolist()\n\n# Ensure label column is present\nif \"SepsisLabel\" not in keep_cols:\n    keep_cols.append(\"SepsisLabel\")\n\nprint(f\"Keeping {len(keep_cols)} columns (including SepsisLabel).\")\n\n# -----------------------------\n# 3. Build consistent arrays\n# -----------------------------\nX_raw, y_raw = [], []\nmax_timesteps = 48  # pad/truncate sequences to 48h\n\nfor f in tqdm(all_files):\n    df = pd.read_csv(f, sep='|')\n\n    # Keep only consistent columns and add missing ones\n    for col in keep_cols:\n        if col not in df.columns:\n            df[col] = np.nan\n    df = df[keep_cols]\n\n    # \u2705 FIX: Only forward-fill to avoid leaking future information.\n    df = df.fillna(method='ffill')\n\n    # After ffill there may still be NaNs at the beginning -> leave them for now\n    label = int(df['SepsisLabel'].max()) if 'SepsisLabel' in df.columns else 0\n    df = df.drop(columns=['SepsisLabel'])\n\n    X_raw.append(df.values.astype(np.float32))\n    y_raw.append(label)\n\nprint(\"\u2705 Loaded raw patient sequences (no backward-fill).\")\n\n# -----------------------------\n# 4. Pad/truncate sequences (so we can split and compute training medians/scaler)\n# -----------------------------\nX_padded = pad_sequences(X_raw, maxlen=max_timesteps, dtype='float32', padding='post', truncating='post')\ny = np.array(y_raw, dtype=np.int64)\n\nprint(\"Shapes before split: X_padded:\", X_padded.shape, \"y:\", y.shape)\n\n# -----------------------------\n# 5. Train/Test split (do this before scaling/imputation using train stats)\n# -----------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X_padded, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(f\"Train patients: {X_train.shape[0]}, Test patients: {X_test.shape[0]}\")\nprint(\"Sepsis % in training set:\", y_train.mean()*100)\n\n# -----------------------------\n# 6. Impute remaining NaNs using training medians (no future-leakage)\n# -----------------------------\n# Compute per-feature median across all (non-padded) values in X_train\nn_train, T, F = X_train.shape\n# mask padded rows (all-zero rows were originally not necessarily zero; but here empty entries are NaN)\n# We'll treat zeros that were present from pad_sequences as 0; we need mask for actual values:\n# Create mask where any non-zero or non-nan in row -> consider valid timesteps\nvalid_mask = ~np.isnan(X_train)  # True where not NaN\n# To compute medians ignoring NaNs and ignoring padded timesteps, flatten and use nanmedian\ntrain_flat = X_train.reshape(-1, F)\nfeat_meds = np.nanmedian(train_flat, axis=0)  # shape (F,)\n# Replace remaining NaNs in both train and test with feature medians\ndef impute_with_median(X, medians):\n    X2 = np.array(X, dtype=np.float32)\n    inds = np.isnan(X2)\n    if inds.any():\n        X2[inds] = np.take(medians, np.where(inds)[2])  # set along feature axis\n    return X2\n\nX_train = impute_with_median(X_train, feat_meds)\nX_test  = impute_with_median(X_test, feat_meds)\nprint(\"\u2705 Imputed remaining NaNs with training-feature medians.\")\n\n# -----------------------------\n# 7. Scale: fit scaler on X_train only (flatten across time)\n# -----------------------------\nscaler = StandardScaler()\nflat_train = X_train.reshape(-1, F)  # (n_train * T, F)\nscaler.fit(flat_train)\n# transform train & test\nX_train = scaler.transform(flat_train).reshape(n_train, T, F)\nX_test  = scaler.transform(X_test.reshape(-1, F)).reshape(X_test.shape[0], T, F)\nprint(\"\u2705 Scaled features using scaler fitted on X_train only.\")\n\n# -----------------------------\n# 8. Save arrays for next notebook (ensure shapes correct)\n# -----------------------------\nprint(\"Final shapes -> X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\nassert X_train.shape[0] == y_train.shape[0]\nassert X_test.shape[0] == y_test.shape[0]\n\nnp.save(\"/kaggle/working/X_train.npy\", X_train)\nnp.save(\"/kaggle/working/X_test.npy\", X_test)\nnp.save(\"/kaggle/working/y_train.npy\", y_train)\nnp.save(\"/kaggle/working/y_test.npy\", y_test)\nprint(\"\u2705 Preprocessing complete and saved to /kaggle/working/\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-18T08:30:47.654465Z",
          "iopub.execute_input": "2025-11-18T08:30:47.654765Z",
          "iopub.status.idle": "2025-11-18T08:38:41.611058Z",
          "shell.execute_reply.started": "2025-11-18T08:30:47.654744Z",
          "shell.execute_reply": "2025-11-18T08:38:41.610352Z"
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "name": "stdout",
          "text": "Total patients found: 40336\nAnalyzing global feature coverage across a sample of patients...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:05<00:00, 87.94it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Keeping 20 columns (including SepsisLabel).\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40336/40336 [07:40<00:00, 87.53it/s] \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u2705 Loaded raw patient sequences (no backward-fill).\nShapes before split: X_padded: (40336, 48, 19) y: (40336,)\nTrain patients: 32268, Test patients: 8068\nSepsis % in training set: 7.270360728895501\n\u2705 Imputed remaining NaNs with training-feature medians.\n\u2705 Scaled features using scaler fitted on X_train only.\nFinal shapes -> X_train: (32268, 48, 19) y_train: (32268,) X_test: (8068, 48, 19) y_test: (8068,)\n\u2705 Preprocessing complete and saved to /kaggle/working/\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# ===============================================================\n# Notebook 2 (Corrected) - Load preprocessed data & train (2H)\n# ===============================================================\nimport os, numpy as np, tensorflow as tf, matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Masking, Conv1D, BatchNormalization, Activation, Dropout,\n    Add, Bidirectional, LSTM, GRU, Dense, Multiply, Lambda,\n    GlobalAveragePooling1D, Reshape, Concatenate\n)\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import (roc_auc_score, precision_recall_curve, auc,\n                             classification_report, confusion_matrix, roc_curve)\n\n# -------------------------\n# 0. Load preprocessed arrays (saved by Notebook 1)\n# -------------------------\nprint(\"Listing files in /kaggle/working/ ...\")\nfor f in sorted(os.listdir(\"/kaggle/working\"))[:20]:\n    print(\" -\", f)\n# change paths if you saved elsewhere\nX_train = np.load(\"/kaggle/working/X_train.npy\")\nX_test  = np.load(\"/kaggle/working/X_test.npy\")\ny_train = np.load(\"/kaggle/working/y_train.npy\")\ny_test  = np.load(\"/kaggle/working/y_test.npy\")\n\n# -------------------------\n# 1. Sanity checks & shapes\n# -------------------------\nprint(\"Shapes after load:\")\nprint(\"X_train:\", X_train.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"X_test :\", X_test.shape)\nprint(\"y_test :\", y_test.shape)\nassert X_train.ndim == 3 and X_test.ndim == 3\nassert y_train.ndim == 1 and y_test.ndim == 1\nassert X_train.shape[0] == y_train.shape[0], \"X_train rows != y_train length\"\nassert X_test.shape[0] == y_test.shape[0],   \"X_test rows != y_test length\"\n\nTIME_STEPS, N_FEATURES = X_train.shape[1], X_train.shape[2]\nprint(f\"TIME_STEPS={TIME_STEPS}, N_FEATURES={N_FEATURES}\")\n\n# -------------------------\n# Reproducibility\n# -------------------------\nSEED = 42\nnp.random.seed(SEED); tf.random.set_seed(SEED)\n\n# -------------------------\n# Bias initializer (dataset base rate)\n# -------------------------\npos_rate = np.clip(y_train.mean(), 1e-6, 1 - 1e-6)\nbias_init = np.log(pos_rate / (1 - pos_rate))\nprint(\"Bias init:\", bias_init)\n\n# -------------------------\n# Define helper layers & blocks (TCN, SE, MHA wrapper)\n# -------------------------\nfrom tensorflow.keras.layers import MultiHeadAttention\n\ndef tcn_res_block(x, filters, kernel_size=3, dilation_rate=1, dropout_rate=0.15):\n    conv = Conv1D(filters, kernel_size, padding='same', dilation_rate=dilation_rate)(x)\n    conv = BatchNormalization()(conv)\n    conv = Activation('relu')(conv)\n    conv = Dropout(dropout_rate)(conv)\n    conv = Conv1D(filters, kernel_size, padding='same', dilation_rate=dilation_rate)(conv)\n    conv = BatchNormalization()(conv)\n    if int(x.shape[-1]) != filters:\n        res = Conv1D(filters, kernel_size=1, padding='same')(x)\n    else:\n        res = x\n    out = Add()([res, conv])\n    out = Activation('relu')(out)\n    return out\n\ndef se_feature_gate(inputs, reduction=8):\n    sq = GlobalAveragePooling1D()(inputs)\n    se = Dense(int(inputs.shape[-1] // reduction), activation='relu')(sq)\n    se = Dense(int(inputs.shape[-1]), activation='sigmoid')(se)\n    se = Reshape((1, int(inputs.shape[-1])))(se)\n    gated = Multiply()([inputs, se])\n    return gated, se\n\n# Multi-head temporal attention wrapper (Keras-safe)\ndef multihead_temporal_attention(seq, num_heads=4, key_dim=64, name=\"mha\"):\n    mha = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, name=f\"{name}_mha\")\n    att_out = mha(seq, seq, return_attention_scores=False)  # (batch, time, hidden)\n    context = Lambda(lambda z: tf.reduce_mean(z, axis=1), name=f\"{name}_context_mean\")(att_out)\n    return context, att_out\n\n# -------------------------\n# Build model (TCN + BiRNN + Dual attention + SE)\n# -------------------------\ninputs = Input(shape=(TIME_STEPS, N_FEATURES), name=\"input_seq\")\nx = Masking(mask_value=0.0, name=\"masking\")(inputs)\n\nx = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', name=\"conv_in\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.15)(x)\n\nx = tcn_res_block(x, filters=64, dilation_rate=1)\nx = tcn_res_block(x, filters=96, dilation_rate=2)\nx = tcn_res_block(x, filters=128, dilation_rate=4)\nx = tcn_res_block(x, filters=128, dilation_rate=8)\n\nx, se_weights = se_feature_gate(x, reduction=8)\n\nlstm = Bidirectional(LSTM(128, return_sequences=True))(x)\nlstm = Dropout(0.15)(lstm)\ngru  = GRU(128, return_sequences=True)(lstm)\ngru_proj = Dense(256, activation='linear')(gru)\nr = Add()([lstm, gru_proj])\nr = Dropout(0.15)(r)\n\ntemp_context, temp_att_seq = multihead_temporal_attention(r, num_heads=4, key_dim=64, name=\"multihead\")\n\nfeat_summary = Lambda(lambda z: K.mean(z, axis=1), name=\"feat_summary\")(inputs)\nfscore = Dense(N_FEATURES, name=\"feat_score\")(feat_summary)\nfweights = Activation('softmax', name=\"feat_weights\")(fscore)\nfeat_context = Multiply()([feat_summary, fweights])\nfeat_context = Dense(128, activation='relu', name=\"feat_proj\")(feat_context)\n\ncombined = Concatenate()([temp_context, feat_context])\n\nh = Dense(256, activation='relu')(combined)\nh = Dropout(0.15)(h)\nh = Dense(128, activation='relu')(h)\nh = Dropout(0.15)(h)\nout = Dense(1, activation='sigmoid', bias_initializer=Constant(bias_init))(h)\n\nmodel = Model(inputs=inputs, outputs=out)\nmodel.summary()\n\n# -------------------------\n# Loss / Optimizer / Compile (stable defaults)\n# -------------------------\ndef focal_loss(alpha=0.75, gamma=0.3):\n    def loss_fn(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n        p_t = y_true*y_pred + (1-y_true)*(1-y_pred)\n        alpha_factor = y_true*alpha + (1-y_true)*(1-alpha)\n        modulating = tf.pow(1.0 - p_t, gamma)\n        return tf.reduce_mean(alpha_factor * modulating * bce)\n    return loss_fn\n\ntry:\n    opt = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5, clipnorm=1.0)\nexcept Exception:\n    opt = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n\nmodel.compile(\n    optimizer=opt,\n    loss=focal_loss(alpha=0.75, gamma=0.3),\n    metrics=[tf.keras.metrics.AUC(name=\"AUC\"),\n             tf.keras.metrics.Precision(name=\"Precision\"),\n             tf.keras.metrics.Recall(name=\"Recall\")]\n)\n\n# -------------------------\n# Callbacks (stable)\n# -------------------------\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\ncallbacks_opt = [\n    EarlyStopping(monitor=\"val_AUC\", mode=\"max\", patience=10, restore_best_weights=True, verbose=1),\n    ModelCheckpoint(\"/kaggle/working/best_model_2H.h5\", monitor=\"val_AUC\", mode=\"max\", save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_AUC\", mode=\"max\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n]\n\n# -------------------------\n# Train (with pre-fit guard)\n# -------------------------\nprint(\"Pre-fit shapes check:\")\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\nprint(\"X_test :\", X_test.shape, \"y_test :\", y_test.shape)\nassert X_train.shape[0] == y_train.shape[0]\nassert X_test.shape[0] == y_test.shape[0]\n\nclass_weight = {0:1.0, 1:4.0}\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=60,\n    batch_size=128,\n    class_weight=class_weight,\n    callbacks=callbacks_opt,\n    verbose=2\n)\n\n# -------------------------\n# Evaluate + save model (recommended .keras)\n# -------------------------\ny_pred_proba = model.predict(X_test, batch_size=128).ravel()\ny_pred_proba = np.convolve(y_pred_proba, np.ones(3)/3, mode=\"same\")\n\n# threshold sweep\nthresholds = np.linspace(0.05, 0.5, 10)\nbest_f1, best_t = 0, 0.5\nfor t in thresholds:\n    pred_t = (y_pred_proba >= t).astype(int)\n    tp = np.sum((pred_t==1) & (y_test==1))\n    fp = np.sum((pred_t==1) & (y_test==0))\n    fn = np.sum((pred_t==0) & (y_test==1))\n    precision = tp/(tp+fp+1e-8)\n    recall = tp/(tp+fn+1e-8)\n    f1 = 2*precision*recall/(precision+recall+1e-8)\n    if f1 > best_f1: best_f1, best_t = f1, t\n\nprint(f\"Best F1 = {best_f1:.4f} at threshold = {best_t:.2f}\")\ny_pred = (y_pred_proba >= best_t).astype(int)\n\nroc_auc = roc_auc_score(y_test, y_pred_proba)\nprec, rec, _ = precision_recall_curve(y_test, y_pred_proba)\npr_auc = auc(rec, prec)\nprint(f\"ROC AUC = {roc_auc:.4f}, PR AUC = {pr_auc:.4f}\")\nprint(classification_report(y_test, y_pred, digits=4))\nprint(confusion_matrix(y_test, y_pred))\n\n# Save final model in modern Keras format\nmodel.save(\"/kaggle/working/sepsis_detector_v2H.keras\")\nprint(\"Saved model to /kaggle/working/sepsis_detector_v2H.keras\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-18T09:25:13.004166Z",
          "iopub.execute_input": "2025-11-18T09:25:13.004854Z",
          "iopub.status.idle": "2025-11-18T09:28:06.735179Z",
          "shell.execute_reply.started": "2025-11-18T09:25:13.004827Z",
          "shell.execute_reply": "2025-11-18T09:28:06.734583Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Listing files in /kaggle/working/ ...\n - .virtual_documents\n - X_test.npy\n - X_train.npy\n - best_model_2H.h5\n - sepsis_detector_v2H.keras\n - y_test.npy\n - y_train.npy\nShapes after load:\nX_train: (32268, 48, 19)\ny_train: (32268,)\nX_test : (8068, 48, 19)\ny_test : (8068,)\nTIME_STEPS=48, N_FEATURES=19\nBias init: -2.545882245560757\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional_4\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_seq           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m19\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 masking (\u001b[38;5;33mMasking\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m19\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 input_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv_in (\u001b[38;5;33mConv1D\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502      \u001b[38;5;34m3,712\u001b[0m \u2502 masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 conv_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_40          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502     \u001b[38;5;34m12,352\u001b[0m \u2502 dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 conv1d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_33       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_41          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_33[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502     \u001b[38;5;34m12,352\u001b[0m \u2502 dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 conv1d_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_20 (\u001b[38;5;33mAdd\u001b[0m)        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_34       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502     \u001b[38;5;34m18,528\u001b[0m \u2502 activation_34[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 conv1d_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_35       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_42          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_35[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_44 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502     \u001b[38;5;34m27,744\u001b[0m \u2502 dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_45 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502      \u001b[38;5;34m6,240\u001b[0m \u2502 activation_34[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 conv1d_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_21 (\u001b[38;5;33mAdd\u001b[0m)        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv1d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_36       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502     \u001b[38;5;34m36,992\u001b[0m \u2502 activation_36[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502        \u001b[38;5;34m512\u001b[0m \u2502 conv1d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_37       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_43          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_37[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502     \u001b[38;5;34m49,280\u001b[0m \u2502 dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502     \u001b[38;5;34m12,416\u001b[0m \u2502 activation_36[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502        \u001b[38;5;34m512\u001b[0m \u2502 conv1d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_22 (\u001b[38;5;33mAdd\u001b[0m)        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv1d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_38       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502     \u001b[38;5;34m49,280\u001b[0m \u2502 activation_38[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502        \u001b[38;5;34m512\u001b[0m \u2502 conv1d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_39       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_44          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_39[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502     \u001b[38;5;34m49,280\u001b[0m \u2502 dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502        \u001b[38;5;34m512\u001b[0m \u2502 conv1d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_23 (\u001b[38;5;33mAdd\u001b[0m)        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_38[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_40       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_poo\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_40[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mGlobalAveragePool\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_26 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        \u2502      \u001b[38;5;34m2,064\u001b[0m \u2502 global_average_p\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_27 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502      \u001b[38;5;34m2,176\u001b[0m \u2502 dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 reshape_4 (\u001b[38;5;33mReshape\u001b[0m) \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multiply_8          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 activation_40[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mMultiply\u001b[0m)          \u2502                   \u2502            \u2502 reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_4     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502    \u001b[38;5;34m263,168\u001b[0m \u2502 multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u2502 (\u001b[38;5;33mBidirectional\u001b[0m)     \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_45          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 bidirectional_4[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 gru_4 (\u001b[38;5;33mGRU\u001b[0m)         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   \u2502    \u001b[38;5;34m148,224\u001b[0m \u2502 dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_28 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502     \u001b[38;5;34m33,024\u001b[0m \u2502 gru_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_summary        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 input_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502 (\u001b[38;5;33mLambda\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_24 (\u001b[38;5;33mAdd\u001b[0m)        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \u2502\n\u2502                     \u2502                   \u2502            \u2502 dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_score (\u001b[38;5;33mDense\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        \u2502        \u001b[38;5;34m380\u001b[0m \u2502 feat_summary[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_46          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502          \u001b[38;5;34m0\u001b[0m \u2502 add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_weights        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 feat_score[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u2502 (\u001b[38;5;33mActivation\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multihead_mha       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u2502    \u001b[38;5;34m263,168\u001b[0m \u2502 dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \u2502\n\u2502 (\u001b[38;5;33mMultiHeadAttentio\u2026\u001b[0m \u2502                   \u2502            \u2502 dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multiply_9          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 feat_summary[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mMultiply\u001b[0m)          \u2502                   \u2502            \u2502 feat_weights[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multihead_context_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 multihead_mha[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u2502 (\u001b[38;5;33mLambda\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_proj (\u001b[38;5;33mDense\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502      \u001b[38;5;34m2,560\u001b[0m \u2502 multiply_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 concatenate_4       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 multihead_contex\u2026 \u2502\n\u2502 (\u001b[38;5;33mConcatenate\u001b[0m)       \u2502                   \u2502            \u2502 feat_proj[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_29 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u2502     \u001b[38;5;34m98,560\u001b[0m \u2502 concatenate_4[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_48          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_30 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m32,896\u001b[0m \u2502 dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_49          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_31 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         \u2502        \u001b[38;5;34m129\u001b[0m \u2502 dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_seq           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 input_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> \u2502 masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 conv_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_40          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> \u2502 dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 conv1d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_33       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_41          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> \u2502 dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 conv1d_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_34       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> \u2502 activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 conv1d_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_35       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_42          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,744</span> \u2502 dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,240</span> \u2502 activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 conv1d_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv1d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_36       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> \u2502 activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \u2502 conv1d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_37       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_43          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> \u2502 dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> \u2502 activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \u2502 conv1d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv1d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_38       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> \u2502 activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \u2502 conv1d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_39       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_44          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> \u2502 dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \u2502 conv1d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 batch_normalizat\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 activation_40       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_poo\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> \u2502 global_average_p\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> \u2502 dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multiply_8          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 activation_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          \u2502                   \u2502            \u2502 reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_4     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> \u2502 multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_45          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,224</span> \u2502 dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> \u2502 gru_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_summary        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 input_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \u2502\n\u2502                     \u2502                   \u2502            \u2502 dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_score (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span> \u2502 feat_summary[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_46          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_weights        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 feat_score[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multihead_mha       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> \u2502 dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio\u2026</span> \u2502                   \u2502            \u2502 dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multiply_9          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 feat_summary[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          \u2502                   \u2502            \u2502 feat_weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multihead_context_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 multihead_mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 feat_proj (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> \u2502 multiply_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 concatenate_4       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 multihead_contex\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       \u2502                   \u2502            \u2502 feat_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> \u2502 concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_48          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> \u2502 dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_49          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> \u2502 dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,128,109\u001b[0m (4.30 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,128,109</span> (4.30 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,126,317\u001b[0m (4.30 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,126,317</span> (4.30 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Pre-fit shapes check:\nX_train: (32268, 48, 19) y_train: (32268,)\nX_test : (8068, 48, 19) y_test : (8068,)\nEpoch 1/60\n\nEpoch 1: val_AUC improved from -inf to 0.77529, saving model to /kaggle/working/best_model_2H.h5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "253/253 - 27s - 108ms/step - AUC: 0.6971 - Precision: 0.3450 - Recall: 0.1223 - loss: 0.1272 - val_AUC: 0.7753 - val_Precision: 0.6176 - val_Recall: 0.0358 - val_loss: 0.1082 - learning_rate: 1.0000e-04\nEpoch 2/60\n\nEpoch 2: val_AUC improved from 0.77529 to 0.81216, saving model to /kaggle/working/best_model_2H.h5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "253/253 - 12s - 47ms/step - AUC: 0.7981 - Precision: 0.3888 - Recall: 0.2779 - loss: 0.1113 - val_AUC: 0.8122 - val_Precision: 0.6875 - val_Recall: 0.1502 - val_loss: 0.0955 - learning_rate: 1.0000e-04\nEpoch 3/60\n\nEpoch 3: val_AUC improved from 0.81216 to 0.81921, saving model to /kaggle/working/best_model_2H.h5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "253/253 - 12s - 47ms/step - AUC: 0.8169 - Precision: 0.3927 - Recall: 0.3035 - loss: 0.1074 - val_AUC: 0.8192 - val_Precision: 0.6781 - val_Recall: 0.1689 - val_loss: 0.0947 - learning_rate: 1.0000e-04\nEpoch 4/60\n\nEpoch 4: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8266 - Precision: 0.4007 - Recall: 0.3261 - loss: 0.1053 - val_AUC: 0.8190 - val_Precision: 0.6347 - val_Recall: 0.1809 - val_loss: 0.0933 - learning_rate: 1.0000e-04\nEpoch 5/60\n\nEpoch 5: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8351 - Precision: 0.3964 - Recall: 0.3367 - loss: 0.1034 - val_AUC: 0.8156 - val_Precision: 0.6599 - val_Recall: 0.1655 - val_loss: 0.0992 - learning_rate: 1.0000e-04\nEpoch 6/60\n\nEpoch 6: val_AUC did not improve from 0.81921\n\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n253/253 - 12s - 47ms/step - AUC: 0.8425 - Precision: 0.4089 - Recall: 0.3559 - loss: 0.1015 - val_AUC: 0.8137 - val_Precision: 0.6447 - val_Recall: 0.1672 - val_loss: 0.1043 - learning_rate: 1.0000e-04\nEpoch 7/60\n\nEpoch 7: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8567 - Precision: 0.4227 - Recall: 0.3870 - loss: 0.0979 - val_AUC: 0.8117 - val_Precision: 0.5474 - val_Recall: 0.1775 - val_loss: 0.1066 - learning_rate: 5.0000e-05\nEpoch 8/60\n\nEpoch 8: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8632 - Precision: 0.4151 - Recall: 0.3981 - loss: 0.0964 - val_AUC: 0.8101 - val_Precision: 0.5805 - val_Recall: 0.1724 - val_loss: 0.1108 - learning_rate: 5.0000e-05\nEpoch 9/60\n\nEpoch 9: val_AUC did not improve from 0.81921\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n253/253 - 12s - 46ms/step - AUC: 0.8649 - Precision: 0.4251 - Recall: 0.3968 - loss: 0.0955 - val_AUC: 0.8102 - val_Precision: 0.5388 - val_Recall: 0.2014 - val_loss: 0.1099 - learning_rate: 5.0000e-05\nEpoch 10/60\n\nEpoch 10: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8744 - Precision: 0.4278 - Recall: 0.4216 - loss: 0.0931 - val_AUC: 0.8146 - val_Precision: 0.5382 - val_Recall: 0.2287 - val_loss: 0.1125 - learning_rate: 2.5000e-05\nEpoch 11/60\n\nEpoch 11: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8760 - Precision: 0.4260 - Recall: 0.4318 - loss: 0.0925 - val_AUC: 0.8116 - val_Precision: 0.5631 - val_Recall: 0.2133 - val_loss: 0.1138 - learning_rate: 2.5000e-05\nEpoch 12/60\n\nEpoch 12: val_AUC did not improve from 0.81921\n\nEpoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n253/253 - 12s - 47ms/step - AUC: 0.8788 - Precision: 0.4415 - Recall: 0.4488 - loss: 0.0916 - val_AUC: 0.8087 - val_Precision: 0.5646 - val_Recall: 0.2014 - val_loss: 0.1170 - learning_rate: 2.5000e-05\nEpoch 13/60\n\nEpoch 13: val_AUC did not improve from 0.81921\n253/253 - 12s - 47ms/step - AUC: 0.8832 - Precision: 0.4426 - Recall: 0.4506 - loss: 0.0901 - val_AUC: 0.8084 - val_Precision: 0.5668 - val_Recall: 0.2099 - val_loss: 0.1206 - learning_rate: 1.2500e-05\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 3.\n\u001b[1m64/64\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step\nBest F1 = 0.2475 at threshold = 0.20\nROC AUC = 0.7241, PR AUC = 0.1939\n              precision    recall  f1-score   support\n\n           0     0.9430    0.9155    0.9291      7482\n           1     0.2139    0.2935    0.2475       586\n\n    accuracy                         0.8704      8068\n   macro avg     0.5785    0.6045    0.5883      8068\nweighted avg     0.8901    0.8704    0.8796      8068\n\n[[6850  632]\n [ 414  172]]\nSaved model to /kaggle/working/sepsis_detector_v2H.keras\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}