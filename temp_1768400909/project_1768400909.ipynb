{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies**"
      ],
      "metadata": {
        "id": "q69hp0KZGiEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYCJoLnjoMWm"
      },
      "outputs": [],
      "source": [
        "!pip install -q flask pyngrok transformers accelerate bitsandbytes sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create folders**"
      ],
      "metadata": {
        "id": "UJE2IIvlGoHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p templates\n",
        "!mkdir -p static"
      ],
      "metadata": {
        "id": "Alr1r9ZGoVqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write app.py**"
      ],
      "metadata": {
        "id": "nQkOC711Gr96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# =============================================================\n",
        "# Project 6: AI-Powered Interactive Interviewer & Feedback Generator\n",
        "# Merged: Strict question-generation pipeline + stable evaluation/UI\n",
        "# =============================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import json\n",
        "from functools import lru_cache\n",
        "from typing import List\n",
        "\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# App config\n",
        "# ------------------------------\n",
        "app = Flask(__name__)\n",
        "app.config[\"SECRET_KEY\"] = \"project6-secret\"\n",
        "STORAGE = \"sessions\"\n",
        "os.makedirs(STORAGE, exist_ok=True)\n",
        "\n",
        "# ------------------------------\n",
        "# Model config\n",
        "# ------------------------------\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def load_model():\n",
        "    \"\"\"\n",
        "    Load tokenizer + model once, using BitsAndBytesConfig for quantization.\n",
        "    Returns tokenizer, model, device.\n",
        "    \"\"\"\n",
        "    bnb = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        quantization_config=bnb,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    device = model.device\n",
        "    return tokenizer, model, device\n",
        "\n",
        "# ------------------------------\n",
        "# Generation helpers (robust)\n",
        "# ------------------------------\n",
        "def clean_text(text: str) -> str:\n",
        "    # remove odd non-printable / corrupted characters\n",
        "    text = re.sub(r\"[^\\x09\\x0A\\x0D\\x20-\\x7E\\u00A0-\\u024F]+\", \" \", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def looks_corrupted(text: str) -> bool:\n",
        "    if not text:\n",
        "        return True\n",
        "    if \"\ufffd\" in text:\n",
        "        return True\n",
        "    non_ascii = sum(1 for ch in text if ord(ch) > 127)\n",
        "    if (non_ascii / max(1, len(text))) > 0.12:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def truncate_prompt(prompt: str, max_words: int = 3000) -> str:\n",
        "    words = prompt.split()\n",
        "    if len(words) <= max_words:\n",
        "        return prompt\n",
        "    # keep the last part (most relevant for context)\n",
        "    return \" \".join(words[-max_words:])\n",
        "\n",
        "def generate_text(prompt: str,\n",
        "                  max_new_tokens: int = 700,\n",
        "                  temperature: float = 0.35,\n",
        "                  top_p: float = 0.85,\n",
        "                  deterministic_fallback: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Generate text using the cached model. Retry with deterministic settings if output looks corrupted.\n",
        "    \"\"\"\n",
        "    tokenizer, model, device = load_model()\n",
        "    prompt = truncate_prompt(prompt, max_words=3000)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    do_sample = temperature > 0.0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            do_sample=do_sample,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    text = clean_text(text)\n",
        "\n",
        "    if looks_corrupted(text) and deterministic_fallback:\n",
        "        try:\n",
        "            with torch.inference_mode():\n",
        "                out2 = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    temperature=0.0,\n",
        "                    top_p=1.0,\n",
        "                    do_sample=False,\n",
        "                    repetition_penalty=1.0,\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "                )\n",
        "            text2 = tokenizer.decode(out2[0], skip_special_tokens=True)\n",
        "            text2 = clean_text(text2)\n",
        "            if not looks_corrupted(text2):\n",
        "                text = text2\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return text\n",
        "\n",
        "# ------------------------------\n",
        "# Persistence helpers\n",
        "# ------------------------------\n",
        "def save_session(sid: str, data: dict):\n",
        "    path = os.path.join(STORAGE, f\"{sid}.json\")\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def load_session(sid: str):\n",
        "    path = os.path.join(STORAGE, f\"{sid}.json\")\n",
        "    if not os.path.exists(path):\n",
        "        return None\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# ------------------------------\n",
        "# Question generation (strict pipeline copied & adapted)\n",
        "# ------------------------------\n",
        "def build_initial_question_prompt(interview_type: str, num_questions: int, role: str, exp_level: str) -> str:\n",
        "    \"\"\"\n",
        "    Initial strict prompt that asks for numbered questions and enforces constraints.\n",
        "    \"\"\"\n",
        "    base_rules = f\"\"\"Generate {num_questions} {interview_type.lower()} interview questions for a {exp_level} candidate applying for {role}.\n",
        "\n",
        "Rules:\n",
        "- Each question must end with a question mark.\n",
        "- Each question must be under 20 words.\n",
        "- Number the questions from 1 to {num_questions} using '1.' '2.' etc.\n",
        "- Avoid duplicates and paraphrases.\n",
        "Return ONLY the numbered list of questions (no extra commentary).\"\"\"\n",
        "\n",
        "    if interview_type.lower() == \"technical\":\n",
        "        extra = \"\"\"\n",
        "Experience level guidance:\n",
        "- Fresher: use hypothetical phrasing (\"How would you...\", \"What steps would you take...\"); avoid asking about prior work.\n",
        "- Mid-Level: include scenario-based troubleshooting and practical challenges.\n",
        "- Experienced: focus on architecture, design decisions, scalability, reliability, and trade-offs.\n",
        "Focus on core fundamentals and practical reasoning.\"\"\"\n",
        "    elif interview_type.lower() == \"hr\":\n",
        "        extra = \"\"\"\n",
        "Experience level guidance:\n",
        "- Fresher: hypothetical only; avoid asking about prior job experience.\n",
        "- Mid-Level: focus on collaboration, conflict resolution, accountability.\n",
        "- Experienced: leadership, stakeholder communication, strategic reasoning.\n",
        "Avoid technical or domain-specific questions.\"\"\"\n",
        "    else:  # Functional\n",
        "        extra = \"\"\"\n",
        "Experience level guidance:\n",
        "- Fresher: hypothetical only; avoid prior experience references.\n",
        "- Mid-Level: scenario-focused execution and collaboration questions.\n",
        "- Experienced: strategic, cross-functional decision-making.\n",
        "Avoid technical, KPI, or tool-specific questions.\"\"\"\n",
        "    return base_rules + \"\\n\\n\" + extra\n",
        "\n",
        "def extract_numbered_questions_from_text(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract numbered questions using robust patterns. Falls back to lines ending in '?'.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    found = re.findall(r'\\d+[\\.\\)]\\s*(.+?\\?)', text)\n",
        "    out = [q.strip() for q in found if q.strip().endswith('?') and len(q.split()) >= 3]\n",
        "    if out:\n",
        "        # dedupe preserving order\n",
        "        seen = set()\n",
        "        res = []\n",
        "        for q in out:\n",
        "            if q not in seen:\n",
        "                res.append(q); seen.add(q)\n",
        "        return res\n",
        "\n",
        "    # fallback: plain lines ending in '?'\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip().endswith('?')]\n",
        "    res = [l for l in lines if len(l.split()) >= 3]\n",
        "    # dedupe\n",
        "    seen = set()\n",
        "    final = []\n",
        "    for q in res:\n",
        "        if q not in seen:\n",
        "            final.append(q); seen.add(q)\n",
        "    return final\n",
        "\n",
        "def generate_strict_questions(interview_type: str, num_questions: int, role: str, exp_level: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Full strict pipeline:\n",
        "    1) Initial generation\n",
        "    2) If missing -> continuation generation\n",
        "    3) If still missing -> verification pass to force exactly N questions\n",
        "    \"\"\"\n",
        "    # 1) Initial generation\n",
        "    initial_prompt = build_initial_question_prompt(interview_type, num_questions, role, exp_level)\n",
        "    raw = generate_text(initial_prompt, max_new_tokens=900, temperature=0.35, top_p=0.85)\n",
        "    qs = extract_numbered_questions_from_text(raw)\n",
        "\n",
        "    # 2) Continuation if needed\n",
        "    if len(qs) < num_questions:\n",
        "        remaining = num_questions - len(qs)\n",
        "        start_num = len(qs) + 1\n",
        "        cont_prompt = f\"\"\"\n",
        "Generate {remaining} additional unique {interview_type.lower()} questions for a {exp_level} candidate applying for {role}.\n",
        "Number them {start_num} to {num_questions}. Follow the same rules as before. Return ONLY numbered list.\n",
        "\"\"\"\n",
        "        raw2 = generate_text(cont_prompt, max_new_tokens=600, temperature=0.3, top_p=0.85)\n",
        "        new_qs = extract_numbered_questions_from_text(raw2)\n",
        "        for q in new_qs:\n",
        "            if q not in qs:\n",
        "                qs.append(q)\n",
        "        qs = qs[:num_questions]\n",
        "\n",
        "    # 3) Verification pass: ensure exactly num_questions; ask model to correct list if mismatch\n",
        "    if len(qs) != num_questions:\n",
        "        verify_prompt = f\"\"\"\n",
        "Review this list of {len(qs)} {interview_type.lower()} questions and correct them to exactly {num_questions} questions, following the rules:\n",
        "- Each question under 20 words\n",
        "- End with a question mark\n",
        "- Correct numbering 1 to {num_questions}\n",
        "- No duplicates\n",
        "Here is the current list:\n",
        "{chr(10).join([f\"{i+1}. {q}\" for i, q in enumerate(qs)])}\n",
        "\n",
        "Return ONLY the corrected numbered list.\n",
        "\"\"\"\n",
        "        raw3 = generate_text(verify_prompt, max_new_tokens=700, temperature=0.25, top_p=0.85)\n",
        "        corrected = extract_numbered_questions_from_text(raw3)\n",
        "        if corrected and len(corrected) >= num_questions:\n",
        "            qs = corrected[:num_questions]\n",
        "        else:\n",
        "            # fallback: pad with placeholders if still insufficient\n",
        "            while len(qs) < num_questions:\n",
        "                qs.append(\"No valid question generated. Please regenerate.\")\n",
        "            qs = qs[:num_questions]\n",
        "\n",
        "    # final dedupe & trim\n",
        "    final = []\n",
        "    seen = set()\n",
        "    for q in qs:\n",
        "        if q not in seen:\n",
        "            final.append(q); seen.add(q)\n",
        "    return final[:num_questions]\n",
        "\n",
        "# ------------------------------\n",
        "# Answer parsing & evaluation builder\n",
        "# ------------------------------\n",
        "def parse_combined_answers(text: str, expected_n: int):\n",
        "    \"\"\"\n",
        "    Parse a single textarea containing all answers in numbered format.\n",
        "    If numbering is not strictly present, split by lines and map sequentially.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return [\"\"] * expected_n\n",
        "\n",
        "    text = text.strip()\n",
        "    # capture numbered blocks: 1. answer ... 2. answer ...\n",
        "    pattern = re.compile(r'\\s*\\d+\\s*[\\.\\)]\\s*(.+?)(?=(?:\\n\\s*\\d+\\s*[\\.\\)]\\s*)|$)', flags=re.DOTALL)\n",
        "    matches = pattern.findall(text)\n",
        "    answers = [m.strip() for m in matches]\n",
        "\n",
        "    if not answers:\n",
        "        # fallback: split by double-newline blocks or single newlines\n",
        "        parts = [p.strip() for p in re.split(r'\\n{2,}', text) if p.strip()]\n",
        "        if not parts:\n",
        "            parts = [p.strip() for p in text.splitlines() if p.strip()]\n",
        "        answers = parts[:expected_n]\n",
        "\n",
        "    # ensure length\n",
        "    if len(answers) < expected_n:\n",
        "        answers += [\"\"] * (expected_n - len(answers))\n",
        "    else:\n",
        "        answers = answers[:expected_n]\n",
        "    return answers\n",
        "\n",
        "def build_evaluation_prompt(role: str, exp_level: str, qa_pairs: List[tuple]) -> str:\n",
        "    transcript = \"\\n\".join([f\"Q{i+1}: {q}\\nA{i+1}: {a}\\n\" for i, (q, a) in enumerate(qa_pairs)])\n",
        "    prompt = f\"\"\"\n",
        "You are a senior hiring manager evaluating a {exp_level.lower()} {role} candidate.\n",
        "\n",
        "Below is the full transcript of their interview:\n",
        "\n",
        "### INTERVIEW TRANSCRIPT START ###\n",
        "{transcript}\n",
        "### INTERVIEW TRANSCRIPT END ###\n",
        "\n",
        "Now, as an experienced HR professional, write a complete and insightful evaluation of the candidate\u2019s overall performance.\n",
        "\n",
        "\ud83d\udccb Final Interview Evaluation Report\n",
        "\n",
        "1. Overall Technical Competence:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "2. Problem-Solving and Analytical Skills:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "3. Communication and Confidence:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "4. Behavioral and Team Skills:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "5. Strengths:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "6. Areas for Improvement:\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "7. Final Recommendation (Hire / Consider / Reject):\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "8. Overall Score (out of 10):\n",
        "<explanation must start on a NEW line>\n",
        "\n",
        "Guidelines:\n",
        "- Summarize the entire interview, not per question.\n",
        "- Be objective and recruiter-like.\n",
        "- Keep it under 250 words.\n",
        "- Start your response immediately after the next line.\n",
        "### BEGIN EVALUATION BELOW ###\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# ------------------------------\n",
        "# Routes (Flask)\n",
        "# ------------------------------\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    if request.method == \"POST\":\n",
        "        role = request.form.get(\"role\", \"\").strip()\n",
        "        exp_level = request.form.get(\"exp_level\", \"Fresher\").strip()\n",
        "        interview_type = request.form.get(\"interview_type\", \"Technical\").strip()\n",
        "        try:\n",
        "            num_questions = int(request.form.get(\"num_questions\", \"5\"))\n",
        "        except Exception:\n",
        "            num_questions = 5\n",
        "        num_questions = max(1, min(num_questions, 20))\n",
        "\n",
        "        sid = str(uuid.uuid4())\n",
        "        data = {\n",
        "            \"role\": role,\n",
        "            \"exp_level\": exp_level,\n",
        "            \"interview_type\": interview_type,\n",
        "            \"num_questions\": num_questions,\n",
        "            \"questions\": [],\n",
        "            \"answers\": [],\n",
        "            \"evaluation\": \"\"\n",
        "        }\n",
        "        save_session(sid, data)\n",
        "\n",
        "        # Generate strict questions (multi-stage)\n",
        "        questions = generate_strict_questions(interview_type, num_questions, role, exp_level)\n",
        "\n",
        "        data[\"questions\"] = questions\n",
        "        save_session(sid, data)\n",
        "\n",
        "        return redirect(url_for(\"answer\", sid=sid))\n",
        "\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/answer/<sid>\", methods=[\"GET\", \"POST\"])\n",
        "def answer(sid):\n",
        "    data = load_session(sid)\n",
        "    if not data:\n",
        "        return \"Session not found\", 404\n",
        "\n",
        "    questions = data.get(\"questions\", [])\n",
        "    if request.method == \"POST\":\n",
        "        combined_answers = request.form.get(\"combined_answers\", \"\")\n",
        "        answers = parse_combined_answers(combined_answers, len(questions))\n",
        "        data[\"answers\"] = answers\n",
        "        save_session(sid, data)\n",
        "        return redirect(url_for(\"evaluate\", sid=sid))\n",
        "\n",
        "    return render_template(\"questions.html\", session=data, sid=sid)\n",
        "\n",
        "@app.route(\"/evaluate/<sid>\", methods=[\"GET\"])\n",
        "def evaluate(sid):\n",
        "    data = load_session(sid)\n",
        "    if not data:\n",
        "        return \"Session not found\", 404\n",
        "\n",
        "    questions = data.get(\"questions\", [])\n",
        "    answers = data.get(\"answers\", [])\n",
        "    qa_pairs = list(zip(questions, answers))\n",
        "    prompt = build_evaluation_prompt(data.get(\"role\", \"\"), data.get(\"exp_level\", \"\"), qa_pairs)\n",
        "\n",
        "    raw_eval = generate_text(prompt, max_new_tokens=700, temperature=0.3, top_p=0.9)\n",
        "    result = raw_eval.split(\"### BEGIN EVALUATION BELOW ###\")[-1].strip()\n",
        "    if not result.startswith(\"\ud83d\udccb\"):\n",
        "        result = \"\ud83d\udccb Final Interview Evaluation Report\\n\\n\" + result\n",
        "\n",
        "    data[\"evaluation\"] = result\n",
        "    save_session(sid, data)\n",
        "\n",
        "    return render_template(\"result.html\", session=data)\n",
        "\n",
        "# ------------------------------\n",
        "# Run app\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)"
      ],
      "metadata": {
        "id": "WCGajDcwoYMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**templates/index.html**"
      ],
      "metadata": {
        "id": "5pcrNr7MG55E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/>\n",
        "  <title>AI Interview Setup</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <h1>\ud83e\udde0 AI Interview \u2014 Setup</h1>\n",
        "\n",
        "    <form method=\"post\">\n",
        "      <label>Job Role</label>\n",
        "      <input name=\"role\" placeholder=\"e.g., ML Engineer\" required/>\n",
        "\n",
        "      <label>Experience Level</label>\n",
        "      <select name=\"exp_level\">\n",
        "        <option>Fresher</option>\n",
        "        <option>Mid-Level</option>\n",
        "        <option>Experienced</option>\n",
        "      </select>\n",
        "\n",
        "      <label>Interview Type</label>\n",
        "      <select name=\"interview_type\">\n",
        "        <option>Technical</option>\n",
        "        <option>HR</option>\n",
        "        <option>Functional</option>\n",
        "      </select>\n",
        "\n",
        "      <label>Number of Questions (1\u201320)</label>\n",
        "      <input type=\"number\" name=\"num_questions\" min=\"1\" max=\"20\" value=\"5\" required/>\n",
        "\n",
        "      <button type=\"submit\">Generate Questions \ud83d\ude80</button>\n",
        "    </form>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "HKv3Anb8odgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**templates/questions.html**"
      ],
      "metadata": {
        "id": "h8cY1Pa5HCH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/questions.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/>\n",
        "  <title>Interview \u2014 Answer</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "  <style>\n",
        "    pre.questions { white-space: pre-wrap; background:rgba(255,255,255,0.02); padding:12px; border-radius:8px; color:#e2e5ff; }\n",
        "    textarea.big { min-height: 260px; }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <h1>\ud83c\udfa4 Interview Questions</h1>\n",
        "\n",
        "    <div class=\"card\">\n",
        "      <h3>Questions (Please answer all in the box below)</h3>\n",
        "      <pre class=\"questions\">\n",
        "{% for q in session.questions %}\n",
        "{{ loop.index }}. {{ q }}\n",
        "{% endfor %}\n",
        "      </pre>\n",
        "\n",
        "      <form method=\"post\">\n",
        "        <label>Enter all answers in the single box below using numbered format (1. ... 2. ...)</label>\n",
        "        <textarea name=\"combined_answers\" class=\"big\" placeholder=\"{% for i in range(session.num_questions) %}{{ i+1 }}. \\n{% endfor %}\" required></textarea>\n",
        "        <button type=\"submit\">Submit & Evaluate</button>\n",
        "      </form>\n",
        "    </div>\n",
        "  </div>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "2R5neo_Uoebd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**templates/result.html**"
      ],
      "metadata": {
        "id": "tXO9qkeuHHFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/result.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/>\n",
        "  <title>Interview Evaluation</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <h1>\ud83d\udccb Final Interview Evaluation</h1>\n",
        "\n",
        "    <div class=\"card\">\n",
        "      <p><strong>Role:</strong> {{ session.role }} \u2014 <strong>Experience:</strong> {{ session.exp_level }}</p>\n",
        "      <hr/>\n",
        "      <pre style=\"white-space:pre-wrap;\">{{ session.evaluation }}</pre>\n",
        "    </div>\n",
        "\n",
        "    <a href=\"{{ url_for('index') }}\">Start New Interview</a>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "UbhGg7Ajoiaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**static/style.css**"
      ],
      "metadata": {
        "id": "IJJLx629HLl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile static/style.css\n",
        "body {\n",
        "  font-family: 'Poppins', Arial, sans-serif;\n",
        "  background: linear-gradient(135deg,#071120,#0f1724);\n",
        "  color: #e6f0ff;\n",
        "  margin: 0;\n",
        "  padding: 24px 12px;\n",
        "}\n",
        "\n",
        ".container {\n",
        "  max-width: 900px;\n",
        "  margin: 36px auto;\n",
        "}\n",
        "\n",
        "h1 { color: #ffe7b6; margin-bottom: 12px; }\n",
        ".card {\n",
        "  background: rgba(255,255,255,0.03);\n",
        "  padding: 18px;\n",
        "  border-radius: 12px;\n",
        "  margin-top: 12px;\n",
        "}\n",
        "\n",
        "input, select, textarea {\n",
        "  width: 100%;\n",
        "  padding: 10px;\n",
        "  margin: 8px 0;\n",
        "  border-radius: 8px;\n",
        "  border: none;\n",
        "  background: #ffffff;\n",
        "  color: #111;\n",
        "}\n",
        "\n",
        "button {\n",
        "  padding: 10px 14px;\n",
        "  border-radius: 8px;\n",
        "  border: none;\n",
        "  background: linear-gradient(90deg,#00c6ff,#0072ff);\n",
        "  color: white;\n",
        "  font-weight: 600;\n",
        "  cursor: pointer;\n",
        "}\n",
        "pre { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; }\n"
      ],
      "metadata": {
        "id": "nnTTrQh-om2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start Flask & ngrok**"
      ],
      "metadata": {
        "id": "Rx8XIALKHS7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any existing servers (safe restart)\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\""
      ],
      "metadata": {
        "id": "5lHT7m7YvZ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i :8000"
      ],
      "metadata": {
        "id": "kC8Ukz69vo0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Flask in background\n",
        "!nohup python app.py > run.log 2>&1 &"
      ],
      "metadata": {
        "id": "BP63dG93vb3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start ngrok tunnel (replace with your token or remove if already authed)\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Include your NGROK Auth token here\n",
        "conf.get_default().auth_token = \"INPUT_YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "# Show logs\n",
        "!sleep 3 && tail -n 40 run.log"
      ],
      "metadata": {
        "id": "ansg7mR1ooqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}