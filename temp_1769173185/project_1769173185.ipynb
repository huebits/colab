{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCS2n7xfobVXcEejJjlHW/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in Kaggle"
      ],
      "metadata": {
        "id": "rXhpBu1FAeff"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcDMe16EAe0g"
      },
      "source": [
        "# \ud83e\uddec Intelligent SNP-Based Machine Learning for Genetic Risk Assessment\n",
        "\n",
        "Dataset used in this project:\n",
        "\ud83d\udd17 https://www.kaggle.com/datasets/huebitsvizg/snp-dataset-1\n",
        "\n",
        "This dataset contains:\n",
        "- X_converted.csv \u2192 SNP matrix (already converted from raw X.txt)\n",
        "- y_converted.csv \u2192 phenotype values\n",
        "- The user does NOT need to manually convert raw `.txt` files.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 How to Use the Dataset in Kaggle\n",
        "\n",
        "1. Open the above dataset link.  \n",
        "2. Click **Add Dataset** \u2192 attach it to your Kaggle notebook.  \n",
        "3. Kaggle will mount the dataset at:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnV95qkyAe0m"
      },
      "source": [
        "4. All code in this notebook loads files directly from that folder.\n",
        "\n",
        "You will see these files automatically:\n",
        "- `/kaggle/input/snp-dataset-1/X_converted.csv`\n",
        "- `/kaggle/input/snp-dataset-1/y_converted.csv`\n",
        "\n",
        "These are already cleaned, separated, and ready for PCA + ML.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 What This Notebook Does\n",
        "\n",
        "This notebook builds a complete ML pipeline for SNP-based genetic risk prediction:\n",
        "\n",
        "\u2714 Loads SNP matrix (X) and phenotype vector (y)  \n",
        "\u2714 Cleans and aligns data  \n",
        "\u2714 Reduces dimensionality using PCA  \n",
        "\u2714 Trains 3 models:  \n",
        "- LightGBM baseline  \n",
        "- XGBoost (feature-selected)  \n",
        "- Final optimized XGBoost (GPU)  \n",
        "\u2714 Saves:\n",
        "- final_xgboost_model.pkl  \n",
        "- top_snps.json  \n",
        "\n",
        "These two files will later be uploaded into the **Colab Web App** for user-facing inference.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 After Running the Notebook\n",
        "\n",
        "You will automatically generate:\n",
        "\n",
        "1. **final_xgboost_model.pkl**  \n",
        "2. **top_snps.json**\n",
        "\n",
        "Download these from:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV6Et2qSAe0o"
      },
      "source": [
        "\n",
        "These are the only two files required to run the next stage (Colab web app).\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 You're Ready!\n",
        "\n",
        "Once the dataset is attached and this notebook is executed:\n",
        "\n",
        "\u2714 All preprocessing is handled  \n",
        "\u2714 All models are trained  \n",
        "\u2714 All final files are exported  \n",
        "\u2714 The user can proceed directly to the Colab web application  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T06:46:02.596079Z",
          "iopub.status.busy": "2025-11-19T06:46:02.595821Z",
          "iopub.status.idle": "2025-11-19T06:46:04.742522Z",
          "shell.execute_reply": "2025-11-19T06:46:04.741553Z",
          "shell.execute_reply.started": "2025-11-19T06:46:02.596057Z"
        },
        "trusted": true,
        "id": "ltRdA9TyAe0p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmhuiW2JAe0r"
      },
      "source": [
        "## Step 1: Load phenotype (y)\n",
        "\n",
        "The dataset provides `y.txt` which contains phenotype values.\n",
        "We load it to understand the number of samples and verify formatting.\n",
        "\n",
        "This is required before doing SNP alignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T06:46:09.057785Z",
          "iopub.status.busy": "2025-11-19T06:46:09.057366Z",
          "iopub.status.idle": "2025-11-19T06:46:09.091726Z",
          "shell.execute_reply": "2025-11-19T06:46:09.090179Z",
          "shell.execute_reply.started": "2025-11-19T06:46:09.057757Z"
        },
        "trusted": true,
        "id": "Jl5RtJBPAe0s"
      },
      "outputs": [],
      "source": [
        "y_path = \"/kaggle/input/snp-dataset-for-gwas/y.txt\"\n",
        "\n",
        "y = pd.read_csv(y_path, header=None)\n",
        "\n",
        "print(\"y shape:\", y.shape)\n",
        "print(y.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T06:55:48.579366Z",
          "iopub.status.busy": "2025-11-19T06:55:48.578789Z",
          "iopub.status.idle": "2025-11-19T07:12:11.683861Z",
          "shell.execute_reply": "2025-11-19T07:12:11.682496Z",
          "shell.execute_reply.started": "2025-11-19T06:55:48.579327Z"
        },
        "trusted": true,
        "id": "VIm9UKgJAe0t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load space-separated SNP matrix\n",
        "X = pd.read_csv(\"/kaggle/input/snp-dataset-for-gwas/X.txt\",\n",
        "                sep=\"\\s+\",\n",
        "                low_memory=False)\n",
        "\n",
        "# Save as CSV\n",
        "X.to_csv(\"X_converted.csv\", index=False)\n",
        "\n",
        "print(\"Conversion completed: X_converted.csv created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqrpVk1jAe0v"
      },
      "source": [
        "## Step 2: Convert raw X.txt \u2192 X_converted.csv\n",
        "\n",
        "The original dataset is space-separated and extremely large.\n",
        "This step converts it into a standard CSV format so ML models can load it faster.\n",
        "\n",
        "NOTE:\n",
        "- Kaggle version already includes `X_converted.csv`\n",
        "- You may skip this conversion if using the provided processed dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T07:12:46.840313Z",
          "iopub.status.busy": "2025-11-19T07:12:46.839917Z",
          "iopub.status.idle": "2025-11-19T07:12:46.862633Z",
          "shell.execute_reply": "2025-11-19T07:12:46.861283Z",
          "shell.execute_reply.started": "2025-11-19T07:12:46.840284Z"
        },
        "trusted": true,
        "id": "2KlJld9hAe0v"
      },
      "outputs": [],
      "source": [
        "y = pd.read_csv(\"/kaggle/input/snp-dataset-for-gwas/y.txt\", header=None)\n",
        "y.to_csv(\"y_converted.csv\", index=False)\n",
        "print(\"y_converted.csv created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T08:58:12.277073Z",
          "iopub.status.busy": "2025-11-19T08:58:12.276697Z",
          "iopub.status.idle": "2025-11-19T08:58:12.466462Z",
          "shell.execute_reply": "2025-11-19T08:58:12.465031Z",
          "shell.execute_reply.started": "2025-11-19T08:58:12.277042Z"
        },
        "trusted": true,
        "id": "KVqKMD_AAe0w"
      },
      "outputs": [],
      "source": [
        "!head -n 1 /kaggle/input/snp-dataset-1/X_converted.csv | cut -d',' -f1-20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkAAv2USAe0x"
      },
      "source": [
        "## Step 3: Quick Inspection of Converted SNP Matrix\n",
        "\n",
        "We inspect the first few columns and rows to confirm:\n",
        "\n",
        "\u2714 Column count (SNP markers)  \n",
        "\u2714 Valid encoding (0,1,2)  \n",
        "\u2714 No parsing errors  \n",
        "\n",
        "This is especially important when handling very large SNP matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:00:14.954826Z",
          "iopub.status.busy": "2025-11-19T09:00:14.954273Z",
          "iopub.status.idle": "2025-11-19T09:00:15.579629Z",
          "shell.execute_reply": "2025-11-19T09:00:15.578349Z",
          "shell.execute_reply.started": "2025-11-19T09:00:14.954782Z"
        },
        "trusted": true,
        "id": "Mx6IojqxAe0x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_small = pd.read_csv(\n",
        "    \"/kaggle/input/snp-dataset-1/X_converted.csv\",\n",
        "    usecols=range(20),   # only first 20 columns\n",
        "    nrows=2              # only first 2 rows\n",
        ")\n",
        "\n",
        "df_small\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NouoQMV8Ae0y"
      },
      "source": [
        "# Step : 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ofE7oEIAe0y"
      },
      "source": [
        "## Step 4: Clean phenotype vector y\n",
        "\n",
        "We perform:\n",
        "\n",
        "\u2714 Remove non-numeric entries  \n",
        "\u2714 Reset index  \n",
        "\u2714 Keep exactly first 1000 samples  \n",
        "\u2714 y must align with X rows for correct training  \n",
        "\n",
        "This ensures downstream models do not fail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:54:13.741680Z",
          "iopub.status.busy": "2025-11-19T09:54:13.741067Z",
          "iopub.status.idle": "2025-11-19T09:54:13.751262Z",
          "shell.execute_reply": "2025-11-19T09:54:13.750631Z",
          "shell.execute_reply.started": "2025-11-19T09:54:13.741656Z"
        },
        "trusted": true,
        "id": "S-OQcDRmAe0y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load y\n",
        "y = pd.read_csv(\"/kaggle/input/snp-dataset-1/y_converted.csv\",\n",
        "                header=None)\n",
        "\n",
        "# Keep only numeric rows\n",
        "y = y[pd.to_numeric(y[0], errors='coerce').notnull()]\n",
        "\n",
        "# Reset index\n",
        "y = y[0].reset_index(drop=True)\n",
        "\n",
        "# Remove the extra last row (make y = 1000 rows)\n",
        "y = y.iloc[:1000].reset_index(drop=True)\n",
        "\n",
        "print(\"Final y shape:\", y.shape)\n",
        "print(y.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1a3RQEfAe0z"
      },
      "source": [
        "## Step 5: Load SNP matrix (X)\n",
        "\n",
        "We load the entire SNP matrix using dtype=int8 (0/1/2 variants).\n",
        "This reduces RAM usage significantly and speeds up PCA & ML models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:42:51.698114Z",
          "iopub.status.busy": "2025-11-19T09:42:51.697612Z",
          "iopub.status.idle": "2025-11-19T09:42:58.581638Z",
          "shell.execute_reply": "2025-11-19T09:42:58.580966Z",
          "shell.execute_reply.started": "2025-11-19T09:42:51.698086Z"
        },
        "trusted": true,
        "id": "Yu5cbngiAe0z"
      },
      "outputs": [],
      "source": [
        "# Load only first row to confirm separator\n",
        "X_test = pd.read_csv(\"/kaggle/input/snp-dataset-1/X_converted.csv\",\n",
        "                     nrows=1)\n",
        "\n",
        "print(\"Columns detected:\", len(X_test.columns))\n",
        "print(X_test.iloc[:, :10])   # first 10 SNPs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:43:20.868082Z",
          "iopub.status.busy": "2025-11-19T09:43:20.867317Z",
          "iopub.status.idle": "2025-11-19T09:44:09.806707Z",
          "shell.execute_reply": "2025-11-19T09:44:09.805947Z",
          "shell.execute_reply.started": "2025-11-19T09:43:20.868057Z"
        },
        "trusted": true,
        "id": "MDFGnnByAe00"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "X = pd.read_csv(\n",
        "    \"/kaggle/input/snp-dataset-1/X_converted.csv\",\n",
        "    dtype=\"int8\",          # SNPs are 0/1/2 \u2192 fits in int8\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "print(\"X shape:\", X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CjwHXycAe00"
      },
      "source": [
        "## Step 6: PCA \u2014 Reduce Dimensionality\n",
        "\n",
        "SNP matrices often contain hundreds of thousands of columns.\n",
        "\n",
        "We reduce to:\n",
        "- 300 principal components  \n",
        "- retaining major genetic variation  \n",
        "\n",
        "This dramatically speeds up modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:45:18.394827Z",
          "iopub.status.busy": "2025-11-19T09:45:18.394309Z",
          "iopub.status.idle": "2025-11-19T09:46:24.093883Z",
          "shell.execute_reply": "2025-11-19T09:46:24.093079Z",
          "shell.execute_reply.started": "2025-11-19T09:45:18.394802Z"
        },
        "trusted": true,
        "id": "WuYhPRl5Ae00"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=300, random_state=42)\n",
        "\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "print(\"Reduced shape:\", X_reduced.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj6aWz4KAe01"
      },
      "source": [
        "## Step 7: Train Baseline Model (LightGBM)\n",
        "\n",
        "We first train a baseline regressor on PCA-reduced SNPs.\n",
        "\n",
        "Outputs:\n",
        "- RMSE error  \n",
        "- R\u00b2 score  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T09:54:21.636536Z",
          "iopub.status.busy": "2025-11-19T09:54:21.635825Z",
          "iopub.status.idle": "2025-11-19T09:54:28.667268Z",
          "shell.execute_reply": "2025-11-19T09:54:28.666447Z",
          "shell.execute_reply.started": "2025-11-19T09:54:21.636512Z"
        },
        "trusted": true,
        "id": "TltgRdMeAe01"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reduced, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model\n",
        "model_lgbm = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "model_lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "preds = model_lgbm.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "r2 = r2_score(y_test, preds)\n",
        "\n",
        "print(\"LightGBM RMSE:\", rmse)\n",
        "print(\"LightGBM R2:\", r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIYMjJ_Ae01"
      },
      "source": [
        "## Step 8: SNP Feature Selection\n",
        "\n",
        "We compute correlation of each SNP with phenotype y\n",
        "and select top 500 strongest SNPs.\n",
        "\n",
        "This reduces noise and improves model accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:12:13.251050Z",
          "iopub.status.busy": "2025-11-19T10:12:13.250348Z",
          "iopub.status.idle": "2025-11-19T10:12:15.319658Z",
          "shell.execute_reply": "2025-11-19T10:12:15.318955Z",
          "shell.execute_reply.started": "2025-11-19T10:12:13.251020Z"
        },
        "trusted": true,
        "id": "_eJfMhy-Ae01"
      },
      "outputs": [],
      "source": [
        "top_snps = corr.abs().sort_values(ascending=False).head(500).index\n",
        "X_top = X[top_snps]\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_top, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = XGBRegressor(\n",
        "    n_estimators=800,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    tree_method=\"hist\",\n",
        "    device=\"cuda\"    # enables GPU\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"RMSE:\", mean_squared_error(y_test, preds, squared=False))\n",
        "print(\"R2:\", r2_score(y_test, preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX2ojlguAe02"
      },
      "source": [
        "## Step 10: FINAL Optimized XGBoost Model\n",
        "\n",
        "We tune:\n",
        "- n_estimators  \n",
        "- learning_rate  \n",
        "- max_depth  \n",
        "- reg_alpha/reg_lambda  \n",
        "- subsample parameters  \n",
        "\n",
        "This produces the final model used in the web app.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:13:08.651308Z",
          "iopub.status.busy": "2025-11-19T10:13:08.651027Z",
          "iopub.status.idle": "2025-11-19T10:13:11.558438Z",
          "shell.execute_reply": "2025-11-19T10:13:11.557601Z",
          "shell.execute_reply.started": "2025-11-19T10:13:08.651287Z"
        },
        "trusted": true,
        "id": "szeRWxzqAe02"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_top, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# FINAL MODEL\n",
        "final_model = XGBRegressor(\n",
        "    n_estimators=1200,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=7,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    tree_method=\"hist\",\n",
        "    device=\"cuda\"\n",
        ")\n",
        "\n",
        "# Train\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "final_preds = final_model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "final_rmse = mean_squared_error(y_test, final_preds, squared=False)\n",
        "final_r2 = r2_score(y_test, final_preds)\n",
        "\n",
        "print(\"FINAL MODEL RMSE:\", final_rmse)\n",
        "print(\"FINAL MODEL R2:\", final_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n7oeyt6Ae03"
      },
      "source": [
        "## Step 11: Save model + selected SNP list\n",
        "\n",
        "Files created:\n",
        "- final_xgboost_model.pkl  \u2192 ML model  \n",
        "- top_snps.json            \u2192 list of selected SNP column names  \n",
        "\n",
        "These must be downloaded if user wants to run the Colab app.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:13:48.621528Z",
          "iopub.status.busy": "2025-11-19T10:13:48.621019Z",
          "iopub.status.idle": "2025-11-19T10:13:48.645389Z",
          "shell.execute_reply": "2025-11-19T10:13:48.644639Z",
          "shell.execute_reply.started": "2025-11-19T10:13:48.621505Z"
        },
        "trusted": true,
        "id": "_UJa0WXYAe03"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(final_model, \"final_xgboost_model.pkl\")\n",
        "\n",
        "# Save SNP list\n",
        "import json\n",
        "with open(\"top_snps.json\", \"w\") as f:\n",
        "    json.dump(list(top_snps), f)\n",
        "\n",
        "print(\"Model and SNP list saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeRXAe-cAe03"
      },
      "source": [
        "## Step 12: Reload saved model for validation\n",
        "\n",
        "We load:\n",
        "- model  \n",
        "- selected SNP list  \n",
        "- reconstructed test data  \n",
        "\n",
        "This step assures reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:22:38.155188Z",
          "iopub.status.busy": "2025-11-19T10:22:38.154484Z",
          "iopub.status.idle": "2025-11-19T10:22:38.195218Z",
          "shell.execute_reply": "2025-11-19T10:22:38.194652Z",
          "shell.execute_reply.started": "2025-11-19T10:22:38.155168Z"
        },
        "trusted": true,
        "id": "NrID1Kg3Ae03"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load model\n",
        "model = joblib.load(\"/kaggle/working/final_xgboost_model.pkl\")\n",
        "\n",
        "# Load SNP columns\n",
        "with open(\"/kaggle/working/top_snps.json\", \"r\") as f:\n",
        "    top_snps = json.load(f)\n",
        "\n",
        "print(\"Model and SNP list loaded successfully!\")\n",
        "print(\"Number of SNPs used:\", len(top_snps))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuv9Sa7DAe04"
      },
      "source": [
        "## Step 13: Evaluate prediction performance\n",
        "\n",
        "We compute:\n",
        "- RMSE  \n",
        "- R\u00b2 scores  \n",
        "\n",
        "And compare actual vs predicted values for first few samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:43:48.695069Z",
          "iopub.status.busy": "2025-11-19T10:43:48.694677Z",
          "iopub.status.idle": "2025-11-19T10:43:50.529037Z",
          "shell.execute_reply": "2025-11-19T10:43:50.527969Z",
          "shell.execute_reply.started": "2025-11-19T10:43:48.695040Z"
        },
        "trusted": true,
        "id": "sau78VXLAe04"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import json\n",
        "\n",
        "MODEL_PATH = \"/kaggle/input/snp-models-best/other/default/1/final_xgboost_model.pkl\"\n",
        "SNPS_PATH = \"/kaggle/input/snp-models-best/other/default/1/top_snps.json\"\n",
        "\n",
        "model = joblib.load(MODEL_PATH)\n",
        "\n",
        "with open(SNPS_PATH, \"r\") as f:\n",
        "    top_snps = json.load(f)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(\"Top SNP count:\", len(top_snps))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T10:49:16.230331Z",
          "iopub.status.busy": "2025-11-19T10:49:16.229953Z",
          "iopub.status.idle": "2025-11-19T10:50:38.632680Z",
          "shell.execute_reply": "2025-11-19T10:50:38.631339Z",
          "shell.execute_reply.started": "2025-11-19T10:49:16.230301Z"
        },
        "trusted": true,
        "id": "U9tkXVUIAe04"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "X_test_input = pd.read_csv(\n",
        "    \"/kaggle/input/snp-dataset-1/X_converted.csv\",\n",
        "    usecols=top_snps,\n",
        "    dtype='int8'\n",
        ")\n",
        "\n",
        "# Keep only the selected SNP columns\n",
        "X_test_input = X_test_input[top_snps]\n",
        "\n",
        "print(\"Final input shape:\", X_test_input.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T11:07:54.724808Z",
          "iopub.status.busy": "2025-11-19T11:07:54.723074Z",
          "iopub.status.idle": "2025-11-19T11:07:54.827219Z",
          "shell.execute_reply": "2025-11-19T11:07:54.825419Z",
          "shell.execute_reply.started": "2025-11-19T11:07:54.724730Z"
        },
        "trusted": true,
        "id": "gvehsJ1eAe04"
      },
      "outputs": [],
      "source": [
        "# Predict for all samples using the already loaded model & selected columns\n",
        "preds = model.predict(X_test_input)\n",
        "\n",
        "print(\"Predictions shape:\", preds.shape)\n",
        "print(preds[:10])   # first 10 predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T11:09:23.201116Z",
          "iopub.status.busy": "2025-11-19T11:09:23.200733Z",
          "iopub.status.idle": "2025-11-19T11:09:23.244995Z",
          "shell.execute_reply": "2025-11-19T11:09:23.244045Z",
          "shell.execute_reply.started": "2025-11-19T11:09:23.201089Z"
        },
        "trusted": true,
        "id": "kG4ZxDVLAe05"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load y\n",
        "y = pd.read_csv(\"/kaggle/input/snp-dataset-1/y_converted.csv\",\n",
        "                header=None)\n",
        "\n",
        "# Keep only numeric rows\n",
        "y = y[pd.to_numeric(y[0], errors='coerce').notnull()]\n",
        "\n",
        "# Reset index\n",
        "y = y[0].reset_index(drop=True)\n",
        "\n",
        "# Remove the extra last row (make y = 1000 rows)\n",
        "y = y.iloc[:1000].reset_index(drop=True)\n",
        "\n",
        "print(\"Final y shape:\", y.shape)\n",
        "print(y.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T11:09:30.964499Z",
          "iopub.status.busy": "2025-11-19T11:09:30.964079Z",
          "iopub.status.idle": "2025-11-19T11:09:30.998346Z",
          "shell.execute_reply": "2025-11-19T11:09:30.997104Z",
          "shell.execute_reply.started": "2025-11-19T11:09:30.964467Z"
        },
        "trusted": true,
        "id": "OEK0EN9rAe05"
      },
      "outputs": [],
      "source": [
        "y_true = y.values\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Actual\": y_true[:10],\n",
        "    \"Predicted\": preds[:10]\n",
        "})\n",
        "\n",
        "comparison_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-19T11:09:58.067384Z",
          "iopub.status.busy": "2025-11-19T11:09:58.066752Z",
          "iopub.status.idle": "2025-11-19T11:09:58.077209Z",
          "shell.execute_reply": "2025-11-19T11:09:58.076103Z",
          "shell.execute_reply.started": "2025-11-19T11:09:58.067346Z"
        },
        "trusted": true,
        "id": "72M5wTRDAe06"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "rmse = mean_squared_error(y_true, preds, squared=False)\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(\"Final RMSE:\", rmse)\n",
        "print(\"Final R2:\", r2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "eueWSlhqAe06"
      },
      "outputs": [],
      "source": [
        "# \ud83c\udf89 COMPLETE PIPELINE SUCCESSFULLY EXECUTED\n",
        "\n",
        "After running this notebook, user will download:\n",
        "\n",
        "1. final_xgboost_model.pkl\n",
        "2. top_snps.json\n",
        "\n",
        "These will be uploaded into the Colab Web App in the next stage.\n",
        "\n",
        "The user only needs:\n",
        "\u2714 This Kaggle notebook\n",
        "\u2714 The dataset link\n",
        "\u2714 The Colab notebook\n",
        "\n",
        "All models, JSON files, PCA data, and predictions are generated automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVv0i32ZAg2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEU66NiBAmt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7FBAs6xAmr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFpkkrdHAmp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaIFFtOIAmn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O6DJyrfZAmmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SE-zyed8AmkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2kcdm5IAmiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in Colab"
      ],
      "metadata": {
        "id": "BW6H1HoRAxiM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VdeZPytAp4M"
      },
      "source": [
        "# \ud83e\uddec SNP Cluster Explorer \u2014 Colab Web App (LLM + KMeans)\n",
        "\n",
        "This notebook turns your trained SNP ML pipeline into a **live web application**.\n",
        "\n",
        "It uses:\n",
        "\u2022 Important SNP list \u2192 `important_snps.json`  \n",
        "\u2022 KMeans model for clustering \u2192 `kmeans_75snps.pkl`  \n",
        "\u2022 SNP dataset \u2192 `X_converted.csv`  \n",
        "\u2022 Mistral-7B-Instruct (4-bit) for cluster explanations  \n",
        "\n",
        "These files should already exist because you exported them from the **Kaggle training notebook**.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 Before You Start: Upload the Required Files to Google Drive\n",
        "\n",
        "Place the following inside:\n",
        "\n",
        "\n",
        "Required files:\n",
        "- `important_snps.json`\n",
        "- `kmeans_75snps.pkl`\n",
        "- `X_converted.csv`\n",
        "\n",
        "Your folder structure:\n",
        "\n",
        "\n",
        "If the user runs this notebook **without these files**, the app will fail.  \n",
        "Make sure they are uploaded before executing.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 What This Web App Does\n",
        "\n",
        "\u2714 User enters a **row number**  \n",
        "\u2714 App loads SNP values for that individual  \n",
        "\u2714 KMeans predicts genetic cluster  \n",
        "\u2714 LLM generates explanation of that cluster  \n",
        "\u2714 UI displays SNP preview + explanation  \n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Workflow Overview\n",
        "\n",
        "1. Mount Google Drive  \n",
        "2. Install dependencies  \n",
        "3. Create Flask server  \n",
        "4. Load SNP models + LLM  \n",
        "5. Build UI (index.html + css)  \n",
        "6. Run ngrok \u2192 generate Public URL  \n",
        "7. Use the app like a real website  \n",
        "\n",
        "---\n",
        "\n",
        "Paste this markdown **just above the following cell**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1abVpXnlC9g"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR_E5zuyAp4T"
      },
      "source": [
        "# \ud83d\udce6 Install Dependencies\n",
        "\n",
        "This cell installs everything needed for:\n",
        "\n",
        "\u2022 Backend server (Flask)  \n",
        "\u2022 LLM inference (Transformers + bitsandbytes)  \n",
        "\u2022 Clustering (scikit-learn, joblib)  \n",
        "\u2022 Public hosting (ngrok)  \n",
        "\n",
        "Notes:\n",
        "- First execution may take 2\u20133 minutes.\n",
        "- Mistral 7B (4-bit) loads **in background**, so the app becomes available immediately, and the LLM loads asynchronously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6afic-PElM6o"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/On-Going Projects/SNP Project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZNW5GuqljMI"
      },
      "outputs": [],
      "source": [
        "!pip install  flask pyngrok pandas scikit-learn joblib\n",
        "!pip install  transformers accelerate huggingface-hub sentencepiece protobuf\n",
        "!pip install  bitsandbytes\n",
        "!pip install  ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snQDUZJWqA4A"
      },
      "outputs": [],
      "source": [
        "!mkdir -p templates static uploads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8N1kdB5Ap4V"
      },
      "source": [
        "# \ud83e\udde0 Create Flask Application (Backend)\n",
        "\n",
        "This cell generates the entire backend:\n",
        "\n",
        "\u2714 Loads:\n",
        "   - important SNP indices  \n",
        "   - KMeans clustering model  \n",
        "   - Full SNP dataset (only selected SNPs)  \n",
        "\n",
        "\u2714 Implements:\n",
        "   - Background LLM loading thread  \n",
        "   - `/api/predict` endpoint for cluster prediction  \n",
        "   - Dynamic explanation generation  \n",
        "\n",
        "Important:\n",
        "- The first request may return:  \n",
        "  \u201cLLM is warming up \u2014 try again in 1\u20133 minutes\u201d  \n",
        "  because the 7B model loads in the background.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgOtYyDIqA0h"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import threading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "\n",
        "# Reduce TF noise if it's present in the environment\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# App Configuration\n",
        "# ============================================================\n",
        "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "\n",
        "# CUDA memory safety\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# Load SNP Models (local, small)\n",
        "# ============================================================\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Colab Notebooks/On-Going Projects/SNP Project\"\n",
        "\n",
        "IMPORTANT_SNPS_PATH = os.path.join(MODEL_DIR, \"important_snps.json\")\n",
        "KMEANS_MODEL_PATH = os.path.join(MODEL_DIR, \"kmeans_75snps.pkl\")\n",
        "DATASET_PATH = os.path.join(MODEL_DIR, \"X_converted.csv\")\n",
        "\n",
        "with open(IMPORTANT_SNPS_PATH, \"r\") as f:\n",
        "    IMPORTANT_SNPS = json.load(f)\n",
        "\n",
        "KMEANS = joblib.load(KMEANS_MODEL_PATH)\n",
        "FULL_DATA = pd.read_csv(DATASET_PATH, usecols=IMPORTANT_SNPS, dtype=\"int8\")\n",
        "\n",
        "# ============================================================\n",
        "# Cluster Labels\n",
        "# ============================================================\n",
        "CLUSTER_LABELS = {\n",
        "    0: \"High variation on chromosome 3 & 6\",\n",
        "    1: \"More stable SNP profile, low diversity\",\n",
        "    2: \"High-risk variants in immune-related SNPs\",\n",
        "    3: \"Strong variation in chromosome 14 region\",\n",
        "    4: \"High heterozygosity across genome\",\n",
        "    5: \"Miscellaneous genetic pattern group\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# LLM Loader state + background loading\n",
        "# ============================================================\n",
        "LLM = None\n",
        "TOKENIZER = None\n",
        "PIPELINE = None\n",
        "LLM_LOCK = threading.Lock()\n",
        "LLM_LOADING = False\n",
        "\n",
        "def _really_load_llm():\n",
        "    \"\"\"Blocking load of the model; run inside a background thread.\"\"\"\n",
        "    global LLM, TOKENIZER, PIPELINE, LLM_LOADING\n",
        "    try:\n",
        "        model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "        print(\"\ud83d\ude80 Background LLM load started (4-bit NF4) ...\")\n",
        "\n",
        "        bnb = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "        )\n",
        "\n",
        "        TOKENIZER = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        LLM = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb,\n",
        "        )\n",
        "\n",
        "        # create a pipeline once model/tokenizer are ready\n",
        "        PIPELINE = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=LLM,\n",
        "            tokenizer=TOKENIZER,\n",
        "            max_new_tokens=250,\n",
        "            temperature=0.4,\n",
        "            do_sample=True,\n",
        "        )\n",
        "\n",
        "        print(\"\u2714 Background LLM load finished.\")\n",
        "    except Exception as e:\n",
        "        print(\"\u203c LLM load failed:\", e)\n",
        "    finally:\n",
        "        # mark loading finished even on error so future calls may retry\n",
        "        with LLM_LOCK:\n",
        "            global LLM_LOADING\n",
        "            LLM_LOADING = False\n",
        "\n",
        "def ensure_llm_background():\n",
        "    \"\"\"If not loaded, start background loading (non-blocking).\"\"\"\n",
        "    global LLM_LOADING\n",
        "    with LLM_LOCK:\n",
        "        if PIPELINE is not None:\n",
        "            return True\n",
        "        if LLM_LOADING:\n",
        "            return False\n",
        "        # start background loader\n",
        "        LLM_LOADING = True\n",
        "        t = threading.Thread(target=_really_load_llm, daemon=True)\n",
        "        t.start()\n",
        "        return False\n",
        "\n",
        "def get_pipeline():\n",
        "    \"\"\"Return pipeline if ready, otherwise None.\"\"\"\n",
        "    return PIPELINE\n",
        "\n",
        "# ============================================================\n",
        "# Generate Explanation (uses pipeline if ready)\n",
        "# ============================================================\n",
        "def generate_cluster_explanation(cluster_id, cluster_name):\n",
        "    pipe = get_pipeline()\n",
        "    if pipe is None:\n",
        "        # trigger background loading if not already started\n",
        "        ensure_llm_background()\n",
        "        return (\"LLM is warming up \u2014 explanation will be generated shortly. \"\n",
        "                \"Try again in ~1\u20133 minutes (model download time depends on your GPU / network).\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "[INST]\n",
        "Explain this genetic cluster in simple terms.\n",
        "\n",
        "Cluster ID: {cluster_id}\n",
        "Cluster Name: {cluster_name}\n",
        "\n",
        "Write 4\u20136 lines:\n",
        "\u2022 What this cluster represents\n",
        "\u2022 Common SNP/variation pattern\n",
        "\u2022 No medical predictions\n",
        "\u2022 Simple, beginner-friendly explanation\n",
        "[/INST]\n",
        "\"\"\"\n",
        "    out = pipe(prompt)[0][\"generated_text\"]\n",
        "    if \"[/INST]\" in out:\n",
        "        out = out.split(\"[/INST]\")[-1].strip()\n",
        "    return out.strip()\n",
        "\n",
        "# ============================================================\n",
        "# ROUTES\n",
        "# ============================================================\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/api/predict\", methods=[\"POST\"])\n",
        "def predict_cluster():\n",
        "    try:\n",
        "        row_id = request.form.get(\"row_id\")\n",
        "        if row_id is None:\n",
        "            return jsonify({\"error\": \"Row number required\"}), 400\n",
        "\n",
        "        try:\n",
        "            row_id = int(row_id)\n",
        "        except:\n",
        "            return jsonify({\"error\": \"Invalid row number\"}), 400\n",
        "\n",
        "        if row_id < 0 or row_id >= len(FULL_DATA):\n",
        "            return jsonify({\"error\": \"Row number out of range\"}), 400\n",
        "\n",
        "        # Get SNPs (single row)\n",
        "        snp_row = FULL_DATA.iloc[row_id]  # Series\n",
        "\n",
        "        # KMeans prediction (fast, local)\n",
        "        cluster_id = int(KMEANS.predict(snp_row.values.reshape(1, -1))[0])\n",
        "        cluster_name = CLUSTER_LABELS.get(cluster_id, \"Unknown Cluster\")\n",
        "\n",
        "        # Preview: first 10 SNP values as native ints\n",
        "        preview_values = [int(x) for x in snp_row.iloc[:10].tolist()]\n",
        "\n",
        "        # Explanation (may be placeholder while model loads)\n",
        "        explanation = generate_cluster_explanation(cluster_id, cluster_name)\n",
        "\n",
        "        return jsonify({\n",
        "            \"row_id\": row_id,\n",
        "            \"cluster_id\": cluster_id,\n",
        "            \"cluster_name\": cluster_name,\n",
        "            \"explanation\": explanation,\n",
        "            \"snp_count\": len(IMPORTANT_SNPS),\n",
        "            \"preview\": preview_values\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\ud83d\udd25 ERROR:\", e)\n",
        "        torch.cuda.empty_cache()\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# ============================================================\n",
        "# RUN SERVER\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # optionally kick off background LLM loading at server startup:\n",
        "    # ensure_llm_background()\n",
        "    app.run(host=\"0.0.0.0\", port=8000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgles9i2Ap4X"
      },
      "source": [
        "# \ud83c\udfa8 Frontend UI \u2014 SNP Cluster Explorer\n",
        "\n",
        "This creates the user interface:\n",
        "\n",
        "\u2714 Row input box  \n",
        "\u2714 SNP preview (first 10 SNPs)  \n",
        "\u2714 Cluster ID + cluster name  \n",
        "\u2714 AI-generated explanation  \n",
        "\u2714 Dynamic badges for clusters  \n",
        "\u2714 Loading spinner + error messages  \n",
        "\n",
        "You don\u2019t need to edit this unless customizing styling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58HSWMjsqvkF"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/index.html\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/>\n",
        "  <title>SNP Cluster Explorer</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "<div class=\"particles\"></div>\n",
        "\n",
        "<header class=\"topbar\">\n",
        "  <div class=\"topbar-left\">\n",
        "    <span class=\"logo-icon\">\ud83e\uddec</span>\n",
        "    <div>\n",
        "      <div class=\"brand-title\">SNP Cluster Explorer</div>\n",
        "      <div class=\"brand-sub\">Genetic Pattern Classification</div>\n",
        "    </div>\n",
        "  </div>\n",
        "</header>\n",
        "\n",
        "<main class=\"container\">\n",
        "\n",
        "  <div class=\"page-header\">\n",
        "    <h2 class=\"page-title\">\ud83d\udd2c Explore Genetic Clusters</h2>\n",
        "    <p class=\"page-subtitle\">Enter a row number (0\u2013999) to fetch SNP values, compute cluster, and generate an AI explanation.</p>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"main-form\">\n",
        "\n",
        "    <!-- INPUT SECTION -->\n",
        "    <div class=\"form-section\">\n",
        "      <h3 class=\"section-title\">\ud83d\udce5 Step 1: Enter Row Number</h3>\n",
        "      <p class=\"section-desc\">The dataset contains 1000 individuals. Select a row to analyze.</p>\n",
        "\n",
        "      <label class=\"input-label\">Row Number (0\u2013999)</label>\n",
        "      <input id=\"rowInput\" type=\"number\" min=\"0\" max=\"999\" placeholder=\"Example: 0\">\n",
        "\n",
        "      <div class=\"action-row\">\n",
        "        <button class=\"submit-button primary\" onclick=\"predictCluster()\">\ud83e\uddec Predict Cluster</button>\n",
        "        <button class=\"submit-button ghost\" onclick=\"clearOutput()\">\ud83d\uddd1\ufe0f Clear</button>\n",
        "      </div>\n",
        "\n",
        "      <!-- LOADING SPINNER -->\n",
        "      <div id=\"loader\" class=\"loader\" style=\"display:none; margin-top:12px; text-align:center;\">\n",
        "        <div class=\"spinner\"></div>\n",
        "        <p style=\"margin-top:8px;\">Fetching row data & generating explanation...</p>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- RESULT SECTION -->\n",
        "    <div id=\"resultSection\" class=\"form-section\" style=\"display:none\">\n",
        "      <h3 class=\"section-title\">\ud83d\udcca Step 2: Cluster Prediction Result</h3>\n",
        "\n",
        "      <!-- Cluster Badge -->\n",
        "      <div class=\"ai-badge\" id=\"clusterBadge\"></div>\n",
        "\n",
        "      <!-- Row Preview -->\n",
        "      <label class=\"input-label\">Preview of SNP Values (first 10 SNPs)</label>\n",
        "      <textarea id=\"rowPreview\" rows=\"2\" readonly></textarea>\n",
        "\n",
        "      <!-- Cluster Info -->\n",
        "      <label class=\"input-label\">Cluster ID</label>\n",
        "      <input id=\"clusterId\" type=\"text\" readonly>\n",
        "\n",
        "      <label class=\"input-label\">Cluster Name</label>\n",
        "      <input id=\"clusterName\" type=\"text\" readonly>\n",
        "\n",
        "      <!-- AI Explanation -->\n",
        "      <label class=\"input-label\">AI Explanation</label>\n",
        "      <textarea id=\"explanation\" rows=\"8\" readonly class=\"fade-in\"></textarea>\n",
        "\n",
        "      <div class=\"action-row\" style=\"margin-top:16px\">\n",
        "        <button class=\"submit-button success\" onclick=\"scrollToTop()\">\ud83d\udd3c Back to Top</button>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <div id=\"status\" class=\"status-message\" style=\"display:none\"></div>\n",
        "\n",
        "  </div>\n",
        "</main>\n",
        "\n",
        "<footer class=\"footer\">\n",
        "  SNP Cluster Explorer \u2014 Powered by Mistral 7B \u2022 \u00a9 2025\n",
        "</footer>\n",
        "\n",
        "<script>\n",
        "function scrollToTop() {\n",
        "  window.scrollTo({ top: 0, behavior: \"smooth\" });\n",
        "}\n",
        "\n",
        "function clearOutput() {\n",
        "  document.getElementById(\"rowInput\").value = \"\";\n",
        "  document.getElementById(\"resultSection\").style.display = \"none\";\n",
        "  document.getElementById(\"loader\").style.display = \"none\";\n",
        "  setStatus(\"\", \"\");\n",
        "}\n",
        "\n",
        "async function predictCluster() {\n",
        "  const rowEl = document.getElementById(\"rowInput\");\n",
        "  const row = (rowEl.value || \"\").toString().trim();\n",
        "\n",
        "  if (row === \"\") {\n",
        "    setStatus(\"\u274c Please enter a row number.\", \"error\");\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  setStatus(\"\ud83d\udd0d Fetching SNP values from dataset...\", \"info\");\n",
        "  document.getElementById(\"loader\").style.display = \"block\";\n",
        "  document.getElementById(\"resultSection\").style.display = \"none\";\n",
        "\n",
        "  const fd = new FormData();\n",
        "  fd.append(\"row_id\", row);\n",
        "\n",
        "  try {\n",
        "    const r = await fetch(\"/api/predict\", { method: \"POST\", body: fd });\n",
        "    if (!r.ok) {\n",
        "      const err = await r.json().catch(()=>({error: r.statusText}));\n",
        "      throw new Error(err.error || r.statusText || \"Server error\");\n",
        "    }\n",
        "    const j = await r.json();\n",
        "\n",
        "    if (j.error) {\n",
        "      setStatus(\"\u274c \" + j.error, \"error\");\n",
        "      document.getElementById(\"loader\").style.display = \"none\";\n",
        "      return;\n",
        "    }\n",
        "\n",
        "    document.getElementById(\"resultSection\").style.display = \"block\";\n",
        "\n",
        "    document.getElementById(\"clusterId\").value = j.cluster_id;\n",
        "    document.getElementById(\"clusterName\").value = j.cluster_name;\n",
        "    document.getElementById(\"explanation\").value = j.explanation || \"\";\n",
        "\n",
        "    // safely render preview (may be undefined)\n",
        "    const previewArr = Array.isArray(j.preview) ? j.preview : [];\n",
        "    document.getElementById(\"rowPreview\").value = previewArr.join(\", \");\n",
        "\n",
        "    const badge = document.getElementById(\"clusterBadge\");\n",
        "    badge.textContent = `Cluster ${j.cluster_id}`;\n",
        "    badge.className = \"ai-badge cluster-\" + j.cluster_id;\n",
        "\n",
        "    setStatus(\"\u2705 Prediction returned.\", \"success\");\n",
        "\n",
        "    document.getElementById(\"loader\").style.display = \"none\";\n",
        "    document.getElementById(\"resultSection\").scrollIntoView({ behavior: \"smooth\" });\n",
        "\n",
        "  } catch (e) {\n",
        "    console.error(\"Fetch error:\", e);\n",
        "    setStatus(\"\u274c Network error: \" + (e.message || \"Failed to fetch\"), \"error\");\n",
        "    document.getElementById(\"loader\").style.display = \"none\";\n",
        "  }\n",
        "}\n",
        "\n",
        "function setStatus(msg, type) {\n",
        "  const el = document.getElementById(\"status\");\n",
        "  el.textContent = msg;\n",
        "  el.className = \"status-message \" + (type || \"\");\n",
        "  el.style.display = msg ? \"block\" : \"none\";\n",
        "}\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW-wwFpxAp4Y"
      },
      "source": [
        "# \ud83c\udfa8 Styling (CSS)\n",
        "\n",
        "This stylesheet provides:\n",
        "\n",
        "\u2022 Dark-glass UI  \n",
        "\u2022 Animations  \n",
        "\u2022 Cluster color badges  \n",
        "\u2022 Responsive layout  \n",
        "\u2022 Modern typography  \n",
        "\n",
        "The UI theme matches the \u201cGenomics + AI\u201d aesthetic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOrpqA_ZrbGp"
      },
      "outputs": [],
      "source": [
        "%%writefile static/style.css\n",
        "/* ============================================================\n",
        "   BASE THEME\n",
        "   ============================================================ */\n",
        ":root {\n",
        "  --bg: #061026;\n",
        "  --card: #0e1724;\n",
        "  --glass: rgba(255,255,255,0.05);\n",
        "  --text: #ffffff;\n",
        "  --muted: #c7d2e8;\n",
        "\n",
        "  --primary: #6366f1;\n",
        "  --primary-dark: #4f46e5;\n",
        "  --success: #10b981;\n",
        "\n",
        "  /* Cluster colors */\n",
        "  --c0: #60a5fa;\n",
        "  --c1: #34d399;\n",
        "  --c2: #fbbf24;\n",
        "  --c3: #c084fc;\n",
        "  --c4: #fb7185;\n",
        "  --c5: #2dd4bf;\n",
        "\n",
        "  --shadow: 0 18px 40px rgba(0,0,0,0.55);\n",
        "}\n",
        "\n",
        "body {\n",
        "  margin: 0;\n",
        "  background: linear-gradient(135deg, #041025, #0b1730);\n",
        "  color: var(--text);\n",
        "  font-family: Inter, system-ui, sans-serif;\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   FULL PAGE WRAPPER\n",
        "   ============================================================ */\n",
        ".container {\n",
        "  max-width: 900px;\n",
        "  margin: 40px auto;\n",
        "  padding: 20px;\n",
        "}\n",
        "\n",
        "/* Title section */\n",
        ".page-header {\n",
        "  text-align: center;\n",
        "  margin-bottom: 30px;\n",
        "}\n",
        "\n",
        ".page-title {\n",
        "  font-size: 32px;\n",
        "  font-weight: 800;\n",
        "}\n",
        "\n",
        ".page-subtitle {\n",
        "  font-size: 15px;\n",
        "  color: var(--muted);\n",
        "  margin-top: 8px;\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   BACKGROUND PARTICLES\n",
        "   ============================================================ */\n",
        ".particles {\n",
        "  position: fixed;\n",
        "  inset: 0;\n",
        "  pointer-events: none;\n",
        "  background:\n",
        "    radial-gradient(circle at 10% 20%, rgba(99,102,241,0.12), transparent 20%),\n",
        "    radial-gradient(circle at 80% 80%, rgba(16,185,129,0.10), transparent 25%);\n",
        "  filter: blur(12px);\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   TOPBAR\n",
        "   ============================================================ */\n",
        ".topbar {\n",
        "  background: rgba(255,255,255,0.04);\n",
        "  backdrop-filter: blur(12px);\n",
        "  padding: 16px 30px;\n",
        "  display: flex;\n",
        "  justify-content: space-between;\n",
        "  align-items: center;\n",
        "  border-bottom: 1px solid rgba(255,255,255,0.05);\n",
        "  position: sticky;\n",
        "  top: 0;\n",
        "  z-index: 10;\n",
        "}\n",
        "\n",
        ".topbar-left {\n",
        "  display: flex;\n",
        "  align-items: center;\n",
        "  gap: 14px;\n",
        "}\n",
        "\n",
        ".logo-icon {\n",
        "  font-size: 32px;\n",
        "}\n",
        "\n",
        ".brand-title {\n",
        "  font-size: 20px;\n",
        "  font-weight: 700;\n",
        "}\n",
        "\n",
        ".brand-sub {\n",
        "  font-size: 12px;\n",
        "  color: var(--muted);\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   CARD (Main Form)\n",
        "   ============================================================ */\n",
        ".main-form {\n",
        "  background: var(--card);\n",
        "  padding: 30px;\n",
        "  border-radius: 14px;\n",
        "  box-shadow: var(--shadow);\n",
        "  border: 1px solid rgba(255,255,255,0.06);\n",
        "}\n",
        "\n",
        "/* Section inside card */\n",
        ".form-section {\n",
        "  margin-bottom: 32px;\n",
        "  padding-bottom: 24px;\n",
        "  border-bottom: 1px solid rgba(255,255,255,0.08);\n",
        "}\n",
        "\n",
        ".form-section:last-child {\n",
        "  border-bottom: none;\n",
        "}\n",
        "\n",
        ".section-title {\n",
        "  font-size: 20px;\n",
        "  font-weight: 700;\n",
        "}\n",
        "\n",
        ".section-desc {\n",
        "  margin-top: 10px;\n",
        "  color: var(--muted);\n",
        "  line-height: 1.5rem;\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   INPUTS\n",
        "   ============================================================ */\n",
        ".input-label {\n",
        "  display: block;\n",
        "  margin-top: 16px;\n",
        "  margin-bottom: 6px;\n",
        "  color: var(--muted);\n",
        "  font-size: 13px;\n",
        "  font-weight: 700;\n",
        "  text-transform: uppercase;\n",
        "}\n",
        "\n",
        "input[type=\"number\"], input[type=\"text\"], textarea {\n",
        "  width: 100%;\n",
        "  padding: 14px;\n",
        "  border-radius: 10px;\n",
        "  background: rgba(255,255,255,0.04);\n",
        "  border: 1px solid rgba(255,255,255,0.12);\n",
        "  color: white;\n",
        "  font-size: 15px;\n",
        "}\n",
        "\n",
        "textarea {\n",
        "  resize: vertical;\n",
        "}\n",
        "\n",
        "input:focus, textarea:focus {\n",
        "  outline: none;\n",
        "  border-color: var(--primary);\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   BUTTONS\n",
        "   ============================================================ */\n",
        ".action-row {\n",
        "  margin-top: 20px;\n",
        "  display: flex;\n",
        "  gap: 12px;\n",
        "  flex-wrap: wrap;\n",
        "}\n",
        "\n",
        ".submit-button {\n",
        "  padding: 12px 22px;\n",
        "  border-radius: 12px;\n",
        "  border: none;\n",
        "  font-weight: 700;\n",
        "  cursor: pointer;\n",
        "  transition: all 0.2s;\n",
        "}\n",
        "\n",
        "/* Primary button */\n",
        ".submit-button.primary {\n",
        "  background: linear-gradient(90deg, var(--primary), var(--primary-dark));\n",
        "  color: white;\n",
        "}\n",
        ".submit-button.primary:hover { transform: translateY(-2px); }\n",
        "\n",
        "/* Ghost button */\n",
        ".submit-button.ghost {\n",
        "  background: transparent;\n",
        "  border: 1px solid rgba(255,255,255,0.25);\n",
        "  color: white;\n",
        "}\n",
        ".submit-button.ghost:hover {\n",
        "  background: rgba(255,255,255,0.05);\n",
        "}\n",
        "\n",
        "/* Success button */\n",
        ".submit-button.success {\n",
        "  background: linear-gradient(90deg, var(--success), #0d9a72);\n",
        "  color: #fff;\n",
        "}\n",
        "\n",
        "/* ============================================================\n",
        "   STATUS MESSAGES + LOADING\n",
        "   ============================================================ */\n",
        ".status-message {\n",
        "  margin-top: 16px;\n",
        "  padding: 12px;\n",
        "  border-radius: 10px;\n",
        "  font-weight: 600;\n",
        "  display: none;\n",
        "  animation: fadein 0.2s ease-in;\n",
        "}\n",
        "\n",
        ".status-message.info {\n",
        "  background: rgba(59,130,246,0.15);\n",
        "  color: #93c5fd;\n",
        "  display: block;\n",
        "}\n",
        "\n",
        ".status-message.success {\n",
        "  background: rgba(16,185,129,0.15);\n",
        "  color: #6ee7b7;\n",
        "  display: block;\n",
        "}\n",
        "\n",
        ".status-message.error {\n",
        "  background: rgba(239,68,68,0.15);\n",
        "  color: #fca5a5;\n",
        "  display: block;\n",
        "}\n",
        "\n",
        "/* Loader spinner */\n",
        ".spinner {\n",
        "  width: 36px;\n",
        "  height: 36px;\n",
        "  border: 4px solid rgba(255,255,255,0.15);\n",
        "  border-top: 4px solid var(--primary);\n",
        "  border-radius: 50%;\n",
        "  margin: 0 auto;\n",
        "  animation: spin 1s linear infinite;\n",
        "}\n",
        "\n",
        "@keyframes spin { 100% { transform: rotate(360deg); } }\n",
        "\n",
        "/* ============================================================\n",
        "   CLUSTER BADGES\n",
        "   ============================================================ */\n",
        ".ai-badge {\n",
        "  padding: 10px 16px;\n",
        "  border-radius: 30px;\n",
        "  font-weight: 800;\n",
        "  margin-bottom: 16px;\n",
        "  display: inline-block;\n",
        "  font-size: 14px;\n",
        "  animation: fadein 0.2s ease-in;\n",
        "}\n",
        "\n",
        ".cluster-0 { background: var(--c0); color: #000; }\n",
        ".cluster-1 { background: var(--c1); color: #000; }\n",
        ".cluster-2 { background: var(--c2); color: #000; }\n",
        ".cluster-3 { background: var(--c3); color: #000; }\n",
        ".cluster-4 { background: var(--c4); color: #000; }\n",
        ".cluster-5 { background: var(--c5); color: #000; }\n",
        "\n",
        "/* ============================================================\n",
        "   RESPONSIVE\n",
        "   ============================================================ */\n",
        "@media (max-width: 600px) {\n",
        "  .main-form { padding: 20px; }\n",
        "  .page-title { font-size: 26px; }\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG7MNN-MAp4Z"
      },
      "source": [
        "\ud83d\udcd8 Kill Previous Processes\n",
        "\n",
        "This ensures Flask and ngrok do not conflict:\n",
        "\n",
        "- Stops earlier Flask sessions  \n",
        "- Stops older ngrok tunnels  \n",
        "- Prevents \"port already in use\" errors  \n",
        "\n",
        "Safe to run every time before starting server.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln9_FC2MGZVr"
      },
      "outputs": [],
      "source": [
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOBw6Kv3Ap4a"
      },
      "source": [
        "\ud83d\udcd8  Checking Port 8000 (User Instructions)\n",
        "\n",
        "If server fails, port 8000 may be occupied.\n",
        "\n",
        "Run:\n",
        "!lsof -i :8000\n",
        "\n",
        "If you see:\n",
        "python   12345 LISTEN\n",
        "\n",
        "Kill it with:\n",
        "!kill -9 12345\n",
        "\n",
        "Then launch Flask again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7irFjgwvTaz5"
      },
      "outputs": [],
      "source": [
        "!lsof -i :8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9ZcAoPTTaz5"
      },
      "outputs": [],
      "source": [
        "!kill -9 8369"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmW0zl-hAp4a"
      },
      "source": [
        "\ud83d\udcd8  Run Flask App in Background\n",
        "\n",
        "Starts backend without blocking the notebook:\n",
        "\n",
        "!nohup python app.py > flask.log 2>&1 &\n",
        "\n",
        "Logs are stored in flask.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrkDsB4fKuQ1"
      },
      "outputs": [],
      "source": [
        "!nohup python app.py > flask.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q6t7avIAp4b"
      },
      "source": [
        "\ud83d\udcd8  Ngrok Setup\n",
        "\n",
        "Ngrok provides a public HTTPS link.\n",
        "\n",
        "Your ngrok token was removed for safety.\n",
        "\n",
        "To use ngrok:\n",
        "1. Get token \u2192 https://dashboard.ngrok.com/get-started/your-authtoken  \n",
        "2. Add inside notebook:\n",
        "\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "3. Start tunnel:\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "\n",
        "Shareable app link appears here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KTiYDH0gsO2"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "!sleep 3 && tail -n 30 flask.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OD1cPc3Ap4b"
      },
      "source": [
        "\ud83d\udcd8  View Logs\n",
        "\n",
        "To debug backend:\n",
        "\n",
        "!tail -n 20 flask.log\n",
        "\n",
        "Shows:\n",
        "- Model loading issues  \n",
        "- Prompt errors  \n",
        "- Script formatting errors  \n",
        "- Runtime crashes  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqlHxRweTaz6"
      },
      "outputs": [],
      "source": [
        "!tail -n 50 flask.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8HijxzcTaz6"
      },
      "outputs": [],
      "source": []
    }
  ]
}