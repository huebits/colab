{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e3 Project Introduction\n",
        "\n",
        "# \u26a1 OmniAI Cloud \u2014 Unified Vision + NLP + OCR + Translation Suite\n",
        "\n",
        "This notebook builds a complete multi-module AI platform containing:\n",
        "\n",
        "- \ud83d\uddbc\ufe0f Image Captioning (BLIP Transformer)\n",
        "- \ud83d\udd0e OCR with Currency Correction (EasyOCR)\n",
        "- \ud83e\udde0 Text Analytics (Sentiment + Keyword Extraction)\n",
        "- \ud83c\udf0d Neural Machine Translation (OPUS-MT Models)\n",
        "- \ud83c\udfa8 Neon Glassmorphism UI with modular pages\n",
        "- \ud83d\ude80 Flask backend + ngrok deployment\n",
        "\n",
        "All tasks are combined into a single cloud dashboard with modern UI, \n",
        "lazy-loaded models, Hugging Face integration, and GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 2\ufe0f\u20e3 Concepts Covered in This Project\n",
        "\n",
        "OmniAI Cloud teaches the foundations of multi-modal AI:\n",
        "\n",
        "1. Vision (BLIP)\n",
        "   - Image \u2192 Text caption generation\n",
        "   - Transformer-based encoder\u2013decoder models\n",
        "\n",
        "2. OCR (Optical Character Recognition)\n",
        "   - EasyOCR GPU pipeline\n",
        "   - Post-processing for INR \u201c\u20b9\u201d cleanup\n",
        "   - Automatic formatting\n",
        "\n",
        "3. NLP Analytics\n",
        "   - Sentiment classification using DistilBERT\n",
        "   - Keyword extraction using YAKE\n",
        "   - Ranking, scoring, text cleanup\n",
        "\n",
        "4. Translation\n",
        "   - Traditional encoder\u2013decoder MT using OPUS-MT\n",
        "   - Language pair mapping logic\n",
        "   - Caching for fast multi-request translation\n",
        "\n",
        "5. Web App Architecture\n",
        "   - Flask routing structure\n",
        "   - Flash messages\n",
        "   - Unified base.html layout\n",
        "   - Static asset management\n",
        "\n",
        "6. UI/UX Engineering\n",
        "   - Neon gradient backgrounds\n",
        "   - Glass panels\n",
        "   - Responsive grid layout\n",
        "   - Toast notifications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 3\ufe0f\u20e3 Install Dependencies\n",
        "\n",
        "This cell installs all required libraries:\n",
        "\n",
        "- Flask \u2192 backend framework\n",
        "- transformers \u2192 BLIP, BERT, OPUS-MT pipelines\n",
        "- easyocr \u2192 OCR engine with multilingual support\n",
        "- yake \u2192 keyword extraction\n",
        "- pillow \u2192 image processing\n",
        "- opencv-python-headless \u2192 image manipulation without GUI\n",
        "- torch + torchvision \u2192 GPU inference\n",
        "- pyngrok \u2192 deploy the app publicly\n",
        "\n",
        "Also creates:\n",
        "templates/\n",
        "static/\n",
        "uploads/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 217252,
          "status": "ok",
          "timestamp": 1762777565865,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "iwAM_xQbbzqe",
        "outputId": "09063add-ff2c-4c11-d812-461159c26deb"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 1\ufe0f\u20e3 Install dependencies\n",
        "# ===============================\n",
        "!pip install -q flask transformers easyocr yake pillow opencv-python-headless torch torchvision --upgrade\n",
        "!mkdir -p templates static uploads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 18348,
          "status": "ok",
          "timestamp": 1762504678270,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "PCenxpG2dq2C",
        "outputId": "c11532fc-f816-43ee-f694-812e2e0de7e6"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 4\ufe0f\u20e3 Hugging Face Authentication\n",
        "\n",
        "Your original token has been removed for security.\n",
        "\n",
        "To load BLIP and OPUS-MT models:\n",
        "\n",
        "1. Open: https://huggingface.co/settings/tokens  \n",
        "2. Generate a token \u2192 set permission to \"Read\"\n",
        "3. Copy the token\n",
        "4. Replace inside the notebook:\n",
        "\n",
        "login(token=\"YOUR_HF_TOKEN_HERE\")\n",
        "\n",
        "\u26a0\ufe0f Never expose your token in GitHub, Kaggle public, or screenshots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-reBCHPFcM87"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 2\ufe0f\u20e3 Hugging Face Authentication\n",
        "# ===============================\n",
        "from huggingface_hub import login\n",
        "login(token=\"YOUR_HF_TOKEN_HERE\")  # \ud83d\udd11 replace with your HF token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 5\ufe0f\u20e3 Application Architecture Overview\n",
        "\n",
        "OmniAI Cloud is structured as a modular AI suite:\n",
        "\n",
        "          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "          \u2502   Home UI    \u2502\n",
        "          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "                 \u2502\n",
        "     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "     \u25bc           \u25bc            \u25bc             \u25bc               \u25bc\n",
        "Image Caption  OCR        Text Analytics  Translation     About\n",
        "(BLIP)         (EasyOCR)  (Sentiment +    (OPUS-MT)\n",
        "                            YAKE)\n",
        "\n",
        "Each module has:\n",
        "- Its own Flask route\n",
        "- Its own template\n",
        "- Lazy-loaded model for performance\n",
        "- Beautiful neon\u2013glass UI styling\n",
        "\n",
        "Shared:\n",
        "- base.html (layout)\n",
        "- style.css (global theme)\n",
        "- Unified flash notifications\n",
        "- Single uploads directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 6\ufe0f\u20e3 Image Captioning (BLIP)\n",
        "\n",
        "Uses:\n",
        "  Salesforce/blip-image-captioning-base\n",
        "\n",
        "Flow:\n",
        "1. Upload image\n",
        "2. Validate format + size\n",
        "3. Preprocess using BLIP processor\n",
        "4. Generate caption with BLIP model.generate()\n",
        "5. Display result inside glowing caption bubble\n",
        "\n",
        "Supports:\n",
        "- PNG / JPG / JPEG / WEBP up to 20MB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 7\ufe0f\u20e3 OCR with Currency Correction\n",
        "\n",
        "OCR Engine:\n",
        "- EasyOCR (GPU enabled if available)\n",
        "\n",
        "Pipeline:\n",
        "1. Read and preprocess image\n",
        "2. Extract full paragraphs (detail=0, paragraph=True)\n",
        "3. Cleanup + normalization via custom regex rules:\n",
        "   - Detect prices\n",
        "   - Convert \"INR\", \"Rs\", or text-detected \"7xxxx\" \u2192 \u20b9xxxx\n",
        "\n",
        "Displayed using:\n",
        "<pre class=\"mono\">\u2026</pre>\n",
        "\n",
        "This ensures neat, readable OCR output suitable for invoices and receipts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 8\ufe0f\u20e3 Text Analytics\n",
        "\n",
        "Two NLP modules are provided:\n",
        "\n",
        "1. Sentiment Analysis:\n",
        "   Model: distilbert-base-uncased-finetuned-sst-2-english\n",
        "   Output:\n",
        "     - Label (POSITIVE/NEGATIVE)\n",
        "     - Confidence score (0\u2013100%)\n",
        "\n",
        "2. Keyword Extraction:\n",
        "   Using YAKE:\n",
        "     - Top 10 ranked keywords\n",
        "     - Deduplication (dedupLim=0.9)\n",
        "     - Score-based sorting\n",
        "\n",
        "Results displayed in:\n",
        "- Chips (sentiment)\n",
        "- Table-style grid (keywords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 9\ufe0f\u20e3 Neural Machine Translation\n",
        "\n",
        "Model: Helsinki-NLP/opus-mt-<src>-<tgt>\n",
        "\n",
        "Pipeline:\n",
        "1. User selects Source and Target languages\n",
        "2. Text is validated\n",
        "3. Translation pipeline loads via @lru_cache\n",
        "4. Output is wrapped in glowing caption bubble\n",
        "\n",
        "Supported languages:\n",
        "- English\n",
        "- French\n",
        "- German\n",
        "- Spanish\n",
        "- Hindi\n",
        "- Italian\n",
        "- Chinese\n",
        "- Japanese\n",
        "- Russian\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 \ud83d\udd1f Flask Routing Overview\n",
        "\n",
        "Routes included:\n",
        "\n",
        "GET /\n",
        " \u2192 Dashboard home\n",
        "\n",
        "GET /vision\n",
        "POST /vision\n",
        " \u2192 BLIP Image Captioning\n",
        "\n",
        "GET /ocr\n",
        "POST /ocr\n",
        " \u2192 EasyOCR extraction\n",
        "\n",
        "GET /nlp\n",
        "POST /nlp\n",
        " \u2192 Sentiment + Keyword extraction\n",
        "\n",
        "GET /translate\n",
        "POST /translate\n",
        " \u2192 Neural machine translation\n",
        "\n",
        "GET /about\n",
        " \u2192 Project details\n",
        "\n",
        "GET /uploads/<file>\n",
        " \u2192 Serve uploaded images back to UI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 264,
          "status": "ok",
          "timestamp": 1762506718090,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "cY9eX5NccM5m",
        "outputId": "c7b9035f-d30c-4b37-96b7-198d9179993c"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 3\ufe0f\u20e3 Create app.py (Main Flask Application)\n",
        "# ===============================\n",
        "%%writefile app.py\n",
        "import os, functools, uuid, torch, re\n",
        "from flask import Flask, render_template, request, redirect, url_for, send_from_directory, flash\n",
        "from werkzeug.utils import secure_filename\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import yake\n",
        "\n",
        "# -------------------------------\n",
        "# Flask setup\n",
        "# -------------------------------\n",
        "app = Flask(__name__)\n",
        "app.secret_key = \"omni_secret_\" + str(uuid.uuid4())[:8]\n",
        "app.config[\"UPLOAD_FOLDER\"] = \"uploads\"\n",
        "app.config[\"MAX_CONTENT_LENGTH\"] = 20 * 1024 * 1024  # 20 MB\n",
        "\n",
        "ALLOWED_IMG = {\"png\", \"jpg\", \"jpeg\", \"webp\"}\n",
        "\n",
        "def allowed_file(filename, exts):\n",
        "    return \".\" in filename and filename.rsplit(\".\", 1)[1].lower() in exts\n",
        "\n",
        "# -------------------------------\n",
        "# Lazy loaders for models\n",
        "# -------------------------------\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_image_captioner():\n",
        "    \"\"\"BLIP model for image captioning\"\"\"\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    return processor, model\n",
        "\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_sentiment():\n",
        "    return pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_keyword_extractor():\n",
        "    return yake.KeywordExtractor(lan=\"en\", n=1, top=10, dedupLim=0.9)\n",
        "\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_ocr_reader():\n",
        "    return easyocr.Reader([\"en\"], gpu=torch.cuda.is_available())\n",
        "\n",
        "# -------------------------------\n",
        "# OCR Post-Processing Correction\n",
        "# -------------------------------\n",
        "def clean_ocr_text(text):\n",
        "    text = re.sub(r\"(?<=\\b)7(?=\\s*\\d{1,3}(?:,?\\d{3})*)\", \"\u20b9\", text)\n",
        "    text = re.sub(r\"^7(?=\\d{1,3}(?:,?\\d{3})*)\", \"\u20b9\", text)\n",
        "    text = re.sub(r\"(?<=\\s)7(?=\\d{1,3}(?:,?\\d{3})*)\", \"\u20b9\", text)\n",
        "    text = re.sub(r\"\\bINR\\s*\", \"\u20b9\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"Rs\\.?\\s*\", \"\u20b9\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "# -------------------------------\n",
        "# Routes\n",
        "# -------------------------------\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/about\")\n",
        "def about():\n",
        "    return render_template(\"about.html\")\n",
        "\n",
        "# ---------- Vision (BLIP Captioning) ----------\n",
        "@app.route(\"/vision\", methods=[\"GET\", \"POST\"])\n",
        "def vision():\n",
        "    caption = None\n",
        "    filename = None\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files.get(\"image\")\n",
        "        if not file or file.filename == \"\":\n",
        "            flash(\"Please upload an image.\", \"warn\")\n",
        "            return redirect(url_for(\"vision\"))\n",
        "        if not allowed_file(file.filename, ALLOWED_IMG):\n",
        "            flash(\"Unsupported file type. Use png/jpg/jpeg/webp.\", \"error\")\n",
        "            return redirect(url_for(\"vision\"))\n",
        "\n",
        "        filename = secure_filename(file.filename)\n",
        "        save_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], f\"{uuid.uuid4().hex}_{filename}\")\n",
        "        file.save(save_path)\n",
        "\n",
        "        try:\n",
        "            processor, model = get_image_captioner()\n",
        "            image = Image.open(save_path).convert(\"RGB\")\n",
        "            inputs = processor(image, return_tensors=\"pt\").to(model.device)\n",
        "            out = model.generate(**inputs)\n",
        "            caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "        except Exception as e:\n",
        "            flash(f\"Image captioning failed: {e}\", \"error\")\n",
        "            caption = None\n",
        "\n",
        "        filename = os.path.basename(save_path)\n",
        "    return render_template(\"image_classification.html\", caption=caption, filename=filename)\n",
        "\n",
        "# ---------- OCR ----------\n",
        "@app.route(\"/ocr\", methods=[\"GET\", \"POST\"])\n",
        "def ocr():\n",
        "    text = None\n",
        "    filename = None\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files.get(\"image\")\n",
        "        if not file or file.filename == \"\":\n",
        "            flash(\"Please upload an image.\", \"warn\")\n",
        "            return redirect(url_for(\"ocr\"))\n",
        "        if not allowed_file(file.filename, ALLOWED_IMG):\n",
        "            flash(\"Unsupported file type. Use png/jpg/jpeg/webp.\", \"error\")\n",
        "            return redirect(url_for(\"ocr\"))\n",
        "\n",
        "        filename = secure_filename(file.filename)\n",
        "        save_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], f\"{uuid.uuid4().hex}_{filename}\")\n",
        "        file.save(save_path)\n",
        "\n",
        "        reader = get_ocr_reader()\n",
        "        try:\n",
        "            img = Image.open(save_path).convert(\"RGB\")\n",
        "            arr = np.array(img)\n",
        "            ocr_out = reader.readtext(arr, detail=0, paragraph=True)\n",
        "            raw_text = \"\\n\".join([t.strip() for t in ocr_out if t and t.strip()])\n",
        "            text = clean_ocr_text(raw_text)\n",
        "        except Exception as e:\n",
        "            flash(f\"OCR failed: {e}\", \"error\")\n",
        "            text = None\n",
        "\n",
        "        filename = os.path.basename(save_path)\n",
        "    return render_template(\"ocr.html\", text=text, filename=filename)\n",
        "\n",
        "# ---------- Text Analytics ----------\n",
        "@app.route(\"/nlp\", methods=[\"GET\", \"POST\"])\n",
        "def nlp():\n",
        "    sentiment = None\n",
        "    keywords = []\n",
        "    user_text = \"\"\n",
        "    if request.method == \"POST\":\n",
        "        user_text = request.form.get(\"text\", \"\").strip()\n",
        "        if not user_text:\n",
        "            flash(\"Please enter some text.\", \"warn\")\n",
        "            return redirect(url_for(\"nlp\"))\n",
        "        try:\n",
        "            sent_pipe = get_sentiment()\n",
        "            sentiment = sent_pipe(user_text)[0]\n",
        "        except Exception as e:\n",
        "            flash(f\"Sentiment failed: {e}\", \"error\")\n",
        "        try:\n",
        "            ke = get_keyword_extractor()\n",
        "            kws = ke.extract_keywords(user_text)\n",
        "            kws = sorted(kws, key=lambda x: x[1])[:10]\n",
        "            keywords = [{\"term\": k, \"score\": round(s, 4)} for k, s in kws]\n",
        "        except Exception as e:\n",
        "            flash(f\"Keyword extraction failed: {e}\", \"error\")\n",
        "    return render_template(\"text_analytics.html\", sentiment=sentiment, keywords=keywords, user_text=user_text)\n",
        "\n",
        "# ---------- Translation ----------\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_translator(src=\"en\", tgt=\"fr\"):\n",
        "    model_name = f\"Helsinki-NLP/opus-mt-{src}-{tgt}\"\n",
        "    return pipeline(\"translation\", model=model_name)\n",
        "\n",
        "LANG_MAP = {\n",
        "    \"en\": \"English\",\n",
        "    \"fr\": \"French\",\n",
        "    \"de\": \"German\",\n",
        "    \"es\": \"Spanish\",\n",
        "    \"hi\": \"Hindi\",\n",
        "    \"it\": \"Italian\",\n",
        "    \"zh\": \"Chinese\",\n",
        "    \"ja\": \"Japanese\",\n",
        "    \"ru\": \"Russian\"\n",
        "}\n",
        "\n",
        "@app.route(\"/translate\", methods=[\"GET\", \"POST\"])\n",
        "def translate():\n",
        "    output_text = None\n",
        "    src_lang = \"en\"\n",
        "    tgt_lang = \"fr\"\n",
        "    input_text = \"\"\n",
        "    if request.method == \"POST\":\n",
        "        input_text = request.form.get(\"text\", \"\").strip()\n",
        "        src_lang = request.form.get(\"source_lang\", \"en\")\n",
        "        tgt_lang = request.form.get(\"target_lang\", \"fr\")\n",
        "        if not input_text:\n",
        "            flash(\"Please enter text to translate.\", \"warn\")\n",
        "            return redirect(url_for(\"translate\"))\n",
        "        try:\n",
        "            translator = get_translator(src_lang, tgt_lang)\n",
        "            translated = translator(input_text, max_length=400)\n",
        "            output_text = translated[0][\"translation_text\"]\n",
        "        except Exception as e:\n",
        "            flash(f\"Translation failed: {e}\", \"error\")\n",
        "    return render_template(\"translate.html\", LANG_MAP=LANG_MAP, src_lang=src_lang,\n",
        "                           tgt_lang=tgt_lang, input_text=input_text, output_text=output_text)\n",
        "\n",
        "# ---------- Serve uploads ----------\n",
        "@app.route(\"/uploads/<path:fname>\")\n",
        "def uploads(fname):\n",
        "    return send_from_directory(app.config[\"UPLOAD_FOLDER\"], fname)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.makedirs(app.config[\"UPLOAD_FOLDER\"], exist_ok=True)\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 75,
          "status": "ok",
          "timestamp": 1762506718901,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "4N00sHPvcM3v",
        "outputId": "5351943b-2d4a-409f-adc4-d4c83283e600"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/base.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>OmniAI Cloud \u2013 Mini</title>\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "  <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
        "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"bg\"></div>\n",
        "\n",
        "  <nav class=\"nav\">\n",
        "    <a class=\"brand\" href=\"{{ url_for('home') }}\">\u26a1 OmniAI Cloud</a>\n",
        "    <div class=\"links\">\n",
        "      <a href=\"{{ url_for('vision') }}\">\ud83d\uddbc\ufe0f Vision</a>\n",
        "      <a href=\"{{ url_for('ocr') }}\">\ud83d\udd0e OCR</a>\n",
        "      <a href=\"{{ url_for('nlp') }}\">\ud83e\udde0 Text Analytics</a>\n",
        "      <a href=\"{{ url_for('translate') }}\">\ud83c\udf0d Translate</a>\n",
        "      <a href=\"{{ url_for('about') }}\">\u2139\ufe0f About</a>\n",
        "    </div>\n",
        "  </nav>\n",
        "\n",
        "  <main class=\"container\">\n",
        "    {% with messages = get_flashed_messages(with_categories=true) %}\n",
        "      {% if messages %}\n",
        "      <div class=\"toast-wrap\">\n",
        "        {% for cat, msg in messages %}\n",
        "          <div class=\"toast {{ cat }}\">{{ msg }}</div>\n",
        "        {% endfor %}\n",
        "      </div>\n",
        "      {% endif %}\n",
        "    {% endwith %}\n",
        "    {% block content %}{% endblock %}\n",
        "  </main>\n",
        "\n",
        "  <footer class=\"footer\">\n",
        "    <span>\u00a9 {{ 2025 }} OmniAI Cloud \u2022 Neon UI</span>\n",
        "  </footer>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e31\ufe0f\u20e3 Frontend Templates\n",
        "\n",
        "Templates included:\n",
        "\n",
        "base.html  \n",
        "- Shared layout\n",
        "- Navbar + footer\n",
        "- Toast messages\n",
        "- Background neon gradients\n",
        "\n",
        "index.html  \n",
        "- Hero section\n",
        "- Feature grid\n",
        "\n",
        "image_classification.html  \n",
        "- Upload \u2192 Caption pipeline\n",
        "- BLIP results bubble\n",
        "\n",
        "ocr.html  \n",
        "- Preview uploaded image\n",
        "- Extracted text area\n",
        "\n",
        "text_analytics.html  \n",
        "- Sentiment + keywords table\n",
        "\n",
        "translate.html  \n",
        "- Language dropdowns\n",
        "- Glowing translation output\n",
        "\n",
        "about.html  \n",
        "- Tech stack showcase\n",
        "- Description of each module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 47,
          "status": "ok",
          "timestamp": 1762506719665,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "--sesBFHcM1F",
        "outputId": "b3006774-7c4e-41a3-f7fd-88a3e2db8cd5"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/index.html\n",
        "{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<section class=\"hero glass glow\">\n",
        "  <h1>Unified Vision & Language Intelligence</h1>\n",
        "  <p>Run image captioning, OCR, text analytics, and translation in a single futuristic dashboard.</p>\n",
        "  <div class=\"cta-row\">\n",
        "    <a class=\"btn primary\" href=\"{{ url_for('vision') }}\">\ud83d\uddbc\ufe0f Try Image Captioning</a>\n",
        "    <a class=\"btn\" href=\"{{ url_for('ocr') }}\">\ud83d\udd0e Run OCR</a>\n",
        "    <a class=\"btn\" href=\"{{ url_for('nlp') }}\">\ud83e\udde0 Analyze Text</a>\n",
        "    <a class=\"btn\" href=\"{{ url_for('translate') }}\">\ud83c\udf0d Translate Text</a>\n",
        "  </div>\n",
        "</section>\n",
        "\n",
        "<section class=\"grid\">\n",
        "  <div class=\"card glass hover-rise\">\n",
        "    <h3>\ud83d\uddbc\ufe0f Vision</h3>\n",
        "    <p>Generate descriptive captions for uploaded images.</p>\n",
        "    <a class=\"link\" href=\"{{ url_for('vision') }}\">Open</a>\n",
        "  </div>\n",
        "  <div class=\"card glass hover-rise\">\n",
        "    <h3>\ud83d\udd0e OCR</h3>\n",
        "    <p>Extract text from images and scanned documents.</p>\n",
        "    <a class=\"link\" href=\"{{ url_for('ocr') }}\">Open</a>\n",
        "  </div>\n",
        "  <div class=\"card glass hover-rise\">\n",
        "    <h3>\ud83e\udde0 Text Analytics</h3>\n",
        "    <p>Analyze sentiment and extract key terms from text.</p>\n",
        "    <a class=\"link\" href=\"{{ url_for('nlp') }}\">Open</a>\n",
        "  </div>\n",
        "  <div class=\"card glass hover-rise\">\n",
        "    <h3>\ud83c\udf0d Translation</h3>\n",
        "    <p>Translate text seamlessly across multiple languages.</p>\n",
        "    <a class=\"link\" href=\"{{ url_for('translate') }}\">Open</a>\n",
        "  </div>\n",
        "</section>\n",
        "{% endblock %}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 37,
          "status": "ok",
          "timestamp": 1762506720401,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "aZsdsRvOcUKc",
        "outputId": "49c30b7d-4fd1-47bf-ddff-5ae65ac0dc89"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/image_classification.html\n",
        "{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<div class=\"page-title\">\n",
        "  <h2>\ud83e\ude84 Image Captioning</h2>\n",
        "  <p>Upload an image to generate a smart descriptive caption using BLIP.</p>\n",
        "</div>\n",
        "\n",
        "<form class=\"uploader glass\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "  <label for=\"image\" class=\"dropzone\">\n",
        "    <span>Drag & drop or click to upload</span>\n",
        "    <small>PNG / JPG / JPEG / WEBP \u2022 max 20MB</small>\n",
        "  </label>\n",
        "  <input id=\"image\" name=\"image\" type=\"file\" accept=\"image/*\" required />\n",
        "  <button class=\"btn primary\" type=\"submit\">Generate Caption \ud83d\ude80</button>\n",
        "</form>\n",
        "\n",
        "{% if filename %}\n",
        "<div class=\"preview-wrap\">\n",
        "  <img class=\"preview\" src=\"{{ url_for('uploads', fname=filename) }}\" alt=\"uploaded\">\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "{% if caption %}\n",
        "<div class=\"results glass glow\">\n",
        "  <h3>Generated Caption \u2728</h3>\n",
        "  <div class=\"caption-bubble\">\n",
        "    <p class=\"caption-text\">\"{{ caption }}\"</p>\n",
        "  </div>\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "<style>\n",
        ".caption-bubble {\n",
        "  margin-top: 15px;\n",
        "  padding: 18px 22px;\n",
        "  border-radius: 14px;\n",
        "  border: 1px solid rgba(45, 226, 230, 0.4);\n",
        "  background: linear-gradient(145deg, rgba(45, 226, 230, 0.1), rgba(154, 77, 255, 0.1));\n",
        "  box-shadow: 0 0 20px rgba(45, 226, 230, 0.2), 0 0 40px rgba(154, 77, 255, 0.15);\n",
        "  text-align: center;\n",
        "  animation: glowPulse 3s ease-in-out infinite;\n",
        "}\n",
        "\n",
        ".caption-text {\n",
        "  font-size: 1.25rem;\n",
        "  color: #e4e8ff;\n",
        "  font-weight: 500;\n",
        "  letter-spacing: 0.4px;\n",
        "  text-shadow: 0 0 10px rgba(45, 226, 230, 0.4);\n",
        "}\n",
        "\n",
        "@keyframes glowPulse {\n",
        "  0% { box-shadow: 0 0 15px rgba(45, 226, 230, 0.2); }\n",
        "  50% { box-shadow: 0 0 30px rgba(154, 77, 255, 0.35); }\n",
        "  100% { box-shadow: 0 0 15px rgba(45, 226, 230, 0.2); }\n",
        "}\n",
        "</style>\n",
        "{% endblock %}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 28,
          "status": "ok",
          "timestamp": 1762506721146,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "aHUSi-M1cWP7",
        "outputId": "0c33733a-6f1b-4f24-ef18-d722109ffcf6"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/ocr.html\n",
        "{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<div class=\"page-title\">\n",
        "  <h2>\ud83d\udd0e OCR \u2013 Text Detection</h2>\n",
        "  <p>Extract text from uploaded images and scanned documents with smart currency correction.</p>\n",
        "</div>\n",
        "\n",
        "<form class=\"uploader glass\" method=\"post\" enctype=\"multipart/form-data\" id=\"ocrForm\">\n",
        "  <label for=\"image\" class=\"dropzone\">\n",
        "    <span>Drag & drop or click to upload</span>\n",
        "    <small>PNG / JPG / JPEG / WEBP \u2022 max 20MB</small>\n",
        "  </label>\n",
        "  <input id=\"image\" name=\"image\" type=\"file\" accept=\"image/*\" required onchange=\"previewImage(event)\" />\n",
        "  <button class=\"btn primary\" type=\"submit\">Run OCR \u2728</button>\n",
        "</form>\n",
        "\n",
        "<div class=\"preview-wrap\" id=\"previewWrap\" style=\"display:none;\">\n",
        "  <h3 style=\"margin-bottom:8px;\">\ud83d\udcf7 Uploaded Image</h3>\n",
        "  <img id=\"previewImg\" class=\"preview\" src=\"#\" alt=\"uploaded preview\">\n",
        "</div>\n",
        "\n",
        "{% if text %}\n",
        "<div class=\"results glass glow\">\n",
        "  <h3>\ud83e\uddfe Extracted Text</h3>\n",
        "  <pre class=\"mono\">{{ text }}</pre>\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "<script>\n",
        "function previewImage(event) {\n",
        "  const input = event.target;\n",
        "  const previewWrap = document.getElementById('previewWrap');\n",
        "  const previewImg = document.getElementById('previewImg');\n",
        "  if (input.files && input.files[0]) {\n",
        "    const reader = new FileReader();\n",
        "    reader.onload = function(e) {\n",
        "      previewImg.src = e.target.result;\n",
        "      previewWrap.style.display = \"block\";\n",
        "    };\n",
        "    reader.readAsDataURL(input.files[0]);\n",
        "  }\n",
        "}\n",
        "</script>\n",
        "{% endblock %}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXDhdkxrcYI6"
      },
      "outputs": [],
      "source": [
        "with open(\"templates/text_analytics.html\", \"w\") as f:\n",
        "    f.write(\"\"\"{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<div class=\"page-title\">\n",
        "  <h2>\ud83e\udde0 Text Analytics</h2>\n",
        "  <p>Sentiment classification + keyword extraction.</p>\n",
        "</div>\n",
        "\n",
        "<form class=\"card glass\" method=\"post\">\n",
        "  <textarea name=\"text\" rows=\"7\" placeholder=\"Paste or type text here...\" required>{{ user_text }}</textarea>\n",
        "  <button class=\"btn primary\" type=\"submit\">Analyze \ud83d\udd2c</button>\n",
        "</form>\n",
        "\n",
        "{% if sentiment %}\n",
        "<div class=\"results glass glow\">\n",
        "  <h3>Sentiment</h3>\n",
        "  <div class=\"chips\">\n",
        "    <span class=\"chip\">Label: {{ sentiment['label'] }}</span>\n",
        "    <span class=\"chip\">Confidence: {{ (sentiment['score'] * 100) | round(2) }}%</span>\n",
        "  </div>\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "{% if keywords %}\n",
        "<div class=\"results glass\">\n",
        "  <h3>Keywords</h3>\n",
        "  <div class=\"table\">\n",
        "    <div class=\"row header\"><div>Keyword</div><div>Score</div></div>\n",
        "    {% for kw in keywords %}\n",
        "      <div class=\"row\"><div>{{ kw.term }}</div><div>{{ kw.score }}</div></div>\n",
        "    {% endfor %}\n",
        "  </div>\n",
        "</div>\n",
        "{% endif %}\n",
        "{% endblock %}\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 31,
          "status": "ok",
          "timestamp": 1762506723156,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "j6If4obvkdj_",
        "outputId": "e62ea669-577e-43fa-c424-bb9040a4d9ea"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/translate.html\n",
        "{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<div class=\"page-title\">\n",
        "  <h2>\ud83c\udf0d Text Translation</h2>\n",
        "  <p>Translate text between multiple languages using neural machine translation models.</p>\n",
        "</div>\n",
        "\n",
        "<form class=\"card glass\" method=\"post\">\n",
        "  <div style=\"display:flex; gap:10px; flex-wrap:wrap;\">\n",
        "    <div style=\"flex:1;\">\n",
        "      <label>From:</label>\n",
        "      <select name=\"source_lang\" class=\"lang-select\">\n",
        "        {% for code, name in LANG_MAP.items() %}\n",
        "          <option value=\"{{ code }}\" {% if code == src_lang %}selected{% endif %}>{{ name }}</option>\n",
        "        {% endfor %}\n",
        "      </select>\n",
        "    </div>\n",
        "    <div style=\"flex:1;\">\n",
        "      <label>To:</label>\n",
        "      <select name=\"target_lang\" class=\"lang-select\">\n",
        "        {% for code, name in LANG_MAP.items() %}\n",
        "          <option value=\"{{ code }}\" {% if code == tgt_lang %}selected{% endif %}>{{ name }}</option>\n",
        "        {% endfor %}\n",
        "      </select>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <textarea name=\"text\" rows=\"6\" placeholder=\"Enter text to translate...\" required>{{ input_text }}</textarea>\n",
        "  <button class=\"btn primary\" type=\"submit\">Translate \ud83d\udd01</button>\n",
        "</form>\n",
        "\n",
        "{% if output_text %}\n",
        "<div class=\"results glass glow\">\n",
        "  <h3>Translated Output \u2728</h3>\n",
        "  <div class=\"caption-bubble\">\n",
        "    <p class=\"caption-text\">{{ output_text }}</p>\n",
        "  </div>\n",
        "</div>\n",
        "{% endif %}\n",
        "\n",
        "<style>\n",
        ".lang-select {\n",
        "  width: 100%;\n",
        "  padding: 10px;\n",
        "  border-radius: 10px;\n",
        "  border: 1px solid rgba(255,255,255,0.2);\n",
        "  background: rgba(255,255,255,0.08);\n",
        "  color: #fff;\n",
        "  font-size: 0.95rem;\n",
        "}\n",
        ".lang-select option {\n",
        "  color: black;\n",
        "}\n",
        ".caption-bubble {\n",
        "  margin-top: 15px;\n",
        "  padding: 18px 22px;\n",
        "  border-radius: 14px;\n",
        "  border: 1px solid rgba(45, 226, 230, 0.4);\n",
        "  background: linear-gradient(145deg, rgba(45, 226, 230, 0.1), rgba(154, 77, 255, 0.1));\n",
        "  box-shadow: 0 0 20px rgba(45, 226, 230, 0.2), 0 0 40px rgba(154, 77, 255, 0.15);\n",
        "  text-align: center;\n",
        "  animation: glowPulse 3s ease-in-out infinite;\n",
        "}\n",
        ".caption-text {\n",
        "  font-size: 1.2rem;\n",
        "  color: #e4e8ff;\n",
        "  text-shadow: 0 0 10px rgba(45, 226, 230, 0.4);\n",
        "}\n",
        "@keyframes glowPulse {\n",
        "  0% { box-shadow: 0 0 15px rgba(45, 226, 230, 0.2); }\n",
        "  50% { box-shadow: 0 0 30px rgba(154, 77, 255, 0.35); }\n",
        "  100% { box-shadow: 0 0 15px rgba(45, 226, 230, 0.2); }\n",
        "}\n",
        "</style>\n",
        "{% endblock %}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 65,
          "status": "ok",
          "timestamp": 1762506723960,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "8ksKgsr-cZ1G",
        "outputId": "566518ae-b656-4083-de2f-f2cea3743afd"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/about.html\n",
        "{% extends \"base.html\" %}\n",
        "{% block content %}\n",
        "<div class=\"page-title\">\n",
        "  <h2>\u2139\ufe0f About OmniAI Cloud (Mini)</h2>\n",
        "  <p>An integrated AI platform bringing Vision, OCR, Text Analytics, and Translation into one futuristic dashboard.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"card glass\">\n",
        "  <ul class=\"bullets\">\n",
        "    <li>\ud83d\uddbc\ufe0f Image Captioning \u2022 <em>BLIP (Salesforce/blip-image-captioning-base)</em></li>\n",
        "    <li>\ud83d\udd0e OCR \u2022 <em>EasyOCR (GPU-accelerated text extraction with currency correction)</em></li>\n",
        "    <li>\ud83e\udde0 Text Analytics \u2022 <em>Sentiment (DistilBERT) + Keywords (YAKE)</em></li>\n",
        "    <li>\ud83c\udf0d Text Translation \u2022 <em>Helsinki-NLP/opus-mt multilingual transformer models</em></li>\n",
        "  </ul>\n",
        "\n",
        "  <p>OmniAI Cloud (Mini) is built for Google Colab, featuring real-time GPU inference,\n",
        "  Hugging Face integration, and a glowing neon UI powered by glassmorphism for a modern AI-as-a-Service experience.</p>\n",
        "\n",
        "  <p style=\"margin-top:10px; color:#b7c0d8;\">\n",
        "    All modules share a unified interface, interactive previews, and a consistent visual style \u2014\n",
        "    making it a perfect demo for end-to-end AI applications on the cloud.\n",
        "  </p>\n",
        "</div>\n",
        "{% endblock %}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e32\ufe0f\u20e3 Neon Glassmorphism UI (CSS)\n",
        "\n",
        "The UI includes:\n",
        "\n",
        "- Multi-gradient neon backgrounds\n",
        "- Smooth glass cards (backdrop-filter blur)\n",
        "- Glowing edges on hover\n",
        "- Animated CTA buttons\n",
        "- Responsive grid system\n",
        "- Toast notifications for warnings/errors\n",
        "- Monospace formatted OCR text\n",
        "- Adaptive layout for mobile devices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 21,
          "status": "ok",
          "timestamp": 1762506726105,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "3CB77FnOccP9",
        "outputId": "eddb7d96-3f14-491d-d29a-90d25e12a63b"
      },
      "outputs": [],
      "source": [
        "%%writefile static/style.css\n",
        ":root{\n",
        "  --bg1:#0e0f24;\n",
        "  --bg2:#111b4b;\n",
        "  --cyan:#2de2e6;\n",
        "  --violet:#9a4dff;\n",
        "  --blue:#3b82f6;\n",
        "  --white:#f5f7ff;\n",
        "  --muted:#b7c0d8;\n",
        "  --glass: rgba(255,255,255,0.08);\n",
        "  --border: rgba(255,255,255,0.16);\n",
        "  --shadow: 0 10px 30px rgba(0,0,0,0.35);\n",
        "}\n",
        "\n",
        "*{box-sizing:border-box}\n",
        "html,body{height:100%}\n",
        "body{\n",
        "  margin:0; font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial;\n",
        "  color:var(--white); background:var(--bg1); overflow-x:hidden;\n",
        "}\n",
        "\n",
        ".bg{\n",
        "  position:fixed; inset:0; z-index:-1;\n",
        "  background: radial-gradient(1000px 800px at 20% 10%, rgba(45,226,230,0.25), transparent 60%),\n",
        "              radial-gradient(900px 700px at 80% 30%, rgba(154,77,255,0.25), transparent 60%),\n",
        "              radial-gradient(700px 600px at 50% 80%, rgba(59,130,246,0.25), transparent 60%),\n",
        "              linear-gradient(140deg, var(--bg1), var(--bg2));\n",
        "  filter:saturate(120%);\n",
        "}\n",
        "\n",
        ".nav{\n",
        "  display:flex; align-items:center; justify-content:space-between;\n",
        "  padding:14px 22px; position:sticky; top:0; backdrop-filter: blur(8px);\n",
        "  background:linear-gradient(to right, rgba(17,17,35,0.7), rgba(17,27,75,0.4));\n",
        "  border-bottom:1px solid var(--border); z-index:10;\n",
        "}\n",
        ".brand{font-weight:800; text-decoration:none; color:var(--white); letter-spacing:.2px}\n",
        ".links a{margin-left:14px; text-decoration:none; color:var(--muted)}\n",
        ".links a:hover{color:var(--white)}\n",
        "\n",
        ".container{max-width:1024px; margin:32px auto; padding:0 18px}\n",
        "\n",
        ".footer{\n",
        "  text-align:center; color:var(--muted); padding:24px 0; border-top:1px solid var(--border);\n",
        "  margin-top:50px; background:linear-gradient(to top, rgba(17,27,75,0.25), transparent);\n",
        "}\n",
        "\n",
        ".hero{\n",
        "  text-align:center; padding:36px 28px; border-radius:18px; box-shadow:var(--shadow);\n",
        "}\n",
        ".hero h1{margin:0 0 10px; font-size:36px; letter-spacing:.3px}\n",
        ".hero p{margin:0 0 18px; color:var(--muted)}\n",
        ".cta-row{display:flex; gap:12px; justify-content:center; flex-wrap:wrap}\n",
        "\n",
        ".btn{\n",
        "  padding:12px 16px; border-radius:12px; border:1px solid var(--border);\n",
        "  color:var(--white); text-decoration:none; display:inline-flex; align-items:center; gap:8px;\n",
        "  background:linear-gradient(180deg, rgba(255,255,255,0.05), rgba(255,255,255,0.02));\n",
        "  transition:transform .15s ease, box-shadow .15s ease, border-color .2s ease;\n",
        "}\n",
        ".btn.primary{\n",
        "  border-color:transparent;\n",
        "  background:linear-gradient(90deg, var(--cyan), var(--violet), var(--blue));\n",
        "  background-size:200% 100%; animation:shine 5s linear infinite;\n",
        "}\n",
        ".btn:hover{transform:translateY(-1px); box-shadow:0 8px 20px rgba(0,0,0,.35)}\n",
        "@keyframes shine{0%{background-position:0% 0}100%{background-position:200% 0}}\n",
        "\n",
        ".grid{\n",
        "  display:grid; grid-template-columns:repeat(auto-fit, minmax(220px,1fr)); gap:16px; margin-top:22px;\n",
        "}\n",
        ".card{\n",
        "  padding:18px; border-radius:16px; border:1px solid var(--border); background:var(--glass);\n",
        "}\n",
        ".link{color:var(--cyan); text-decoration:none}\n",
        ".link:hover{text-decoration:underline}\n",
        "\n",
        ".glass{backdrop-filter: blur(10px)}\n",
        ".glow{box-shadow:0 0 0 1px rgba(45,226,230,.15), 0 0 40px rgba(154,77,255,.15)}\n",
        "\n",
        ".hover-rise{transition:transform .18s ease, box-shadow .18s ease}\n",
        ".hover-rise:hover{transform:translateY(-3px); box-shadow:0 16px 40px rgba(0,0,0,.4)}\n",
        "\n",
        ".page-title h2{margin:.2rem 0 .25rem}\n",
        ".page-title p{margin:0; color:var(--muted)}\n",
        "\n",
        ".uploader{\n",
        "  margin:16px 0 10px; padding:18px; border-radius:16px; background:var(--glass); border:1px solid var(--border);\n",
        "  display:flex; flex-direction:column; gap:14px;\n",
        "}\n",
        ".dropzone{\n",
        "  display:flex; flex-direction:column; align-items:center; justify-content:center;\n",
        "  height:160px; border:2px dashed rgba(255,255,255,0.25); border-radius:14px; cursor:pointer;\n",
        "  color:var(--muted); transition:border-color .15s ease, color .15s ease;\n",
        "}\n",
        ".dropzone:hover{border-color:var(--cyan); color:var(--white)}\n",
        ".uploader input[type=file]{display:none}\n",
        "\n",
        ".preview-wrap{margin:14px 0}\n",
        ".preview{\n",
        "  width:100%; max-height:360px; object-fit:contain; border-radius:12px; border:1px solid var(--border);\n",
        "  background:rgba(0,0,0,.25)\n",
        "}\n",
        "\n",
        ".results{margin:18px 0; padding:18px; border-radius:16px; border:1px solid var(--border); background:var(--glass)}\n",
        ".chips{display:flex; flex-wrap:wrap; gap:10px; margin-top:6px}\n",
        ".chip{\n",
        "  padding:8px 12px; border-radius:999px; border:1px solid var(--border); background:rgba(255,255,255,0.06);\n",
        "}\n",
        "\n",
        ".card textarea{\n",
        "  width:100%; border:none; outline:none; resize:vertical; padding:12px;\n",
        "  border-radius:12px; color:var(--white); background:rgba(255,255,255,0.06);\n",
        "}\n",
        "\n",
        ".table{display:grid; gap:6px; margin-top:8px}\n",
        ".row{display:grid; grid-template-columns:2fr 1fr; gap:10px; padding:10px; border-radius:10px; background:rgba(255,255,255,0.05)}\n",
        ".row.header{font-weight:600; background:rgba(255,255,255,0.08)}\n",
        "\n",
        ".mono{\n",
        "  white-space:pre-wrap; word-wrap:break-word; font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, \"Liberation Mono\", monospace;\n",
        "  background:rgba(0,0,0,.25); padding:12px; border-radius:12px; border:1px solid var(--border);\n",
        "}\n",
        "\n",
        "/* Toasts */\n",
        ".toast-wrap{position:fixed; right:16px; bottom:16px; display:flex; flex-direction:column; gap:10px; z-index:20}\n",
        ".toast{\n",
        "  padding:10px 12px; border-radius:12px; border:1px solid var(--border); background:rgba(20,20,35,0.85);\n",
        "  box-shadow:var(--shadow); animation:fadeIn .3s ease both;\n",
        "}\n",
        ".toast.warn{border-color:#f59e0b; color:#fde68a}\n",
        ".toast.error{border-color:#ef4444; color:#fecaca}\n",
        "@keyframes fadeIn{from{opacity:0; transform:translateY(6px)} to{opacity:1; transform:translateY(0)}}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e33\ufe0f\u20e3 Kill Previous Flask/ngrok Sessions\n",
        "\n",
        "Running multiple Flask servers can cause:\n",
        "- Port 8000 already in use\n",
        "- ngrok tunnel conflicts\n",
        "\n",
        "Solution:\n",
        "!pkill -f flask\n",
        "!pkill -f ngrok\n",
        "\n",
        "Check running processes:\n",
        "!lsof -i :8000\n",
        "\n",
        "Kill specific PID:\n",
        "!kill -9 <PID>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 360,
          "status": "ok",
          "timestamp": 1762506727600,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "gX-KmSAgqXer",
        "outputId": "31298964-516c-4da1-a4a1-a242a8be19f9"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 6\ufe0f\u20e3 Kill any previous processes\n",
        "# ===============================\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZgowrU9qmd5"
      },
      "outputs": [],
      "source": [
        "!lsof -i :8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 129,
          "status": "ok",
          "timestamp": 1762506736521,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "9PgxXT0NqXcL",
        "outputId": "77a20d75-cb8b-470a-ca44-b75f67dea953"
      },
      "outputs": [],
      "source": [
        "!kill -9 6620"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e34\ufe0f\u20e3 Run Flask in Background\n",
        "\n",
        "Start server silently:\n",
        "\n",
        "!nohup python app.py > flask.log 2>&1 &\n",
        "\n",
        "This keeps the server running even if the cell is stopped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQJlJGhDqo1m"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 7\ufe0f\u20e3 Run Flask in the background\n",
        "# ===============================\n",
        "!nohup python app.py > flask.log 2>&1 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e35\ufe0f\u20e3 Start ngrok Tunnel\n",
        "\n",
        "To expose your app publicly:\n",
        "\n",
        "1. Create account:\n",
        "   https://dashboard.ngrok.com/signup\n",
        "\n",
        "2. Get authtoken:\n",
        "   https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "3. Insert token:\n",
        "   conf.get_default().auth_token = \"YOUR_NGROK_TOKEN\"\n",
        "\n",
        "4. Create tunnel:\n",
        "   public_url = ngrok.connect(8000)\n",
        "\n",
        "Share this public URL with anyone \u2014 the full app runs online.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4210,
          "status": "ok",
          "timestamp": 1762506742275,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "9obP350nqqxq",
        "outputId": "1ceeeece-b2e4-4e68-c052-b88ec1ba8806"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 8\ufe0f\u20e3 Start ngrok tunnel\n",
        "# ===============================\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN\"  # \ud83d\udd11 replace with your token\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "# ===============================\n",
        "# 9\ufe0f\u20e3 Check logs (optional)\n",
        "# ===============================\n",
        "!sleep 3 && tail -n 20 flask.log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e36\ufe0f\u20e3 View Logs\n",
        "\n",
        "Check the last 20\u201350 lines:\n",
        "\n",
        "!tail -n 20 flask.log\n",
        "!tail -n 50 flask.log\n",
        "\n",
        "Useful for:\n",
        "- BLIP model errors\n",
        "- OCR reader failures\n",
        "- Translation fallback issues\n",
        "- Upload path mistakes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 115,
          "status": "ok",
          "timestamp": 1762506786693,
          "user": {
            "displayName": "Huebits tech",
            "userId": "04186726763663586350"
          },
          "user_tz": -330
        },
        "id": "_FwmZCymq2Ku",
        "outputId": "8da0ee53-6a51-4b4f-b92e-434acf1bc788"
      },
      "outputs": [],
      "source": [
        "!tail -n 50 flask.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ6MHYJcrLxl"
      },
      "outputs": [],
      "source": [
        "\ud83d\udcd8 1\ufe0f\u20e37\ufe0f\u20e3 OmniAI Cloud \u2014 Completed\n",
        "\n",
        "\ud83c\udf89 Your OmniAI Cloud platform is ready!\n",
        "\n",
        "Users can:\n",
        "\n",
        "\u2714 Caption images  \n",
        "\u2714 Extract OCR text with currency correction  \n",
        "\u2714 Analyze sentiment and keywords  \n",
        "\u2714 Translate text across 9 languages  \n",
        "\u2714 Enjoy a neon futuristic UI  \n",
        "\u2714 Access everything through ngrok links  \n",
        "\n",
        "A perfect end-to-end cloud AI dashboard for demos, portfolio, or teaching.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM1oEYKz8f4h3VXRRMWYTmi",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}