{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 1 \u2014 Project Introduction\n",
        "\n",
        "# \ud83c\udf3f AI-Based Tulasi Leaf Disease Classification System\n",
        "\n",
        "This project provides:\n",
        "\n",
        "* \ud83c\udf31 Tulasi Leaf Image Upload\n",
        "* \ud83e\udd16 Deep Learning based Disease Detection\n",
        "* \u26a1 EfficientNet-B0 for High Accuracy\n",
        "* \ud83d\udcca Top-3 Predictions with Confidence Scores\n",
        "* \ud83d\udcda Disease Description Mapping\n",
        "* \ud83c\udf0d Public Deployment using Flask + ngrok\n",
        "\n",
        "### \u2705 Supported Disease Classes:\n",
        "\n",
        "* Healthy\n",
        "* Bacterial\n",
        "* Fungal\n",
        "* Pests\n",
        "\n",
        "This notebook performs:\n",
        "\n",
        "1. Dependency Installation\n",
        "2. Dataset Loading from Google Drive\n",
        "3. Model Training using EfficientNet\n",
        "4. Model Saving & Export\n",
        "5. Flask Web App Creation\n",
        "6. Public Deployment via ngrok\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 2 \u2014 Install All Dependencies\n",
        "\n",
        "This step installs all libraries required for:\n",
        "\n",
        "* Deep Learning (PyTorch, timm)\n",
        "* Image Processing\n",
        "* Evaluation Metrics\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 1: Install All Dependencies\n",
        "\n",
        "# ===============================\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Jq7AVDg8jV7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4ofkFf4k1nK"
      },
      "outputs": [],
      "source": [
        "!pip install timm torch torchvision scikit-learn --quiet\n",
        "print(\"Libraries installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 3 \u2014 Mount Google Drive & Load Dataset\n",
        "\n",
        "This step:\n",
        "\n",
        "* Mounts Google Drive\n",
        "* Loads Tulasi Leaf Dataset\n",
        "* Displays available disease classes\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 2: Mount Drive & Load Dataset\n",
        "\n",
        "# ===============================\n"
      ],
      "metadata": {
        "id": "z9yonUPejZLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\u2705 **Yes, you can absolutely use that Kaggle dataset instead of Google Drive** \u2014 and it\u2019s actually a **better, cleaner, and more professional approach** for your project \ud83d\udc4f\n",
        "\n",
        "Dataset Link:\n",
        "\ud83d\udc49 [https://www.kaggle.com/datasets/huebitsvizg/tulasi-leaf-dataset](https://www.kaggle.com/datasets/huebitsvizg/tulasi-leaf-dataset)\n",
        "\n",
        "This means you will **REMOVE Google Drive mounting completely** and **LOAD the dataset directly from Kaggle into `/content/`**.\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 WHAT YOU SHOULD REPLACE (Your Old Code \u274c)\n",
        "\n",
        "You will **REMOVE this entire block**:\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/Sasi Projects/Tulasi Leaf Dataset/classifier model/dataset/train_aug\"\n",
        "\n",
        "print(\"Dataset Path:\", DATASET_DIR)\n",
        "print(\"Available Classes:\", os.listdir(DATASET_DIR))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 NEW PROFESSIONAL KAGGLE DATASET SETUP (FINAL \u2705)\n",
        "\n",
        "### \ud83d\udcd8 New Notebook Cell \u2014 *Dataset Download from Kaggle*\n",
        "\n",
        "```python\n",
        "# ===============================\n",
        "# \u2705 CELL: Download Dataset from Kaggle\n",
        "# ===============================\n",
        "\n",
        "!pip install -q kaggle\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcd8 Upload Kaggle API Key (ONE TIME STEP)\n",
        "\n",
        "1. Go to \ud83d\udc49 **[https://www.kaggle.com/settings](https://www.kaggle.com/settings)**\n",
        "2. Scroll to **API**\n",
        "3. Click **Create New Token**\n",
        "4. A file named `kaggle.json` will download\n",
        "5. Upload it to Colab using this:\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcd8 Configure Kaggle & Download Dataset\n",
        "\n",
        "```python\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "```python\n",
        "# \u2705 Download Tulasi Leaf Dataset\n",
        "!kaggle datasets download -d huebitsvizg/tulasi-leaf-dataset\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcd8 Extract Dataset\n",
        "\n",
        "```python\n",
        "!unzip -q tulasi-leaf-dataset.zip\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcd8 Set FINAL Dataset Path \u2705 (THIS replaces your Drive path)\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "DATASET_DIR = \"/content/tulasi-leaf-dataset\"\n",
        "\n",
        "print(\"\u2705 Dataset Path:\", DATASET_DIR)\n",
        "print(\"\u2705 Available Classes:\", os.listdir(DATASET_DIR))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \u2705 FINAL ANSWER TO YOUR QUESTION\n",
        "\n",
        "| Old Method                 | New Method                 |\n",
        "| -------------------------- | -------------------------- |\n",
        "| Google Drive manual upload | \u2705 Direct Kaggle Download   |\n",
        "| Risk of missing files      | \u2705 Clean structured dataset |\n",
        "| Slow access                | \u2705 Faster training          |\n",
        "| Manual dataset handling    | \u2705 100% automated           |\n",
        "\n",
        "\u2705 **You should now use this path in ALL your training code:**\n",
        "\n",
        "```python\n",
        "DATASET_DIR = \"/content/tulasi-leaf-dataset\"\n",
        "```\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "k8Nq4PBZ_oAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change this below cell based on above instructions\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/Sasi Projects/Tulasi Leaf Dataset/classifier model/dataset/train_aug\"\n",
        "\n",
        "print(\"Dataset Path:\", DATASET_DIR)\n",
        "print(\"Available Classes:\", os.listdir(DATASET_DIR))\n"
      ],
      "metadata": {
        "id": "wpgf3gKUAWjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 4 \u2014 Import Libraries & Set Seed\n",
        "\n",
        "This step:\n",
        "\n",
        "* Imports PyTorch, torchvision, timm\n",
        "* Sets random seeds for reproducibility\n",
        "* Enables GPU if available\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 3: Import Libraries & Set Seed\n",
        "\n",
        "# ===============================\n"
      ],
      "metadata": {
        "id": "VBZEwP6PkPYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "import timm\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "4fpTJYCslkyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 5 \u2014 Data Augmentation & Preprocessing\n",
        "\n",
        "This step prepares:\n",
        "\n",
        "* Training Transformations\n",
        "* Validation Transformations\n",
        "* Image Normalization for EfficientNet\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 4: Data Transforms\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpuE2yi3kRUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_tf = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(20),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406],\n",
        "                [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_tf = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406],\n",
        "                [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(DATASET_DIR, transform=train_tf)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Total images:\", len(dataset))\n"
      ],
      "metadata": {
        "id": "eCsZtW8ilwoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 6 \u2014 Train/Validation Dataset Split\n",
        "\n",
        "This step:\n",
        "\n",
        "* Splits dataset into 80% training\n",
        "* 20% validation\n",
        "* Maintains reproducibility\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 5: Dataset Split\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "zgjElB_okTCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_ratio = 0.2\n",
        "n_total = len(dataset)\n",
        "n_val = int(n_total * val_ratio)\n",
        "n_train = n_total - n_val\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    dataset, [n_train, n_val],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "val_ds.dataset.transform = val_tf\n",
        "\n",
        "print(\"Train size:\", len(train_ds))\n",
        "print(\"Val size:\", len(val_ds))\n"
      ],
      "metadata": {
        "id": "9ClJEF-hl4H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 7 \u2014 DataLoader Preparation\n",
        "\n",
        "This step:\n",
        "\n",
        "* Creates batch loaders\n",
        "* Enables fast training\n",
        "* Optimizes GPU usage\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 6: DataLoader Setup\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "T0UI5ed-kVFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "75Cl7-Qel7X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 8 \u2014 Model Creation (EfficientNet-B0)\n",
        "\n",
        "This step includes:\n",
        "\n",
        "* Transfer Learning with EfficientNet-B0\n",
        "* Loss Function (Cross Entropy)\n",
        "* Optimizer (AdamW)\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 7: Model Initialization\n",
        "\n",
        "# ==============================="
      ],
      "metadata": {
        "id": "PMuJuNbSkXI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(dataset.classes)\n",
        "\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n"
      ],
      "metadata": {
        "id": "ffFjywq4mBRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 9 \u2014 Model Training & Validation\n",
        "\n",
        "This step:\n",
        "\n",
        "* Trains for 15 epochs\n",
        "* Evaluates Accuracy & F1 Score\n",
        "* Saves best performing model automatically\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 8: Training Loop\n",
        "\n",
        "# ===============================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a-RQnOx6kZOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "best_acc = 0\n",
        "BEST_MODEL_PATH = \"/content/tulsi_effnetb0_best.pth\"\n",
        "\n",
        "for epoch in range(1, 16):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/15\")\n",
        "    for imgs, labels in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            out = model(imgs)\n",
        "            pred = out.argmax(1)\n",
        "            preds += pred.cpu().numpy().tolist()\n",
        "            true += labels.cpu().numpy().tolist()\n",
        "\n",
        "    val_acc = accuracy_score(true, preds)\n",
        "    val_f1 = f1_score(true, preds, average=\"weighted\")\n",
        "\n",
        "    print(f\"Epoch {epoch} \u2192 Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        print(\"\ud83d\udcbe New best model saved!\")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "print(\"Best Accuracy:\", best_acc)\n"
      ],
      "metadata": {
        "id": "miymBJuymEAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 10 \u2014 Save Class Mapping & Disease Information\n",
        "\n",
        "This step stores:\n",
        "\n",
        "* Class-to-Index Mapping\n",
        "* Disease Descriptions\n",
        "* Used for Flask Inference\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 9: Save JSON Files\n",
        "\n",
        "# ==============================="
      ],
      "metadata": {
        "id": "20bQu8UXkb15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class_to_idx = dataset.class_to_idx\n",
        "\n",
        "with open(\"/content/class_to_idx.json\", \"w\") as f:\n",
        "    json.dump(class_to_idx, f, indent=2)\n",
        "\n",
        "disease_info = {\n",
        "    \"healthy\": \"Healthy Tulasi leaf \u2013 no visible disease.\",\n",
        "    \"bacterial\": \"Dark circular bacterial lesions.\",\n",
        "    \"fungal\": \"White/gray fungal patches.\",\n",
        "    \"pests\": \"Insect bites or holes on the leaf.\"\n",
        "}\n",
        "\n",
        "with open(\"/content/disease_info.json\", \"w\") as f:\n",
        "    json.dump(disease_info, f, indent=2)\n",
        "\n",
        "print(\"JSON files saved.\")\n"
      ],
      "metadata": {
        "id": "HFpVqHYWmMRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 11 \u2014 Export Trained Model as ZIP\n",
        "\n",
        "This step creates a deployable archive containing:\n",
        "\n",
        "* Trained Model\n",
        "* Class Labels\n",
        "* Disease Info\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 10: ZIP Model Files\n",
        "\n",
        "# ==============================="
      ],
      "metadata": {
        "id": "uTcMT6n1kdlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -j /content/tulasi_leaf_model.zip /content/tulsi_effnetb0_best.pth /content/class_to_idx.json /content/disease_info.json\n",
        "print(\"ZIP created \u2192 /content/tulasi_leaf_model.zip\")\n"
      ],
      "metadata": {
        "id": "fFKB0KmupSTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 12 \u2014 Backup Model & JSON to Google Drive\n",
        "\n",
        "This step backs up:\n",
        "\n",
        "* Model file\n",
        "* Class mapping\n",
        "* Disease description\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 11: Backup to Drive\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "TOrizAIdkfuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/tulsi_effnetb0_best.pth \"/content/drive/MyDrive/tulsi_effnetb0_best.pth\"\n",
        "!cp /content/class_to_idx.json \"/content/drive/MyDrive/class_to_idx.json\"\n",
        "!cp /content/disease_info.json \"/content/drive/MyDrive/disease_info.json\"\n",
        "\n",
        "print(\"Files copied to Google Drive \u2192 MyDrive/\")\n"
      ],
      "metadata": {
        "id": "BuwvwQfEpWNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 13 \u2014 Install Flask & Prepare Deployment\n",
        "\n",
        "This step:\n",
        "\n",
        "* Installs Flask & ngrok\n",
        "* Copies trained model to runtime\n",
        "* Creates upload & template folders\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 12: Flask Setup\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "27IBMVp7khk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok timm torch torchvision --quiet\n",
        "print(\"\u2705 Flask, pyngrok, timm installed\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "# Copy model & jsons from Drive (paths based on your previous message)\n",
        "src_model = \"/content/drive/MyDrive/tulsi_effnetb0_best.pth\"\n",
        "src_class = \"/content/drive/MyDrive/class_to_idx.json\"\n",
        "src_info  = \"/content/drive/MyDrive/disease_info.json\"\n",
        "\n",
        "shutil.copy(src_model, \"/content/tulsi_effnetb0_best.pth\")\n",
        "shutil.copy(src_class, \"/content/class_to_idx.json\")\n",
        "shutil.copy(src_info, \"/content/disease_info.json\")\n",
        "\n",
        "print(\"\u2705 Copied model & JSON files to /content\")\n",
        "\n",
        "# Create folders for Flask\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "os.makedirs(\"static\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "JDkMiM96rVWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 14 \u2014 Create Flask Backend (app.py)\n",
        "\n",
        "This step builds:\n",
        "\n",
        "* Image Upload API\n",
        "* Model Lazy Loading\n",
        "* Disease Prediction API\n",
        "* Confidence & Description Output\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 13: Create app.py\n",
        "\n",
        "# ==============================="
      ],
      "metadata": {
        "id": "PisqpvHkkjU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, render_template, request, send_from_directory, url_for\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import functools\n",
        "from PIL import Image\n",
        "import json\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads'\n",
        "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB\n",
        "\n",
        "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'webp'}\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Global Variables\n",
        "# ===============================\n",
        "MODEL_LOADING = False\n",
        "current_model = None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL_PATH = \"tulsi_effnetb0_best.pth\"\n",
        "CLASS_MAP_PATH = \"class_to_idx.json\"\n",
        "DISEASE_INFO_PATH = \"disease_info.json\"\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Load class mapping & disease info\n",
        "# ===============================\n",
        "with open(CLASS_MAP_PATH, \"r\") as f:\n",
        "    class_to_idx = json.load(f)\n",
        "\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "with open(DISEASE_INFO_PATH, \"r\") as f:\n",
        "    disease_info = json.load(f)\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Image Transform (same as validation)\n",
        "# ===============================\n",
        "IMG_SIZE = 224\n",
        "infer_tf = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406],\n",
        "                [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Lazy-load Model (EfficientNet-B0)\n",
        "# ===============================\n",
        "@functools.lru_cache(maxsize=1)\n",
        "def get_tulsi_model():\n",
        "    global MODEL_LOADING, current_model\n",
        "    MODEL_LOADING = True\n",
        "\n",
        "    try:\n",
        "        print(\"\ud83d\udd04 Loading Tulasi EfficientNet model...\")\n",
        "        num_classes = len(class_to_idx)\n",
        "\n",
        "        model = timm.create_model(\"efficientnet_b0\", pretrained=False, num_classes=num_classes)\n",
        "        state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        current_model = model\n",
        "        MODEL_LOADING = False\n",
        "        print(\"\u2705 Tulasi model loaded successfully!\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error loading Tulasi model: {e}\")\n",
        "        MODEL_LOADING = False\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Prediction Helper\n",
        "# ===============================\n",
        "def predict_leaf(image_path, topk=3):\n",
        "    model = get_tulsi_model()\n",
        "    if model is None:\n",
        "        raise RuntimeError(\"Model is not available\")\n",
        "\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    x = infer_tf(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    # Top-k predictions\n",
        "    top_indices = probs.argsort()[-topk:][::-1]\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        class_name = idx_to_class[idx]\n",
        "        confidence = float(probs[idx])\n",
        "        desc = disease_info.get(class_name, \"No description available.\")\n",
        "        results.append({\n",
        "            \"class_name\": class_name,\n",
        "            \"confidence\": round(confidence * 100, 2),\n",
        "            \"description\": desc\n",
        "        })\n",
        "\n",
        "    # Best prediction (top-1)\n",
        "    best = results[0]\n",
        "    return best, results\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Routes\n",
        "# ===============================\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    uploaded_image = None\n",
        "    prediction = None\n",
        "    top_predictions = None\n",
        "    error_message = None\n",
        "    model_loading = MODEL_LOADING\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        if 'image' not in request.files:\n",
        "            error_message = \"No image uploaded\"\n",
        "        else:\n",
        "            file = request.files['image']\n",
        "\n",
        "            if file.filename == '':\n",
        "                error_message = \"No image selected\"\n",
        "            elif not allowed_file(file.filename):\n",
        "                error_message = \"Invalid file type. Please upload PNG, JPG, JPEG, or WEBP\"\n",
        "            else:\n",
        "                try:\n",
        "                    filename = f\"leaf_{file.filename}\"\n",
        "                    save_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "                    file.save(save_path)\n",
        "\n",
        "                    best, topk = predict_leaf(save_path)\n",
        "\n",
        "                    uploaded_image = filename\n",
        "                    prediction = best\n",
        "                    top_predictions = topk\n",
        "\n",
        "                except Exception as e:\n",
        "                    error_message = f\"Error processing image: {str(e)}\"\n",
        "\n",
        "    return render_template(\n",
        "        \"index.html\",\n",
        "        uploaded_image=uploaded_image,\n",
        "        prediction=prediction,\n",
        "        top_predictions=top_predictions,\n",
        "        error_message=error_message,\n",
        "        model_loading=model_loading\n",
        "    )\n",
        "\n",
        "@app.route('/uploads/<filename>')\n",
        "def uploaded_file(filename):\n",
        "    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)\n",
        "\n",
        "# ===============================\n",
        "# \ud83d\udd39 Run\n",
        "# ===============================\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)\n"
      ],
      "metadata": {
        "id": "MWBB3ZtuxUu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 15 \u2014 Create Frontend Web Interface\n",
        "\n",
        "This step creates:\n",
        "\n",
        "* Upload UI\n",
        "* Prediction Display\n",
        "* Confidence Table\n",
        "* Loading Animation\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 14: Create index.html\n",
        "\n",
        "# ===============================\n"
      ],
      "metadata": {
        "id": "1tjLMYOfkmQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>\ud83c\udf3f Tulasi Leaf Disease Classifier</title>\n",
        "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>\ud83c\udf3f Tulasi Leaf Disease Classifier</h1>\n",
        "        <p class=\"subtitle\">Upload a Tulasi leaf image to detect disease type using Deep Learning</p>\n",
        "\n",
        "        {% if model_loading %}\n",
        "        <div class=\"loading\">\n",
        "            \u26a1 Model is loading... This may take a few moments on first use.\n",
        "        </div>\n",
        "        {% endif %}\n",
        "\n",
        "        {% if error_message %}\n",
        "        <div class=\"error\">\n",
        "            \u274c {{ error_message }}\n",
        "        </div>\n",
        "        {% endif %}\n",
        "\n",
        "        <div class=\"card\">\n",
        "            <form method=\"post\" enctype=\"multipart/form-data\">\n",
        "                <div class=\"upload-area\" id=\"uploadArea\">\n",
        "                    <input type=\"file\" name=\"image\" id=\"imageInput\" accept=\"image/*\" required>\n",
        "                    <label for=\"imageInput\" id=\"uploadLabel\">\n",
        "                        <div class=\"upload-icon\">\ud83d\udcc1</div>\n",
        "                        <div class=\"upload-text\">Click to upload or drag & drop</div>\n",
        "                        <div class=\"upload-hint\">Supports: PNG, JPG, JPEG, WEBP (Max 16MB)</div>\n",
        "                    </label>\n",
        "                </div>\n",
        "\n",
        "                <button type=\"submit\" id=\"predictBtn\">\ud83d\udd0d Predict Disease</button>\n",
        "            </form>\n",
        "        </div>\n",
        "\n",
        "        {% if uploaded_image and prediction %}\n",
        "        <div class=\"results\">\n",
        "            <h2>\ud83d\udcca Prediction Result</h2>\n",
        "\n",
        "            <div class=\"comparison-container\">\n",
        "                <div class=\"image-box\">\n",
        "                    <h3>Uploaded Leaf</h3>\n",
        "                    <img src=\"{{ url_for('uploaded_file', filename=uploaded_image) }}\" alt=\"Leaf\">\n",
        "                </div>\n",
        "\n",
        "                <div class=\"image-box enhanced\">\n",
        "                    <h3>Predicted Disease</h3>\n",
        "                    <p class=\"pred-class\">\n",
        "                        \ud83c\udff7\ufe0f Class: <strong>{{ prediction.class_name|capitalize }}</strong>\n",
        "                    </p>\n",
        "                    <p class=\"pred-conf\">\n",
        "                        \ud83c\udfaf Confidence: <strong>{{ prediction.confidence }}%</strong>\n",
        "                    </p>\n",
        "                    <p class=\"pred-desc\">\n",
        "                        \ud83d\udcda Description: {{ prediction.description }}\n",
        "                    </p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            {% if top_predictions %}\n",
        "            <div class=\"info-box\">\n",
        "                <h3>Top Predictions</h3>\n",
        "                <table class=\"pred-table\">\n",
        "                    <tr>\n",
        "                        <th>Disease Class</th>\n",
        "                        <th>Confidence (%)</th>\n",
        "                    </tr>\n",
        "                    {% for p in top_predictions %}\n",
        "                    <tr>\n",
        "                        <td>{{ p.class_name|capitalize }}</td>\n",
        "                        <td>{{ p.confidence }}</td>\n",
        "                    </tr>\n",
        "                    {% endfor %}\n",
        "                </table>\n",
        "            </div>\n",
        "            {% endif %}\n",
        "        </div>\n",
        "        {% endif %}\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        const imageInput = document.getElementById('imageInput');\n",
        "        const uploadLabel = document.getElementById('uploadLabel');\n",
        "        const uploadArea = document.getElementById('uploadArea');\n",
        "        const predictBtn = document.getElementById('predictBtn');\n",
        "\n",
        "        imageInput.addEventListener('change', function(e) {\n",
        "            if (e.target.files.length > 0) {\n",
        "                const fileName = e.target.files[0].name;\n",
        "                uploadLabel.innerHTML = `\n",
        "                    <div class=\"upload-icon\">\u2705</div>\n",
        "                    <div class=\"upload-text\">${fileName}</div>\n",
        "                    <div class=\"upload-hint\">Click to change file</div>\n",
        "                `;\n",
        "                uploadArea.classList.add('has-file');\n",
        "            }\n",
        "        });\n",
        "\n",
        "        uploadArea.addEventListener('dragover', function(e) {\n",
        "            e.preventDefault();\n",
        "            uploadArea.classList.add('drag-over');\n",
        "        });\n",
        "\n",
        "        uploadArea.addEventListener('dragleave', function(e) {\n",
        "            e.preventDefault();\n",
        "            uploadArea.classList.remove('drag-over');\n",
        "        });\n",
        "\n",
        "        uploadArea.addEventListener('drop', function(e) {\n",
        "            e.preventDefault();\n",
        "            uploadArea.classList.remove('drag-over');\n",
        "\n",
        "            if (e.dataTransfer.files.length > 0) {\n",
        "                imageInput.files = e.dataTransfer.files;\n",
        "                imageInput.dispatchEvent(new Event('change'));\n",
        "            }\n",
        "        });\n",
        "\n",
        "        const form = document.querySelector('form');\n",
        "        form.addEventListener('submit', function() {\n",
        "            predictBtn.disabled = true;\n",
        "            predictBtn.innerHTML = '\u23f3 Predicting... Please wait';\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "XD3_BYflxerI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 16 \u2014 UI Styling using CSS\n",
        "\n",
        "This step styles:\n",
        "\n",
        "* Upload Interface\n",
        "* Cards & Buttons\n",
        "* Prediction Results\n",
        "* Mobile Responsive Design\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 15: Create style.css\n",
        "\n",
        "# ===============================\n",
        "\n"
      ],
      "metadata": {
        "id": "aBQkeXyEkokp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile static/style.css\n",
        "* {\n",
        "    margin: 0;\n",
        "    padding: 0;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        "\n",
        "body {\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "    background: linear-gradient(135deg, #16a34a 0%, #14532d 100%);\n",
        "    color: white;\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    align-items: flex-start;\n",
        "    padding: 30px 20px;\n",
        "    min-height: 100vh;\n",
        "}\n",
        "\n",
        ".container {\n",
        "    text-align: center;\n",
        "    width: 100%;\n",
        "    max-width: 1000px;\n",
        "}\n",
        "\n",
        "h1 {\n",
        "    margin-bottom: 10px;\n",
        "    font-size: 2.5em;\n",
        "    font-weight: 700;\n",
        "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);\n",
        "}\n",
        "\n",
        ".subtitle {\n",
        "    font-size: 1.1em;\n",
        "    opacity: 0.95;\n",
        "    margin-bottom: 30px;\n",
        "}\n",
        "\n",
        ".card {\n",
        "    background: rgba(255, 255, 255, 0.15);\n",
        "    backdrop-filter: blur(10px);\n",
        "    padding: 30px;\n",
        "    border-radius: 20px;\n",
        "    margin-bottom: 30px;\n",
        "    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);\n",
        "}\n",
        "\n",
        "/* Upload Area Styling */\n",
        ".upload-area {\n",
        "    position: relative;\n",
        "    border: 3px dashed rgba(255, 255, 255, 0.5);\n",
        "    border-radius: 15px;\n",
        "    padding: 50px 20px;\n",
        "    margin-bottom: 25px;\n",
        "    background: rgba(255, 255, 255, 0.05);\n",
        "    transition: all 0.3s ease;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        ".upload-area:hover {\n",
        "    border-color: rgba(255, 255, 255, 0.8);\n",
        "    background: rgba(255, 255, 255, 0.1);\n",
        "    transform: scale(1.02);\n",
        "}\n",
        "\n",
        ".upload-area.drag-over {\n",
        "    border-color: #4ade80;\n",
        "    background: rgba(74, 222, 128, 0.1);\n",
        "}\n",
        "\n",
        ".upload-area.has-file {\n",
        "    border-color: #4ade80;\n",
        "    background: rgba(74, 222, 128, 0.15);\n",
        "}\n",
        "\n",
        ".upload-area input[type=\"file\"] {\n",
        "    position: absolute;\n",
        "    opacity: 0;\n",
        "    width: 100%;\n",
        "    height: 100%;\n",
        "    cursor: pointer;\n",
        "    top: 0;\n",
        "    left: 0;\n",
        "}\n",
        "\n",
        ".upload-area label {\n",
        "    display: block;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        ".upload-icon {\n",
        "    font-size: 4em;\n",
        "    margin-bottom: 15px;\n",
        "}\n",
        "\n",
        ".upload-text {\n",
        "    font-size: 1.3em;\n",
        "    font-weight: 600;\n",
        "    margin-bottom: 8px;\n",
        "}\n",
        "\n",
        ".upload-hint {\n",
        "    font-size: 0.9em;\n",
        "    opacity: 0.8;\n",
        "}\n",
        "\n",
        "/* Button */\n",
        "button {\n",
        "    width: 100%;\n",
        "    padding: 15px;\n",
        "    background: linear-gradient(135deg, #22c55e, #15803d);\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 10px;\n",
        "    font-size: 18px;\n",
        "    font-weight: bold;\n",
        "    cursor: pointer;\n",
        "    transition: all 0.3s ease;\n",
        "    text-transform: uppercase;\n",
        "    letter-spacing: 1px;\n",
        "}\n",
        "\n",
        "button:hover:not(:disabled) {\n",
        "    transform: translateY(-2px);\n",
        "    box-shadow: 0 6px 20px rgba(34, 197, 94, 0.4);\n",
        "}\n",
        "\n",
        "button:disabled {\n",
        "    opacity: 0.6;\n",
        "    cursor: not-allowed;\n",
        "}\n",
        "\n",
        "/* Results Section */\n",
        ".results {\n",
        "    background: rgba(255, 255, 255, 0.15);\n",
        "    backdrop-filter: blur(10px);\n",
        "    padding: 30px;\n",
        "    border-radius: 20px;\n",
        "    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);\n",
        "    animation: slideIn 0.5s ease;\n",
        "}\n",
        "\n",
        "@keyframes slideIn {\n",
        "    from {\n",
        "        opacity: 0;\n",
        "        transform: translateY(20px);\n",
        "    }\n",
        "    to {\n",
        "        opacity: 1;\n",
        "        transform: translateY(0);\n",
        "    }\n",
        "}\n",
        "\n",
        ".comparison-container {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n",
        "    gap: 25px;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "\n",
        ".image-box {\n",
        "    background: rgba(0, 0, 0, 0.3);\n",
        "    padding: 20px;\n",
        "    border-radius: 15px;\n",
        "    border: 2px solid rgba(255, 255, 255, 0.2);\n",
        "}\n",
        "\n",
        ".image-box.enhanced {\n",
        "    border-color: #4ade80;\n",
        "    box-shadow: 0 0 20px rgba(74, 222, 128, 0.3);\n",
        "}\n",
        "\n",
        ".image-box h3 {\n",
        "    margin-bottom: 15px;\n",
        "    font-size: 1.2em;\n",
        "}\n",
        "\n",
        ".image-box img {\n",
        "    width: 100%;\n",
        "    height: auto;\n",
        "    border-radius: 10px;\n",
        "    margin-bottom: 15px;\n",
        "    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);\n",
        "}\n",
        "\n",
        "/* Prediction Details */\n",
        ".pred-class, .pred-conf, .pred-desc {\n",
        "    font-size: 1.1em;\n",
        "    margin-bottom: 8px;\n",
        "}\n",
        "\n",
        "/* Info Box */\n",
        ".info-box {\n",
        "    background: rgba(74, 222, 128, 0.2);\n",
        "    border: 2px solid #4ade80;\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    margin-top: 20px;\n",
        "}\n",
        "\n",
        ".pred-table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    margin-top: 10px;\n",
        "}\n",
        "\n",
        ".pred-table th, .pred-table td {\n",
        "    border: 1px solid rgba(255,255,255,0.3);\n",
        "    padding: 8px 10px;\n",
        "}\n",
        "\n",
        ".pred-table th {\n",
        "    background: rgba(0,0,0,0.4);\n",
        "}\n",
        "\n",
        "/* Loading & Error */\n",
        ".loading {\n",
        "    background: rgba(251, 191, 36, 0.2);\n",
        "    border: 2px solid #fbbf24;\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    margin-bottom: 20px;\n",
        "    font-weight: bold;\n",
        "    animation: pulse 2s infinite;\n",
        "}\n",
        "\n",
        ".error {\n",
        "    background: rgba(239, 68, 68, 0.2);\n",
        "    border: 2px solid #ef4444;\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    margin-bottom: 20px;\n",
        "    font-weight: bold;\n",
        "}\n",
        "\n",
        "@keyframes pulse {\n",
        "    0%, 100% { opacity: 1; }\n",
        "    50% { opacity: 0.7; }\n",
        "}\n",
        "\n",
        "/* Responsive */\n",
        "@media (max-width: 768px) {\n",
        "    h1 {\n",
        "        font-size: 2em;\n",
        "    }\n",
        "    .card, .results {\n",
        "        padding: 20px;\n",
        "    }\n",
        "    .comparison-container {\n",
        "        grid-template-columns: 1fr;\n",
        "    }\n",
        "    .upload-area {\n",
        "        padding: 30px 15px;\n",
        "    }\n",
        "    .upload-icon {\n",
        "        font-size: 3em;\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "4BV5BvX3xoch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 17 \u2014 Run Flask Server & ngrok Deployment\n",
        "\n",
        "This step:\n",
        "\n",
        "* Stops existing Flask/ngrok\n",
        "* Starts Flask Server\n",
        "* Creates Public ngrok URL\n",
        "\n",
        "# \ud83d\udd10 ngrok Token Removed for Security\n",
        "\n",
        "User should insert their own token.\n",
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 16: Run Server & ngrok\n",
        "\n",
        "# ===============================\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8  Authenticate ngrok\n",
        "\n",
        "This step:\n",
        "\n",
        "* Authenticates ngrok with your account\n",
        "* Enables secure public HTTPS access\n",
        "* Prepares the system for live deployment\n",
        "\n",
        "# ===============================\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udf10 Ngrok Setup (Public Deployment)\n",
        "\n",
        "Ngrok provides a **secure public HTTPS link** to your locally running Flask application.\n",
        "\n",
        "\ud83d\udd10 **For security reasons, your ngrok token should NOT be shared publicly.**\n",
        "\n",
        "### \u2705 To Use Ngrok, Follow These Steps:\n",
        "\n",
        "### \ud83d\udccc Step 1 \u2014 Get Your Auth Token\n",
        "\n",
        "Go to this link and copy your personal token:\n",
        "\ud83d\udc49 **[https://dashboard.ngrok.com/get-started/your-authtoken](https://dashboard.ngrok.com/get-started/your-authtoken)**\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udccc Step 2 \u2014 Add Token Inside Notebook\n",
        "\n",
        "Paste your token in the following line:\n",
        "\n",
        "```python\n",
        "#from pyngrok import ngrok, conf\n",
        "\n",
        "#conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udccc Step 3 \u2014 Start Ngrok Tunnel\n",
        "\n",
        "```python\n",
        "#public_url = ngrok.connect(8000)\n",
        "#print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "```\n",
        "\n",
        "\u2705 After running this, a **shareable public link** will appear here.\n",
        "You can open it in your browser and access your Flask app from **anywhere in the world** \ud83c\udf0e\n",
        "\n",
        "---\n",
        "\n",
        "### \u2705 Summary\n",
        "\n",
        "\u2714 Secure HTTPS URL\n",
        "\n",
        "\u2714 No port forwarding required\n",
        "\n",
        "\u2714 Works on Google Colab\n",
        "\n",
        "\u2714 Perfect for project demos, reviews, and viva\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "84XcJ6yGkrXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\"\n",
        "\n",
        "# Start Flask app\n",
        "!nohup python app.py > flask.log 2>&1 &\n",
        "\n",
        "# Start ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# \ud83d\udd11 PUT YOUR NGROK TOKEN HERE\n",
        "conf.get_default().auth_token = \"PASTE_YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "# Show last lines of log (optional)\n",
        "!sleep 3 && tail -n 20 flask.log\n"
      ],
      "metadata": {
        "id": "nMesaZaUxvFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udcd8 18 \u2014 Notebook Completed\n",
        "\n",
        "# \ud83c\udf89 Tulasi Leaf Disease Detection System Ready!\n",
        "\n",
        "You can now:\n",
        "\n",
        "1. Upload Tulasi Leaf Image\n",
        "2. Detect Disease using AI\n",
        "3. View Confidence & Description\n",
        "4. See Top-3 Predictions\n",
        "5. Access Public Web App using ngrok\n",
        "\n",
        "\u2705 Fully Offline AI Model\n",
        "\n",
        "\u2705 No External API Used\n",
        "\n",
        "\u2705 Resume, GitHub & College Submission Ready\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Kv1PrdeatxMJ"
      }
    }
  ]
}