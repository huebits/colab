{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYrVaEfyh6JTJxZpI17eN4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in Kaggle"
      ],
      "metadata": {
        "id": "VQLKXlD8AMJD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkkkpqFo-Y5j"
      },
      "source": [
        "# \ud83d\ude97 Vehicle Damage Detection + Cost Estimation  \n",
        "### Part 1 \u2014 YOLOv5 Training (Kaggle)\n",
        "\n",
        "This notebook prepares and trains a **YOLOv5 damage detector** using the *Car Damage Dataset (CarDD)*.  \n",
        "In **Part 2**, we will integrate this model in Colab with an **AI-based repair cost estimator**.\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83d\udce6 Dataset Used\n",
        "Kaggle Dataset:  \n",
        "https://www.kaggle.com/datasets/huebitsvizg/vehicle-damage\n",
        "\n",
        "Inside this dataset you receive:\n",
        "CarDD_release/CarDD_COCO/\n",
        "\u251c\u2500\u2500 train2017/\n",
        "\u251c\u2500\u2500 val2017/\n",
        "\u251c\u2500\u2500 test2017/\n",
        "\u2514\u2500\u2500 annotations/ instances_*.json (COCO format)\n",
        "\n",
        "\n",
        "The annotations are in **COCO JSON format**.  \n",
        "YOLOv5 requires:\n",
        "\n",
        "images/train\n",
        "images/val\n",
        "images/test\n",
        "labels/train\n",
        "labels/val\n",
        "labels/test\n",
        "cardd.yaml\n",
        "\n",
        "\n",
        "So the first part of the pipeline converts **COCO \u2192 YOLO labels**.\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83e\udde0 What This Notebook Will Do\n",
        "\n",
        "### \u2714 Convert COCO annotations \u2192 YOLO labels  \n",
        "### \u2714 Generate required folder structure  \n",
        "### \u2714 Train YOLOv5s for damage detection  \n",
        "### \u2714 Run inference on test images  \n",
        "### \u2714 Export trained model for Colab App (Part 2)\n",
        "\n",
        "After training, the following file becomes important:\n",
        "\n",
        "runs/train/CarDD/weights/best.pt\n",
        "\n",
        "\n",
        "You will upload this to Google Drive during the Colab web app phase.\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83d\udee0 NOTES\n",
        "\u2022 Only **1 class** is used: `\"damage\"`  \n",
        "\u2022 Later in Colab, we\u2019ll layer a **cost estimation model** on top of the detector output  \n",
        "\u2022 This Kaggle notebook focuses on **object detection only**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-29T04:35:18.939193Z",
          "iopub.status.busy": "2025-11-29T04:35:18.938969Z",
          "iopub.status.idle": "2025-11-29T04:37:09.269844Z",
          "shell.execute_reply": "2025-11-29T04:37:09.269042Z",
          "shell.execute_reply.started": "2025-11-29T04:35:18.939171Z"
        },
        "id": "8bb-A43gXf24",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall \"numpy==1.26.4\" \"opencv-python==4.7.0.72\" \"matplotlib==3.7.2\"\n",
        "!rm -rf yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUpggvoC-Y5t"
      },
      "source": [
        "# \ud83d\udcc1 Step 1 \u2014 Prepare YOLO Directory Structure\n",
        "\n",
        "YOLOv5 expects the dataset in this layout:\n",
        "\n",
        "CarDD_yolo/\n",
        "\u251c\u2500\u2500 images/train  \n",
        "\u251c\u2500\u2500 images/val  \n",
        "\u251c\u2500\u2500 images/test  \n",
        "\u251c\u2500\u2500 labels/train  \n",
        "\u251c\u2500\u2500 labels/val  \n",
        "\u251c\u2500\u2500 labels/test  \n",
        "\u2514\u2500\u2500 cardd.yaml\n",
        "\n",
        "This block creates these folders inside `/kaggle/working`.\n",
        "\n",
        "The *original dataset* stays in:\n",
        "`/kaggle/input/damage-dataset/CarDD_release/CarDD_COCO/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:37:44.930042Z",
          "iopub.status.busy": "2025-11-29T04:37:44.929728Z",
          "iopub.status.idle": "2025-11-29T04:37:44.936215Z",
          "shell.execute_reply": "2025-11-29T04:37:44.935477Z",
          "shell.execute_reply.started": "2025-11-29T04:37:44.930013Z"
        },
        "id": "qkTRT5GVXf26",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json, shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "root = Path(\"/kaggle/input/damage-dataset/CarDD_release/CarDD_COCO\")\n",
        "out_root = Path(\"/kaggle/working/CarDD_yolo\")\n",
        "\n",
        "# Create folders\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    (out_root / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
        "    (out_root / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSeCtQ1b-Y5u"
      },
      "source": [
        "# \ud83d\udd04 Step 2 \u2014 Convert COCO JSON \u2192 YOLO Labels\n",
        "\n",
        "The COCO annotation format gives:\n",
        "- top-left (x, y)\n",
        "- width\n",
        "- height\n",
        "\n",
        "YOLO requires:\n",
        "- class_id  \n",
        "- center_x  \n",
        "- center_y  \n",
        "- width  \n",
        "- height  \n",
        "(all normalized)\n",
        "\n",
        "Also:\n",
        "\u2714 Reads image sizes using OpenCV  \n",
        "\u2714 Writes YOLO `.txt` label files  \n",
        "\u2714 Copies images into YOLO folders  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:37:54.677024Z",
          "iopub.status.busy": "2025-11-29T04:37:54.676347Z",
          "iopub.status.idle": "2025-11-29T04:37:54.683960Z",
          "shell.execute_reply": "2025-11-29T04:37:54.683264Z",
          "shell.execute_reply.started": "2025-11-29T04:37:54.677000Z"
        },
        "id": "1wRsgvJcXf26",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def coco_to_yolo(json_path, image_dir, out_img, out_lbl):\n",
        "    with open(json_path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Map image-id \u2192 filename\n",
        "    id_to_file = {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
        "\n",
        "    # Collect annotations per image\n",
        "    anns = {}\n",
        "    for a in data[\"annotations\"]:\n",
        "        img_id = a[\"image_id\"]\n",
        "        x, y, w, h = a[\"bbox\"]\n",
        "\n",
        "        # Convert bbox to YOLO format (normalized center x,y,w,h)\n",
        "        cx = (x + w/2)\n",
        "        cy = (y + h/2)\n",
        "        img_file = image_dir / id_to_file[img_id]\n",
        "        img_path = str(img_file)\n",
        "\n",
        "        import cv2\n",
        "        img = cv2.imread(img_path)\n",
        "        H, W = img.shape[:2]\n",
        "\n",
        "        cx /= W\n",
        "        cy /= H\n",
        "        w /= W\n",
        "        h /= H\n",
        "\n",
        "        if img_id not in anns:\n",
        "            anns[img_id] = []\n",
        "        anns[img_id].append([0, cx, cy, w, h])  # class: 0 (damage)\n",
        "\n",
        "    # Write image files & labels\n",
        "    for img_id, file_name in id_to_file.items():\n",
        "        src_img = image_dir / file_name\n",
        "        dst_img = out_img / file_name\n",
        "        shutil.copy(src_img, dst_img)\n",
        "\n",
        "        label_file = out_lbl / (file_name.replace(\".jpg\", \".txt\"))\n",
        "        with open(label_file, \"w\") as f:\n",
        "            for anno in anns.get(img_id, []):\n",
        "                f.write(\" \".join(map(str, anno)) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-oU7GCP-Y5v"
      },
      "source": [
        "# \ud83e\udde9 Step 3 \u2014 Run COCO \u2192 YOLO Conversion for Train/Val/Test\n",
        "\n",
        "Each annotation file is converted automatically.\n",
        "\n",
        "After this step:\n",
        "\u2714 All images copied  \n",
        "\u2714 YOLO label files created  \n",
        "\u2714 Dataset ready for YOLOv5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:38:03.141638Z",
          "iopub.status.busy": "2025-11-29T04:38:03.141393Z",
          "iopub.status.idle": "2025-11-29T04:43:11.961327Z",
          "shell.execute_reply": "2025-11-29T04:43:11.960507Z",
          "shell.execute_reply.started": "2025-11-29T04:38:03.141619Z"
        },
        "id": "t7rIdbUJXf27",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "coco_to_yolo(\n",
        "    json_path=root/\"annotations/instances_train2017.json\",\n",
        "    image_dir=root/\"train2017\",\n",
        "    out_img=out_root/\"images/train\",\n",
        "    out_lbl=out_root/\"labels/train\"\n",
        ")\n",
        "\n",
        "coco_to_yolo(\n",
        "    json_path=root/\"annotations/instances_val2017.json\",\n",
        "    image_dir=root/\"val2017\",\n",
        "    out_img=out_root/\"images/val\",\n",
        "    out_lbl=out_root/\"labels/val\"\n",
        ")\n",
        "\n",
        "coco_to_yolo(\n",
        "    json_path=root/\"annotations/instances_test2017.json\",\n",
        "    image_dir=root/\"test2017\",\n",
        "    out_img=out_root/\"images/test\",\n",
        "    out_lbl=out_root/\"labels/test\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vPTKU0-Y5x"
      },
      "source": [
        "# \ud83d\udcdd Step 4 \u2014 Create cardd.yaml (YOLO Config File)\n",
        "\n",
        "YOLOv5 requires a dataset configuration YAML file containing:\n",
        "\n",
        "train: path/to/train  \n",
        "val: path/to/val  \n",
        "test: path/to/test  \n",
        "nc: number of classes  \n",
        "names: [\"damage\"]\n",
        "\n",
        "This file tells YOLO how many classes and where the dataset lives.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:45:51.230990Z",
          "iopub.status.busy": "2025-11-29T04:45:51.230368Z",
          "iopub.status.idle": "2025-11-29T04:45:51.257484Z",
          "shell.execute_reply": "2025-11-29T04:45:51.256863Z",
          "shell.execute_reply.started": "2025-11-29T04:45:51.230962Z"
        },
        "id": "OdKb9rC5Xf27",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os, shutil, json\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "\n",
        "base = \"/kaggle/working/CarDD_yolo\"\n",
        "os.makedirs(base, exist_ok=True)\n",
        "\n",
        "# Write cardd.yaml\n",
        "yaml.safe_dump({\n",
        "    \"train\": f\"{base}/images/train\",\n",
        "    \"val\": f\"{base}/images/val\",\n",
        "    \"test\": f\"{base}/images/test\",\n",
        "    \"nc\": 1,\n",
        "    \"names\": [\"damage\"]\n",
        "}, open(f\"{base}/cardd.yaml\", \"w\"))\n",
        "\n",
        "print(\"\u2714 cardd.yaml created at\", f\"{base}/cardd.yaml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQFH6Yq-Y5y"
      },
      "source": [
        "# \u26a0\ufe0f Step 5 \u2014 Kaggle Fixes for TensorFlow / Protobuf Conflicts\n",
        "\n",
        "Kaggle occasionally auto-installs packages that break YOLOv5.\n",
        "\n",
        "We disable:\n",
        "\u2714 TensorBoard  \n",
        "\u2714 protobuf  \n",
        "\u2714 W&B  \n",
        "\n",
        "This ensures YOLOv5 trains without errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:47:53.466551Z",
          "iopub.status.busy": "2025-11-29T04:47:53.466253Z",
          "iopub.status.idle": "2025-11-29T04:47:55.030663Z",
          "shell.execute_reply": "2025-11-29T04:47:55.029881Z",
          "shell.execute_reply.started": "2025-11-29T04:47:53.466526Z"
        },
        "id": "eSRtZ-_7Xf28",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# FIX 1: Disable TensorBoard entirely (avoids protobuf errors)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# FIX 2: Uninstall TensorBoard + protobuf if already installed\n",
        "!pip uninstall -y tensorboard protobuf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Tm71Pq-Y5y"
      },
      "source": [
        "# \ud83d\ude80 Step 6 \u2014 Train YOLOv5s Model\n",
        "\n",
        "Training settings:\n",
        "\u2022 Image size: 640  \n",
        "\u2022 Batch size: 16  \n",
        "\u2022 Epochs: 50  \n",
        "\u2022 Base model: yolov5s.pt  \n",
        "\u2022 Project name: CarDD  \n",
        "\n",
        "After training, your important model file is:\n",
        "\n",
        "\ud83d\udccc runs/train/CarDD/weights/best.pt  \n",
        "(This will be used in the Colab Damage Cost Estimator App)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T04:51:36.964904Z",
          "iopub.status.busy": "2025-11-29T04:51:36.964221Z",
          "iopub.status.idle": "2025-11-29T06:35:54.761732Z",
          "shell.execute_reply": "2025-11-29T06:35:54.761001Z",
          "shell.execute_reply.started": "2025-11-29T04:51:36.964876Z"
        },
        "id": "NSr5aj01Xf28",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!python train.py \\\n",
        "  --img 640 \\\n",
        "  --batch 16 \\\n",
        "  --epochs 50 \\\n",
        "  --data /kaggle/working/CarDD_yolo/cardd.yaml \\\n",
        "  --weights yolov5s.pt \\\n",
        "  --name CarDD \\\n",
        "  --exist-ok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm3s4W68-Y5z"
      },
      "source": [
        "# \ud83d\udd0d Step 7 \u2014 Run Test Inference\n",
        "\n",
        "This runs YOLOv5 detection on all test images.\n",
        "\n",
        "Outputs stored in:\n",
        "\n",
        "runs/detect/CarDD_test/\n",
        "\n",
        "Useful for:\n",
        "\u2714 Validating detection quality  \n",
        "\u2714 Exporting predictions  \n",
        "\u2714 Preparing data for damage-cost estimation model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T06:41:29.842304Z",
          "iopub.status.busy": "2025-11-29T06:41:29.842002Z",
          "iopub.status.idle": "2025-11-29T06:41:54.042434Z",
          "shell.execute_reply": "2025-11-29T06:41:54.041500Z",
          "shell.execute_reply.started": "2025-11-29T06:41:29.842277Z"
        },
        "id": "YJww4C5fXf29",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!python detect.py \\\n",
        "  --weights runs/train/CarDD/weights/best.pt \\\n",
        "  --source /kaggle/working/CarDD_yolo/images/test \\\n",
        "  --img 640 \\\n",
        "  --conf 0.25 \\\n",
        "  --name CarDD_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CGhfrM9-Y5z"
      },
      "source": [
        "# \ud83d\uddbc Step 8 \u2014 Display Sample Predictions\n",
        "\n",
        "Shows annotated images with bounding boxes.\n",
        "\n",
        "This confirms:\n",
        "\u2022 COCO \u2192 YOLO conversion worked  \n",
        "\u2022 Model trained correctly  \n",
        "\u2022 Predictions are visually reasonable  \n",
        "\n",
        "Next Step:\n",
        "You will upload **best.pt** to Colab for the **Damage + Cost Estimation Web App**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-29T06:42:55.412872Z",
          "iopub.status.busy": "2025-11-29T06:42:55.412106Z",
          "iopub.status.idle": "2025-11-29T06:42:55.441506Z",
          "shell.execute_reply": "2025-11-29T06:42:55.441000Z",
          "shell.execute_reply.started": "2025-11-29T06:42:55.412814Z"
        },
        "id": "Jtz1_DQvXf29",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image\n",
        "\n",
        "for img in glob.glob('runs/detect/CarDD_test/*.jpg')[:5]:\n",
        "    display(Image(filename=img))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SblPpdwXf2-",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLWHw6tB-6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jGj-y9j-6Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPE0Bd-d-6FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2mM9KVh_JMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXZZarK8_JIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mBAw1-K_JG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in Colab"
      ],
      "metadata": {
        "id": "E9fmfAPrAQGl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJ1Iyxy-b6C"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83d\ude97 **Vehicle Damage Detection + Cost Estimation (Web App \u2013 Colab Deployment)**\n",
        "\n",
        "This notebook allows you to deploy a **full web application** for detecting vehicle damage and estimating repair cost using:\n",
        "\n",
        "* **YOLOv5** \u2192 Damage detection\n",
        "* **LLaVA 1.6 Mistral 7B** \u2192 Car-part reasoning + damage description\n",
        "* **Flask Web App** \u2192 User interface for uploading images & estimating cost\n",
        "\n",
        "This Colab notebook is the **second stage** of the project.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd17 **Prerequisites from Kaggle Training Notebook**\n",
        "\n",
        "Before running this Colab web app, you MUST complete the **Kaggle training notebook**, where you:\n",
        "\n",
        "\u2714 Train YOLOv5 on the Vehicle Damage dataset\n",
        "\u2714 Export the trained weights\n",
        "\u2714 Obtain the file:\n",
        "\n",
        "```\n",
        "best.pt   (your custom YOLO damage detector)\n",
        "```\n",
        "\n",
        "### \u2b50 REQUIRED ACTION\n",
        "\n",
        "Download the `best.pt` model from Kaggle and upload it to:\n",
        "\n",
        "```\n",
        "Google Drive \u2192 MyDrive \u2192 vehicle damage detection/\n",
        "```\n",
        "\n",
        "The web app will load your trained model from:\n",
        "\n",
        "```\n",
        "/content/drive/MyDrive/vehicle damage detection/best (2).pt\n",
        "```\n",
        "\n",
        "(You can rename your file or update the path in `YOLO_MODEL_PATH` accordingly.)\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd10 **Hugging Face Token Requirement**\n",
        "\n",
        "This app uses **LLaVA-1.6 Mistral 7B**, which requires authentication to download.\n",
        "\n",
        "### How to create a token:\n",
        "\n",
        "1. Visit [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "2. Click **New Token \u2192 Read Access**\n",
        "3. Copy the token (starts with `hf_...`)\n",
        "\n",
        "Paste it inside:\n",
        "\n",
        "```python\n",
        "login(token=\"hf_your_token_here\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcc1 **Project Workflow Overview**\n",
        "\n",
        "```\n",
        "USER IMAGE \u2192 YOLO \u2192 detected bboxes \u2192 crop regions\n",
        "                         \u2193\n",
        "                 LLaVA (Vision + Language)\n",
        "                         \u2193\n",
        "        Car part names + short damage description\n",
        "                         \u2193\n",
        "      Cost estimation engine (rule + severity-based)\n",
        "                         \u2193\n",
        "              Final formatted repair report\n",
        "```\n",
        "\n",
        "The web app consists of two stages:\n",
        "\n",
        "### 1\ufe0f\u20e3 /api/analyze_damage\n",
        "\n",
        "* Applies YOLO model\n",
        "* Returns:\n",
        "\n",
        "  * annotated bounding-box image\n",
        "  * list of detections\n",
        "  * severity score (avg conf)\n",
        "  * tightly cropped damage images (used by LLaVA)\n",
        "\n",
        "### 2\ufe0f\u20e3 /api/estimate_cost\n",
        "\n",
        "* Runs LLaVA on each crop\n",
        "* Identifies:\n",
        "\n",
        "  * affected part (e.g., \"front bumper\")\n",
        "  * nature of damage (e.g., \"dented\")\n",
        "* Estimates repair cost\n",
        "* Produces a formatted plain-text repair report\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udce6 **Colab Setup Explained**\n",
        "\n",
        "### **1. Mount Google Drive**\n",
        "\n",
        "Used to load your trained YOLO model.\n",
        "\n",
        "```python\n",
        "drive.mount(\"/content/drive/\")\n",
        "```\n",
        "\n",
        "### **2. Install dependencies**\n",
        "\n",
        "YOLO, Flask, LLaVA transformers, BitsAndBytes, Pillow, ngrok.\n",
        "\n",
        "```python\n",
        "!pip install -q flask pyngrok ultralytics transformers ...\n",
        "```\n",
        "\n",
        "### **3. Create folders**\n",
        "\n",
        "Required for Flask templates, static files, and user uploads.\n",
        "\n",
        "```python\n",
        "!mkdir -p templates static uploads\n",
        "```\n",
        "\n",
        "### **4. Authenticate Hugging Face**\n",
        "\n",
        "Needed to load LLaVA.\n",
        "\n",
        "```python\n",
        "login(token=\"hf_...\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83e\udde0 **Model Loading Explained**\n",
        "\n",
        "### YOLO Model (Damage Detection)\n",
        "\n",
        "Loaded with:\n",
        "\n",
        "```python\n",
        "torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=YOLO_MODEL_PATH)\n",
        "```\n",
        "\n",
        "### LLaVA Model (Car-Part Recognition)\n",
        "\n",
        "Loaded with 8-bit quantization:\n",
        "\n",
        "```python\n",
        "LlavaForConditionalGeneration.from_pretrained(..., quantization_config=BNB_CONFIG)\n",
        "```\n",
        "\n",
        "Benefits:\n",
        "\n",
        "* Lower VRAM usage\n",
        "* Faster inference\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd0d **Damage Detection Logic (YOLO Section)**\n",
        "\n",
        "When the user uploads a vehicle image:\n",
        "\n",
        "1. YOLO detects damage regions\n",
        "2. Very small boxes are filtered out\n",
        "3. Each bounding box is cropped tightly\n",
        "4. Severity score = average YOLO confidence\n",
        "5. Annotated image is generated for preview\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83e\udde0 **Car Part Identification Logic (LLaVA Section)**\n",
        "\n",
        "Each crop is passed to LLaVA with a structured prompt:\n",
        "\n",
        "```\n",
        "Identify the EXACT car part and describe the damage.\n",
        "Return only: <part> - <damage>\n",
        "```\n",
        "\n",
        "Examples:\n",
        "\n",
        "```\n",
        "Front bumper \u2013 cracked\n",
        "Right headlight \u2013 broken\n",
        "Left fender \u2013 major dent\n",
        "```\n",
        "\n",
        "LLaVA output is cleaned, deduplicated, and limited to max 8 parts.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcb0 **Cost Estimation Engine Logic**\n",
        "\n",
        "Cost is calculated using:\n",
        "\n",
        "### Inputs:\n",
        "\n",
        "* Number of damages\n",
        "* Severity score\n",
        "* Type of parts damaged\n",
        "\n",
        "### Output:\n",
        "\n",
        "A cost range, e.g.:\n",
        "\n",
        "```\n",
        "\u20b924,500 \u2013 \u20b958,000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83e\uddfe **Final Report Format**\n",
        "\n",
        "The backend returns a professional repair report:\n",
        "\n",
        "```\n",
        "Damage Level: Moderate\n",
        "\n",
        "Estimated Repair Cost (INR):\n",
        "\u20b918,000 \u2013 \u20b942,000\n",
        "\n",
        "Parts Affected:\n",
        "- Front bumper - dented\n",
        "- Left headlight - cracked\n",
        "\n",
        "Repair Recommendation:\n",
        "- Replace damaged components\n",
        "- Repaint affected areas\n",
        "- Perform alignment check\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udda5 **Web UI Explanation**\n",
        "\n",
        "Your app includes:\n",
        "\n",
        "### **/ (Home page)**\n",
        "\n",
        "Introduction + navigation\n",
        "\n",
        "### **/estimate page**\n",
        "\n",
        "Upload \u2192 Detection \u2192 Severity \u2192 Crops \u2192 LLaVA \u2192 Cost Estimate\n",
        "\n",
        "### All interactions happen without page reload\n",
        "\n",
        "(using fetch APIs).\n",
        "\n",
        "---\n",
        "\n",
        "## \u25b6\ufe0f **Starting the Web App**\n",
        "\n",
        "At the end of the notebook:\n",
        "\n",
        "```python\n",
        "!nohup python app.py > flask.log 2>&1 &\n",
        "```\n",
        "\n",
        "The server runs in the background.\n",
        "\n",
        "### Then you start ngrok:\n",
        "\n",
        "```python\n",
        "public_url = ngrok.connect(8000)\n",
        "```\n",
        "\n",
        "Copy the public URL \u2192 open in browser \u2192 start using the app!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6tcqkOWctNv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnKo7VW3czmQ"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/MyDrive/vehicle damage detection\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwIvDqw1c_9q"
      },
      "outputs": [],
      "source": [
        "!pip install -q flask pyngrok ultralytics transformers accelerate bitsandbytes pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFtU_GLmitPe"
      },
      "outputs": [],
      "source": [
        "!mkdir -p templates static uploads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyYhJ26hitMB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"hf_your_token_here\")   # replace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N553-WEXitKC"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/navbar.html\n",
        "<header class=\"topbar\">\n",
        "  <div class=\"topbar-left\">\n",
        "    <span class=\"logo-icon\">\ud83d\ude97</span>\n",
        "    <div class=\"brand-box\">\n",
        "      <div class=\"brand-title\">AutoDamage AI</div>\n",
        "      <div class=\"brand-sub\">Smart Vehicle Damage Estimation</div>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"topbar-right\">\n",
        "    <a href=\"{{ url_for('home') }}\"\n",
        "       class=\"nav-btn {{ 'active' if request.path in ['/', url_for('home')] else '' }}\">\n",
        "       Home\n",
        "    </a>\n",
        "\n",
        "    <a href=\"{{ url_for('estimate_page') }}\"\n",
        "       class=\"nav-btn {{ 'active' if request.path == url_for('estimate_page') else '' }}\">\n",
        "       Estimate Cost\n",
        "    </a>\n",
        "  </div>\n",
        "</header>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWL97UhyitHX"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import uuid\n",
        "import json\n",
        "import math\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from flask import Flask, render_template, request, send_from_directory, jsonify\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# LLaVA imports\n",
        "from transformers import LlavaProcessor, LlavaForConditionalGeneration\n",
        "\n",
        "# YOLOv5 via torch.hub\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# -------------------------------------------\n",
        "# FLASK CONFIG\n",
        "# -------------------------------------------\n",
        "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
        "UPLOAD_DIR = Path(\"uploads\")\n",
        "UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------\n",
        "# MODEL PATHS\n",
        "# -------------------------------------------\n",
        "YOLO_MODEL_PATH = \"/content/drive/MyDrive/vehicle damage detection/best (2).pt\"\n",
        "LLAVA_MODEL = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
        "\n",
        "# Cache\n",
        "CACHE = {\"detector\": None, \"processor\": None, \"llava\": None}\n",
        "\n",
        "# GPU config\n",
        "BNB_CONFIG = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "# -------------------------------------------\n",
        "# LOAD MODELS\n",
        "# -------------------------------------------\n",
        "def load_models(force_reload=False):\n",
        "    # Load YOLOv5 detector via torch.hub (custom)\n",
        "    if CACHE[\"detector\"] is None or force_reload:\n",
        "        try:\n",
        "            CACHE[\"detector\"] = torch.hub.load(\n",
        "                \"ultralytics/yolov5\",\n",
        "                \"custom\",\n",
        "                path=YOLO_MODEL_PATH,\n",
        "                force_reload=False\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"YOLO load failed:\", e)\n",
        "            CACHE[\"detector\"] = None\n",
        "\n",
        "    # Load LLaVA processor + model\n",
        "    if CACHE[\"processor\"] is None or CACHE[\"llava\"] is None or force_reload:\n",
        "        try:\n",
        "            CACHE[\"processor\"] = LlavaProcessor.from_pretrained(LLAVA_MODEL)\n",
        "            CACHE[\"llava\"] = LlavaForConditionalGeneration.from_pretrained(\n",
        "                LLAVA_MODEL,\n",
        "                device_map=\"cuda\",\n",
        "                torch_dtype=torch.float16,\n",
        "                quantization_config=BNB_CONFIG,\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"LLaVA load failed:\", e)\n",
        "            CACHE[\"processor\"] = None\n",
        "            CACHE[\"llava\"] = None\n",
        "\n",
        "    return CACHE[\"detector\"], CACHE[\"processor\"], CACHE[\"llava\"]\n",
        "\n",
        "# -------------------------------------------\n",
        "# TIGHT CROP FUNCTION\n",
        "# -------------------------------------------\n",
        "def crop_image_tight(pil_img, bbox):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    x1 = max(0, x1)\n",
        "    y1 = max(0, y1)\n",
        "    x2 = min(pil_img.width - 1, x2)\n",
        "    y2 = min(pil_img.height - 1, y2)\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return None\n",
        "    return pil_img.crop((x1, y1, x2, y2))\n",
        "\n",
        "# -------------------------------------------\n",
        "# IDENTIFY PART USING LLaVA (IMPROVED)\n",
        "# -------------------------------------------\n",
        "def identify_part_with_llava(processor, model, crop_pil):\n",
        "    \"\"\"\n",
        "    Uses LLaVA to identify specific car part and short damage in format:\n",
        "    <Part name> - <damage>\n",
        "    Returns None on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ensure RGB and resize for stable performance\n",
        "        crop_pil = crop_pil.convert(\"RGB\").resize((336, 336))\n",
        "\n",
        "        prompt = (\n",
        "            \"You are an automotive damage expert.\\n\"\n",
        "            \"Identify the EXACT car part visible in this image and describe the damage.\\n\"\n",
        "            \"Return ONLY one short line in this EXACT format:\\n\"\n",
        "            \"<part name> - <damage>\\n\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            \"Front bumper - cracked\\n\"\n",
        "            \"Right headlight - broken\\n\"\n",
        "            \"Wheel - punctured\\n\"\n",
        "            \"Left fender - dented\\n\"\n",
        "        )\n",
        "\n",
        "        # Processor expects (images, text)\n",
        "        inputs = processor(crop_pil, prompt, return_tensors=\"pt\").to(model.device, torch.float16)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            out = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=60,\n",
        "                do_sample=False,\n",
        "                eos_token_id=processor.tokenizer.eos_token_id if hasattr(processor, \"tokenizer\") else None\n",
        "            )\n",
        "\n",
        "        text = processor.decode(out[0], skip_special_tokens=True).strip()\n",
        "        if not text:\n",
        "            return None\n",
        "\n",
        "        # Take first non-empty line\n",
        "        line = next((ln.strip() for ln in text.splitlines() if ln.strip()), \"\").strip()\n",
        "\n",
        "        # cleanup\n",
        "        line = line.replace(\"Answer:\", \"\").replace(\"###\", \"\").strip()\n",
        "        # ensure contains dash to match format\n",
        "        if \"-\" not in line:\n",
        "            return None\n",
        "\n",
        "        # limit length\n",
        "        return line[:140]\n",
        "    except Exception as e:\n",
        "        # print for debug in flask logs\n",
        "        print(\"LLaVA error:\", e)\n",
        "        return None\n",
        "\n",
        "# -------------------------------------------\n",
        "# COST ENGINE\n",
        "# -------------------------------------------\n",
        "def compute_cost_range(num_damages, severity):\n",
        "    if num_damages == 0:\n",
        "        base_low, base_high = 2000, 6000\n",
        "    elif num_damages == 1:\n",
        "        base_low, base_high = 8000, 15000\n",
        "    elif num_damages == 2:\n",
        "        base_low, base_high = 15000, 30000\n",
        "    elif num_damages == 3:\n",
        "        base_low, base_high = 25000, 60000\n",
        "    else:\n",
        "        base_low, base_high = 40000, 120000\n",
        "\n",
        "    multiplier = 1.0 + (severity * 1.2)\n",
        "    low = int(math.ceil(base_low * multiplier))\n",
        "    high = int(math.ceil(base_high * multiplier))\n",
        "    return f\"\u20b9{low:,} \u2013 \u20b9{high:,}\"\n",
        "\n",
        "# -------------------------------------------\n",
        "# FORMAT OUTPUT (F1)\n",
        "# -------------------------------------------\n",
        "def format_report(damage_level, cost_range, parts_list):\n",
        "    parts_text = \"\\n\".join(f\"- {p}\" for p in parts_list) if parts_list else \"- No specific part identified\"\n",
        "    recommendations = [\n",
        "        \"Replace damaged components\",\n",
        "        \"Repaint affected areas\",\n",
        "        \"Perform alignment check\"\n",
        "    ]\n",
        "    rec_text = \"\\n\".join(f\"- {r}\" for r in recommendations)\n",
        "\n",
        "    report = (\n",
        "        f\"Damage Level: {damage_level}\\n\\n\"\n",
        "        f\"Estimated Repair Cost (INR):\\n{cost_range}\\n\\n\"\n",
        "        f\"Parts Affected:\\n{parts_text}\\n\\n\"\n",
        "        f\"Repair Recommendation:\\n{rec_text}\"\n",
        "    )\n",
        "    return report\n",
        "\n",
        "# -------------------------------------------\n",
        "# ROUTES\n",
        "# -------------------------------------------\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/estimate\")\n",
        "def estimate_page():\n",
        "    return render_template(\"estimate.html\")\n",
        "\n",
        "@app.route(\"/uploads/<path:filename>\")\n",
        "def uploaded_file(filename):\n",
        "    return send_from_directory(str(UPLOAD_DIR), filename)\n",
        "\n",
        "# -------------------------------------------\n",
        "# API: ANALYZE DAMAGE (YOLO)\n",
        "# -------------------------------------------\n",
        "@app.route(\"/api/analyze_damage\", methods=[\"POST\"])\n",
        "def analyze_damage_api():\n",
        "    try:\n",
        "        if \"image\" not in request.files:\n",
        "            return jsonify({\"error\": \"No image uploaded\"}), 400\n",
        "\n",
        "        img_file = request.files[\"image\"]\n",
        "        fname = f\"{uuid.uuid4().hex}_{secure_filename(img_file.filename)}\"\n",
        "        saved_path = UPLOAD_DIR / fname\n",
        "        img_file.save(saved_path)\n",
        "\n",
        "        detector, _, _ = load_models()\n",
        "        if detector is None:\n",
        "            return jsonify({\"error\": \"YOLO detector not loaded\"}), 500\n",
        "\n",
        "        results = detector(str(saved_path))\n",
        "\n",
        "        try:\n",
        "            boxes = results.xyxy[0].cpu().numpy()\n",
        "        except:\n",
        "            boxes = []\n",
        "\n",
        "        detections = []\n",
        "        confs = []\n",
        "        crop_files = []\n",
        "\n",
        "        pil_img = Image.open(saved_path).convert(\"RGB\")\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            x1, y1, x2, y2, conf, cls = box\n",
        "            conf = float(conf)\n",
        "\n",
        "            # ignore tiny boxes - likely noise\n",
        "            if (x2 - x1) < 40 or (y2 - y1) < 40:\n",
        "                continue\n",
        "\n",
        "            detections.append({\"class\": \"damage\", \"confidence\": round(conf, 3)})\n",
        "            confs.append(conf)\n",
        "\n",
        "            crop = crop_image_tight(pil_img, (x1, y1, x2, y2))\n",
        "            if crop is None:\n",
        "                continue\n",
        "\n",
        "            crop_name = f\"{saved_path.stem}_crop_{i}.jpg\"\n",
        "            crop_path = UPLOAD_DIR / crop_name\n",
        "            # save high-quality crop\n",
        "            crop.save(crop_path, quality=90)\n",
        "            crop_files.append(str(crop_path))\n",
        "\n",
        "        severity = round(sum(confs) / len(confs), 3) if confs else 0.0\n",
        "\n",
        "        try:\n",
        "            results.render()\n",
        "            rendered = results.ims[0]\n",
        "            annotated_img = Image.fromarray(rendered)\n",
        "            annotated_name = f\"det_{fname}\"\n",
        "            annotated_path = UPLOAD_DIR / annotated_name\n",
        "            annotated_img.save(annotated_path, quality=90)\n",
        "            annotated_url = f\"/uploads/{annotated_name}\"\n",
        "        except:\n",
        "            annotated_url = None\n",
        "\n",
        "        return jsonify({\n",
        "            \"success\": True,\n",
        "            \"original\": f\"/uploads/{fname}\",\n",
        "            \"annotated\": annotated_url,\n",
        "            \"detections\": detections,\n",
        "            \"severity\": severity,\n",
        "            \"crops\": crop_files\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# -------------------------------------------\n",
        "# API: ESTIMATE COST (LLaVA)\n",
        "# -------------------------------------------\n",
        "@app.route(\"/api/estimate_cost\", methods=[\"POST\"])\n",
        "def estimate_cost_api():\n",
        "    try:\n",
        "        payload = request.get_json(force=True)\n",
        "        detections = payload.get(\"detections\", [])\n",
        "        severity = float(payload.get(\"severity\", 0))\n",
        "        crop_files = payload.get(\"crops\", [])\n",
        "\n",
        "        # load models\n",
        "        detector, processor, llava = load_models()\n",
        "        num_damages = len(detections)\n",
        "\n",
        "        if severity < 0.30:\n",
        "            damage_level = \"Minor\"\n",
        "        elif severity < 0.65:\n",
        "            damage_level = \"Moderate\"\n",
        "        else:\n",
        "            damage_level = \"Severe\"\n",
        "\n",
        "        cost_range = compute_cost_range(num_damages, severity)\n",
        "\n",
        "        parts_identified = []\n",
        "\n",
        "        # fallback default mapping if llava not available or no crops\n",
        "        if llava is None or processor is None or not crop_files:\n",
        "            default_parts = {\n",
        "                0: [],\n",
        "                1: [\"Front bumper - dented\"],\n",
        "                2: [\"Front bumper - dented\", \"Left fender - scratched\"],\n",
        "                3: [\"Front bumper - dented\", \"Left fender - scratched\", \"Headlight - broken\"],\n",
        "            }\n",
        "            parts_identified = default_parts.get(num_damages, [\"Front bumper - multiple panels\"])\n",
        "        else:\n",
        "            # run LLaVA over each crop (tight crop)\n",
        "            for cpath in crop_files:\n",
        "                try:\n",
        "                    crop_img = Image.open(cpath).convert(\"RGB\")\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                res = identify_part_with_llava(processor, llava, crop_img)\n",
        "                if res:\n",
        "                    cleaned = res.strip().rstrip(\" .:;,-\")\n",
        "                    parts_identified.append(cleaned)\n",
        "\n",
        "            # de-duplicate while preserving order using case-insensitive comparison\n",
        "            seen = set()\n",
        "            unique_parts = []\n",
        "            for p in parts_identified:\n",
        "                key = p.lower()\n",
        "                if key not in seen:\n",
        "                    unique_parts.append(p)\n",
        "                    seen.add(key)\n",
        "            parts_identified = unique_parts or [\"Front bumper - multiple panels\"]\n",
        "\n",
        "        # limit number of parts\n",
        "        parts_identified = parts_identified[:8]\n",
        "\n",
        "        report = format_report(damage_level, cost_range, parts_identified)\n",
        "\n",
        "        # return plain text report\n",
        "        return app.response_class(report, mimetype=\"text/plain\")\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# -------------------------------------------\n",
        "# RUN SERVER\n",
        "# -------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading models...\")\n",
        "    load_models()\n",
        "    print(\"Models loaded. Starting server.\")\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxvVPxNhjE2K"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/index.html\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>AutoDamage AI</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  {% include 'navbar.html' %}\n",
        "\n",
        "  <main class=\"container\">\n",
        "    <section class=\"hero\">\n",
        "      <h1 class=\"title\">AutoDamage AI</h1>\n",
        "      <p class=\"subtitle\">\n",
        "        Advanced AI system using YOLO + LLaVA to analyze damage, identify affected parts,\n",
        "        and generate a professional repair cost report.\n",
        "      </p>\n",
        "\n",
        "      <a href=\"{{ url_for('estimate_page') }}\" class=\"cta-button\">\n",
        "        \ud83d\ude97 Start Damage Assessment\n",
        "      </a>\n",
        "    </section>\n",
        "  </main>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdv2zLyMjEzU"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/estimate.html\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>Estimate Cost | AutoDamage AI</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "{% include 'navbar.html' %}\n",
        "\n",
        "<main class=\"container\">\n",
        "\n",
        "  <h2 class=\"page-title\">Vehicle Damage Assessment</h2>\n",
        "\n",
        "  <div class=\"upload-box\">\n",
        "    <input type=\"file\" id=\"image\" accept=\"image/*\" onchange=\"previewImage(event)\">\n",
        "    <img id=\"preview\" class=\"preview-img\" style=\"display:none\">\n",
        "  </div>\n",
        "\n",
        "  <button id=\"analyzeBtn\" class=\"btn primary\" onclick=\"analyzeDamage()\">\ud83d\udd0d Analyze Damage</button>\n",
        "  <div id=\"loadingAnalyze\" class=\"loader\" style=\"display:none;\">Analyzing damage\u2026</div>\n",
        "\n",
        "  <div id=\"resultSection\" style=\"display:none\">\n",
        "\n",
        "    <h3>Detected Damages</h3>\n",
        "    <div id=\"detList\" class=\"det-list\"></div>\n",
        "\n",
        "    <h3>Severity Score</h3>\n",
        "    <div id=\"sevScore\"></div>\n",
        "\n",
        "    <h3>Annotated Image</h3>\n",
        "    <img id=\"annotatedImg\" class=\"annotated-img\">\n",
        "\n",
        "    <h3>Cropped Damage Regions (Used for LLaVA part identification)</h3>\n",
        "    <div id=\"cropGrid\" class=\"crop-grid\"></div>\n",
        "\n",
        "    <button id=\"costBtn\" class=\"btn accent\" onclick=\"estimateCost()\">\ud83d\udcb0 Generate Cost Estimate</button>\n",
        "    <div id=\"loadingCost\" class=\"loader\" style=\"display:none;\">Generating cost estimate\u2026</div>\n",
        "\n",
        "    <div id=\"costOutput\" class=\"cost-box\"></div>\n",
        "  </div>\n",
        "\n",
        "</main>\n",
        "\n",
        "<script>\n",
        "let uploadedFile = null;\n",
        "let detections = [];\n",
        "let severity = 0;\n",
        "let cropFiles = [];   // IMPORTANT for LLaVA\n",
        "\n",
        "function previewImage(e) {\n",
        "  uploadedFile = e.target.files[0];\n",
        "  const img = document.getElementById(\"preview\");\n",
        "  img.src = URL.createObjectURL(uploadedFile);\n",
        "  img.style.display = \"block\";\n",
        "}\n",
        "\n",
        "async function analyzeDamage() {\n",
        "  if (!uploadedFile) {\n",
        "    alert(\"Select an image first!\");\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  document.getElementById(\"analyzeBtn\").disabled = true;\n",
        "  document.getElementById(\"loadingAnalyze\").style.display = \"block\";\n",
        "\n",
        "  const fd = new FormData();\n",
        "  fd.append(\"image\", uploadedFile);\n",
        "\n",
        "  const r = await fetch(\"/api/analyze_damage\", { method: \"POST\", body: fd });\n",
        "  const j = await r.json();\n",
        "\n",
        "  document.getElementById(\"analyzeBtn\").disabled = false;\n",
        "  document.getElementById(\"loadingAnalyze\").style.display = \"none\";\n",
        "\n",
        "  detections = j.detections || [];\n",
        "  severity = j.severity || 0;\n",
        "  cropFiles = j.crops || [];   // <<--- IMPORTANT FIX\n",
        "\n",
        "  document.getElementById(\"detList\").innerHTML =\n",
        "    detections.map(d => `<div>Class: ${d.class}, Conf: ${d.confidence}</div>`).join(\"\");\n",
        "\n",
        "  document.getElementById(\"sevScore\").textContent = severity;\n",
        "  document.getElementById(\"annotatedImg\").src = j.annotated;\n",
        "\n",
        "  // show cropped images\n",
        "  document.getElementById(\"cropGrid\").innerHTML =\n",
        "    cropFiles.map(c => `<img src=\"${c}\" class=\"crop-img\">`).join(\"\");\n",
        "\n",
        "  document.getElementById(\"resultSection\").style.display = \"block\";\n",
        "}\n",
        "\n",
        "async function estimateCost() {\n",
        "  const payload = {\n",
        "    detections,\n",
        "    severity,\n",
        "    crops: cropFiles   // <<--- SEND TO BACKEND\n",
        "  };\n",
        "\n",
        "  document.getElementById(\"costBtn\").disabled = true;\n",
        "  document.getElementById(\"loadingCost\").style.display = \"block\";\n",
        "\n",
        "  const r = await fetch(\"/api/estimate_cost\", {\n",
        "    method: \"POST\",\n",
        "    headers: {\"Content-Type\": \"application/json\"},\n",
        "    body: JSON.stringify(payload)\n",
        "  });\n",
        "\n",
        "  const text = await r.text();\n",
        "\n",
        "  document.getElementById(\"costBtn\").disabled = false;\n",
        "  document.getElementById(\"loadingCost\").style.display = \"none\";\n",
        "\n",
        "  document.getElementById(\"costOutput\").innerText = text;\n",
        "}\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoxyZfL7jExO"
      },
      "outputs": [],
      "source": [
        "%%writefile static/style.css\n",
        "/* =============================\n",
        "   GLOBAL\n",
        "==============================*/\n",
        "body {\n",
        "  background: #0b132b;\n",
        "  color: white;\n",
        "  font-family: Arial, sans-serif;\n",
        "  margin: 0;\n",
        "  padding: 0;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   NAVBAR\n",
        "==============================*/\n",
        ".topbar {\n",
        "  display:flex;\n",
        "  justify-content:space-between;\n",
        "  padding:14px 24px;\n",
        "  background:#1c2541;\n",
        "  align-items:center;\n",
        "  border-bottom: 2px solid #3a86ff22;\n",
        "}\n",
        "\n",
        ".nav-btn {\n",
        "  color:#bfc7e0;\n",
        "  margin-left:18px;\n",
        "  text-decoration:none;\n",
        "  transition:0.2s;\n",
        "  padding: 6px 10px;\n",
        "  border-radius: 6px;\n",
        "}\n",
        "\n",
        ".nav-btn:hover {\n",
        "  color:white;\n",
        "  background:#3a86ff33;\n",
        "  transform:scale(1.08);\n",
        "}\n",
        "\n",
        ".nav-btn.active {\n",
        "  color:white;\n",
        "  background:#3a86ff55;\n",
        "  font-weight:bold;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   PAGE LAYOUT\n",
        "==============================*/\n",
        ".container {\n",
        "  max-width:900px;\n",
        "  margin:auto;\n",
        "  padding:30px;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   BUTTONS\n",
        "==============================*/\n",
        ".btn {\n",
        "  padding:12px 20px;\n",
        "  border:none;\n",
        "  border-radius:8px;\n",
        "  cursor:pointer;\n",
        "  margin-top:10px;\n",
        "  font-weight:bold;\n",
        "  transition:0.2s;\n",
        "  font-size:15px;\n",
        "}\n",
        "\n",
        ".btn:hover {\n",
        "  transform:scale(1.05);\n",
        "}\n",
        "\n",
        ".btn:disabled {\n",
        "  opacity:0.6;\n",
        "  cursor:not-allowed;\n",
        "  transform:none;\n",
        "}\n",
        "\n",
        ".btn.primary {\n",
        "  background:#3a86ff;\n",
        "  color:white;\n",
        "}\n",
        "\n",
        ".btn.accent {\n",
        "  background:#2ec4b6;\n",
        "  color:black;\n",
        "}\n",
        "\n",
        ".btn.warn {\n",
        "  background:#ffbe0b;\n",
        "  color:black;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   LOADER TEXT\n",
        "==============================*/\n",
        ".loader {\n",
        "  margin-top:10px;\n",
        "  font-size:14px;\n",
        "  color:#ffe066;\n",
        "  animation: pulse 1.5s infinite;\n",
        "}\n",
        "\n",
        "@keyframes pulse {\n",
        "  0% {opacity: 0.3;}\n",
        "  50% {opacity: 1;}\n",
        "  100% {opacity: 0.3;}\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   IMAGES\n",
        "==============================*/\n",
        ".preview-img,\n",
        ".annotated-img {\n",
        "  width:100%;\n",
        "  margin-top:20px;\n",
        "  border-radius:10px;\n",
        "  box-shadow: 0px 0px 12px #0008;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   CROPPED DAMAGE GRID\n",
        "==============================*/\n",
        ".crop-grid {\n",
        "  display: grid;\n",
        "  grid-template-columns: repeat(auto-fill, minmax(140px, 1fr));\n",
        "  gap: 14px;\n",
        "  margin-top: 12px;\n",
        "}\n",
        "\n",
        ".crop-img {\n",
        "  width: 100%;\n",
        "  height: 130px;\n",
        "  object-fit: cover;\n",
        "  border-radius: 8px;\n",
        "  border: 2px solid #3a86ff55;\n",
        "  transition: 0.25s;\n",
        "}\n",
        "\n",
        ".crop-img:hover {\n",
        "  transform: scale(1.06);\n",
        "  border-color: #3a86ff;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   OUTPUT BOXES\n",
        "==============================*/\n",
        ".cost-box {\n",
        "  background:#1c2541;\n",
        "  padding:20px;\n",
        "  border-radius:10px;\n",
        "  margin-top:20px;\n",
        "  white-space:pre-wrap;\n",
        "  border:1px solid #3a86ff;\n",
        "  box-shadow: 0px 0px 12px #0006;\n",
        "  line-height: 1.5;\n",
        "}\n",
        "\n",
        "/* Part Identification Box Styling */\n",
        "#partsOutput {\n",
        "  background: #172036;\n",
        "  border: 1px solid #ffbe0b99;\n",
        "  box-shadow: 0px 0px 10px #ffbe0b44;\n",
        "  margin-top: 20px;\n",
        "  padding: 18px;\n",
        "  border-radius: 10px;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   TITLES & TEXT\n",
        "==============================*/\n",
        ".page-title {\n",
        "  font-size: 28px;\n",
        "  margin-bottom: 20px;\n",
        "  font-weight: bold;\n",
        "  color: #d7e3ff;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "  margin-top: 25px;\n",
        "  color: #a3bffa;\n",
        "}\n",
        "\n",
        ".det-list div {\n",
        "  background: #1c2541;\n",
        "  margin: 6px 0;\n",
        "  padding: 8px 12px;\n",
        "  border-radius: 6px;\n",
        "  border-left: 4px solid #3a86ff;\n",
        "}\n",
        "\n",
        "/* =============================\n",
        "   UPLOAD BOX\n",
        "==============================*/\n",
        ".upload-box {\n",
        "  padding:20px;\n",
        "  border:2px dashed #5bc0be;\n",
        "  text-align:center;\n",
        "  margin:20px 0;\n",
        "  border-radius: 12px;\n",
        "  background: #0f1936;\n",
        "  transition: 0.25s;\n",
        "}\n",
        "\n",
        ".upload-box:hover {\n",
        "  background:#12204a;\n",
        "  border-color:#2ec4b6;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC0aQffFjEvb"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "flask==2.2.5\n",
        "pyngrok==5.1.0\n",
        "ultralytics==8.1.0\n",
        "transformers==4.34.0\n",
        "accelerate==0.22.0\n",
        "bitsandbytes==0.39.0\n",
        "pillow==10.0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxjLpGefTaz5"
      },
      "outputs": [],
      "source": [
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7irFjgwvTaz5"
      },
      "outputs": [],
      "source": [
        "!lsof -i :8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9ZcAoPTTaz5"
      },
      "outputs": [],
      "source": [
        "!kill -9 5206"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_7L1w91Taz6"
      },
      "outputs": [],
      "source": [
        "!nohup python app.py > flask.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_euoBj1-b6i"
      },
      "source": [
        "\ud83d\udcd8  Ngrok Setup\n",
        "\n",
        "Ngrok provides a public HTTPS link.\n",
        "\n",
        "Your ngrok token was removed for safety.\n",
        "\n",
        "To use ngrok:\n",
        "1. Get token \u2192 https://dashboard.ngrok.com/get-started/your-authtoken  \n",
        "2. Add inside notebook:\n",
        "\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "3. Start tunnel:\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "\n",
        "Shareable app link appears here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YLbLHWxTaz6"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"   # \ud83d\udd11 replace with your ngrok token\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "!sleep 3 && tail -n 30 flask.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqlHxRweTaz6"
      },
      "outputs": [],
      "source": [
        "!tail -n 50 flask.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8HijxzcTaz6"
      },
      "outputs": [],
      "source": []
    }
  ]
}