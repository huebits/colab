{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70zC5WwF-7a7"
      },
      "source": [
        "## \ud83d\udcd8 How to Use Kaggle (Upload Dataset & Notebook)\n",
        "\n",
        "### \u2705 Step 1: Create Kaggle Account\n",
        "- Go to \ud83d\udc49 https://www.kaggle.com  \n",
        "- Sign in using Google / Email\n",
        "\n",
        "---\n",
        "\n",
        "### \u2705 Step 2: Upload Your Dataset\n",
        "1. Click **Datasets** \u2192 **Create New Dataset**\n",
        "2. Upload your **dataset folder or ZIP file**\n",
        "3. Add:\n",
        "   - Dataset name\n",
        "   - Short description\n",
        "4. Set visibility \u2192 **Public / Private**\n",
        "5. Click **Create**\n",
        "\n",
        "\u2705 After upload, Kaggle gives a dataset path like:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-P2LdxV-7a9"
      },
      "source": [
        "## \ud83d\udfe2 Cell 1 \u2013 Imports, Paths & Data Generators\n",
        "\n",
        "This cell:\n",
        "\n",
        "- Imports core libraries:\n",
        "  - **TensorFlow / Keras** \u2192 modeling & training\n",
        "  - **ImageDataGenerator** \u2192 image loading + augmentation\n",
        "  - **Sklearn metrics** \u2192 evaluation (report + confusion matrix)\n",
        "  - **Matplotlib / Seaborn** \u2192 visualization\n",
        "\n",
        "- Defines dataset paths:\n",
        "  - `train_dir`, `val_dir`, `test_dir` inside the **Diabetic Retinopathy** dataset folder.\n",
        "\n",
        "- Sets image & training parameters:\n",
        "  - `IMG_HEIGHT = 224`, `IMG_WIDTH = 224`, `BATCH_SIZE = 32`\n",
        "  - `NUM_CLASSES = 2` \u2192 DR vs No_DR (binary)\n",
        "\n",
        "- Creates **data generators**:\n",
        "  - `train_datagen` with:\n",
        "    - rescaling (0\u20131)\n",
        "    - rotation, shift, zoom, horizontal flip \u2192 robust to variations\n",
        "  - `val_datagen`, `test_datagen` with just rescaling\n",
        "\n",
        "- Builds **directory-based generators**:\n",
        "  - `train_generator`, `val_generator`, `test_generator`\n",
        "  - `class_mode='binary'` \u2192 labels are 0 or 1\n",
        "  - `shuffle=False` for test generator \u2192 keeps order for evaluation\n",
        "\n",
        "- Prints `train_generator.class_indices` to show class \u2192 label mapping.\n",
        "\n",
        "\ud83d\udd17 Official docs (used once for entire code):\n",
        "\n",
        "- Keras ImageDataGenerator: https://keras.io/api/preprocessing/image/  \n",
        "- Model training API: https://keras.io/api/models/model_training_apis/  \n",
        "- Sklearn metrics: https://scikit-learn.org/stable/modules/model_evaluation.html  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Do1Rfg-7a9"
      },
      "source": [
        "#### Dataset path: https://www.kaggle.com/datasets/huebitsvizg/retinopathy-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "vnzvuziH-7a9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# Paths \u2014 adjust as per your folder structure\n",
        "base_dir = '/kaggle/input/diagnosis-of-diabetic-retinopathy/Diagnosis of Diabetic Retinopathy'   # change this to your root folder\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir   = os.path.join(base_dir, 'valid')\n",
        "test_dir  = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Image parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH  = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2    # DR vs No_DR\n",
        "\n",
        "# Data generators with augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'     # since two classes\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False    # for evaluation, keep ordering\n",
        ")\n",
        "\n",
        "print(\"Classes:\", train_generator.class_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02gt-4uk-7a-"
      },
      "source": [
        "## \ud83d\udfe2 Cell 2 \u2013 CNN Model Definition & Compilation\n",
        "\n",
        "This cell defines a **simple CNN** for binary DR classification:\n",
        "\n",
        "- Architecture:\n",
        "  - `Input(shape=(224, 224, 3))`\n",
        "  - Conv2D(32) \u2192 MaxPooling\n",
        "  - Conv2D(64) \u2192 MaxPooling\n",
        "  - Conv2D(128) \u2192 MaxPooling  \n",
        "  \u2192 gradual increase in filters = more complex pattern learning\n",
        "  - `Flatten()` \u2192 converts feature maps to a vector\n",
        "  - `Dense(128, relu)` \u2192 learns high-level features\n",
        "  - `Dropout(0.5)` \u2192 reduces overfitting\n",
        "  - `Dense(1, sigmoid)` \u2192 outputs a probability for \"DR present\"\n",
        "\n",
        "- Compilation:\n",
        "  - Optimizer: `adam`\n",
        "  - Loss: `binary_crossentropy` (since binary classification)\n",
        "  - Metric: `accuracy`\n",
        "\n",
        "- `model_cnn.summary()` prints:\n",
        "  - Layer types\n",
        "  - Output shapes\n",
        "  - Number of parameters\n",
        "\n",
        "\u2705 This creates and prepares the CNN for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "rp7jCCoH-7a-"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model_cnn = keras.Sequential([\n",
        "    layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')   # binary classification\n",
        "])\n",
        "\n",
        "model_cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_cnn.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mHTWsy-7a-"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "_wk31KkN-7a_"
      },
      "outputs": [],
      "source": [
        "epochs = 10   # you can increase\n",
        "history_cnn = model_cnn.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
        "    epochs=epochs,\n",
        "    validation_data = val_generator,\n",
        "    validation_steps = val_generator.samples // BATCH_SIZE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9UoBNIx-7a_"
      },
      "source": [
        "## \ud83d\udfe2 Cell 3 \u2013 Prediction, Classification Report & Confusion Matrix\n",
        "\n",
        "This cell **evaluates** the CNN:\n",
        "\n",
        "- `model_cnn.predict(test_generator, steps=test_steps)`:\n",
        "  - Gets predicted probabilities for each test image.\n",
        "- Converts probabilities to class labels:\n",
        "  - `pred_labels = (pred_probs > 0.5).astype(int)`  \n",
        "  \u2192 threshold at 0.5:  \n",
        "    - \u2265 0.5 \u2192 class 1 (DR)  \n",
        "    - < 0.5 \u2192 class 0 (No_DR)\n",
        "\n",
        "- `true_labels = test_generator.classes`:\n",
        "  - True labels in same order (because `shuffle=False`).\n",
        "\n",
        "- `classification_report(...)`:\n",
        "  - Shows precision, recall, F1-score and support per class.\n",
        "\n",
        "- `confusion_matrix(true_labels, pred_labels)`:\n",
        "  - Counts TP, TN, FP, FN\n",
        "  - Plotted using Seaborn heatmap:\n",
        "    - X-axis: Predicted\n",
        "    - Y-axis: Actual\n",
        "\n",
        "\u2705 This gives a clear picture of **how well the CNN distinguishes DR vs No_DR**, beyond just accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "n3oidu3P-7a_"
      },
      "outputs": [],
      "source": [
        "# Get predictions\n",
        "test_steps = test_generator.samples // BATCH_SIZE + 1\n",
        "pred_probs = model_cnn.predict(test_generator, steps=test_steps)\n",
        "pred_labels = (pred_probs > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "true_labels = test_generator.classes  # since shuffle=False\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(true_labels, pred_labels, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"CNN Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "qLGhlPxv-7a_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Save as HDF5\n",
        "model_cnn.save('cnn_model.h5')\n",
        "print(\"CNN model saved as cnn_model.h5\")\n",
        "\n",
        "# Load later\n",
        "loaded_cnn_h5 = load_model('cnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "NmgkNyfd-7a_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this in colab"
      ],
      "metadata": {
        "id": "qESJVmzU_VBv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SH2cTv9_FyN"
      },
      "source": [
        "##  Environment Setup for Model Deployment (Flask + Ngrok)\n",
        "\n",
        "This cell prepares the system for **web deployment of your deep learning model**.\n",
        "\n",
        "###  Installed Packages\n",
        "- **Flask** \u2192 Web framework for building the prediction UI  \n",
        "  https://flask.palletsprojects.com/\n",
        "- **pyngrok** \u2192 Creates public URL for Colab/Notebook apps  \n",
        "  https://ngrok.com/docs\n",
        "- **TensorFlow** \u2192 Loads and runs your trained CNN model  \n",
        "  https://www.tensorflow.org/\n",
        "- **Pillow (PIL)** \u2192 Handles image loading and processing  \n",
        "  https://python-pillow.org/\n",
        "\n",
        "###  Folder Creation\n",
        "Creates required directories:\n",
        "- `templates/` \u2192 HTML files\n",
        "- `static/` \u2192 CSS, JS files\n",
        "- `uploads/` \u2192 Uploaded images\n",
        "\n",
        " This cell ensures your system is **ready for model-based web deployment**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3dlTHo23fXF"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok tensorflow pillow\n",
        "!mkdir -p templates static uploads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW6P1jeg_FyR"
      },
      "source": [
        "**Connects drive to colab for easy access to the files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi5MmlovIZf2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E53H4cGIZca"
      },
      "outputs": [],
      "source": [
        "# Verify model file path\n",
        "!ls \"/content/drive/MyDrive/Colab Notebooks/Varma sir projects/cnn_advanced_model.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHKg8IRs_FyS"
      },
      "source": [
        "##  Diabetic Retinopathy Prediction \u2013 Flask Backend (API)\n",
        "\n",
        "This Flask app deploys your **trained CNN diabetic retinopathy model** and provides a web-based prediction system.\n",
        "\n",
        "###  What This App Does\n",
        "- Loads the trained **CNN model (`.h5`)** from Google Drive  \n",
        "- Accepts eye images uploaded by the user  \n",
        "- Preprocesses images to **224\u00d7224 + normalization**  \n",
        "- Predicts:\n",
        "  - **DR** \u2192 Diabetic Retinopathy detected  \n",
        "  - **No_DR** \u2192 Healthy retina  \n",
        "- Returns a **user-friendly message with medical guidance**\n",
        "\n",
        "---\n",
        "\n",
        "###  Key Routes\n",
        "- `/` \u2192 Welcome page  \n",
        "- `/upload` \u2192 Image upload page  \n",
        "- `/predict` \u2192 Model inference (POST request)\n",
        "\n",
        "---\n",
        "\n",
        "###  Prediction Logic\n",
        "- Image \u2192 Resize \u2192 Normalize \u2192 CNN Prediction  \n",
        "- Output > 0.5 \u2192 **No_DR**  \n",
        "- Output \u2264 0.5 \u2192 **DR**\n",
        "\n",
        "---\n",
        "\n",
        "###  Libraries Used\n",
        "- **Flask** \u2013 Web framework \u2192 https://flask.palletsprojects.com/  \n",
        "- **TensorFlow/Keras** \u2013 Model loading & prediction \u2192 https://www.tensorflow.org/  \n",
        "- **Pillow (PIL)** \u2013 Image handling \u2192 https://python-pillow.org/\n",
        "\n",
        "This file acts as the **core backend engine** for your diabetic retinopathy web application.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdDoTVMmIZZ5"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from flask import Flask, request, render_template, jsonify, redirect, url_for\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved CNN diabetic retinopathy model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Varma sir projects/cnn_advanced_model.h5\"\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = image.resize((224, 224))  # Update from (128,128) to correct size\n",
        "    image = np.array(image) / 255.0\n",
        "    return np.expand_dims(image, axis=0)\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def welcome():\n",
        "    return render_template(\"welcome.html\")\n",
        "\n",
        "@app.route(\"/upload\")\n",
        "def upload_page():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if \"image\" not in request.files:\n",
        "        return jsonify({\"error\": \"No image uploaded\"}), 400\n",
        "    file = request.files[\"image\"]\n",
        "    try:\n",
        "        image = Image.open(file).convert(\"RGB\")\n",
        "        input_arr = preprocess_image(image)\n",
        "        pred = model.predict(input_arr)[0][0]\n",
        "        # Adjust label logic consistently with training\n",
        "        label = \"No_DR\" if pred > 0.5 else \"DR\"\n",
        "\n",
        "        # Friendly explanations with emojis\n",
        "        explanations = {\n",
        "            \"No_DR\": \"\ud83d\udc41\ufe0f Your retina looks healthy with no signs of diabetic retinopathy detected. Keep up good eye care habits!\",\n",
        "            \"DR\": \"\u26a0\ufe0f Signs of diabetic retinopathy detected. It's advisable to consult an eye specialist early to prevent vision loss.\"\n",
        "        }\n",
        "        explanation_text = explanations.get(label, \"Prediction unavailable.\")\n",
        "        return jsonify({\"prediction\": explanation_text})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8MCFFZO_FyT"
      },
      "source": [
        "##  Retina Image Upload & Prediction UI (Frontend)\n",
        "\n",
        "This page provides the **user interface** for uploading a retina image and displaying the CNN prediction result.\n",
        "\n",
        "###  What This Page Does\n",
        "- Allows users to **upload a retina eye image**\n",
        "- Shows a **live image preview** before prediction\n",
        "- Sends the image to Flask using **AJAX (Fetch API)**\n",
        "- Displays the **AI prediction result dynamically (without page reload)**\n",
        "\n",
        "---\n",
        "\n",
        "###  Key Components\n",
        "- **HTML Form** \u2192 Uploads retina image\n",
        "- **JavaScript (Fetch API)** \u2192 Sends image to `/predict`\n",
        "- **Live Preview** \u2192 Displays selected image instantly\n",
        "- **Result Box** \u2192 Shows prediction returned by the CNN model\n",
        "\n",
        "---\n",
        "\n",
        "###  Technologies Used\n",
        "- **HTML5** \u2013 Page structure \u2192 https://developer.mozilla.org/en-US/docs/Web/HTML  \n",
        "- **JavaScript Fetch API** \u2013 Image upload & prediction \u2192 https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API  \n",
        "- **Flask Jinja (`url_for`)** \u2013 Static file linking \u2192 https://flask.palletsprojects.com/\n",
        "\n",
        " This file acts as the **frontend bridge between user and deep learning model**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj0uabiJQ5-b"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "  <title>\ud83d\udc41\ufe0f Diabetic Retinopathy Prediction</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\" />\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <header class=\"header\">\n",
        "      <h1>\ud83d\udc41\ufe0f Upload Retina Image for Detection</h1>\n",
        "      <p class=\"subtitle\">Select an eye retina image, then click 'Detect' to see the results.</p>\n",
        "    </header>\n",
        "    <div class=\"card\">\n",
        "      <form id=\"uploadForm\" onsubmit=\"uploadImage(event)\">\n",
        "        <label for=\"image\">\ud83d\udcf8 Choose Retina Image:</label>\n",
        "        <input type=\"file\" id=\"image\" name=\"image\" accept=\"image/*\" required />\n",
        "        <button type=\"submit\" class=\"submit-btn\">\ud83d\udd0d Detect</button>\n",
        "      </form>\n",
        "      <img id=\"uploadedImage\" alt=\"Preview\" style=\"display:none;\"/>\n",
        "      <div id=\"predictionResult\" class=\"result-text\"></div>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "<script>\n",
        "function uploadImage(event) {\n",
        "  event.preventDefault();\n",
        "  const file = document.getElementById(\"image\").files[0];\n",
        "  if (!file) {\n",
        "    alert(\"Please select an image file.\");\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  const reader = new FileReader();\n",
        "  reader.onload = e => {\n",
        "    const preview = document.getElementById(\"uploadedImage\");\n",
        "    preview.src = e.target.result;\n",
        "    preview.style.display = \"block\";\n",
        "  };\n",
        "  reader.readAsDataURL(file);\n",
        "\n",
        "  const formData = new FormData();\n",
        "  formData.append(\"image\", file);\n",
        "  document.getElementById(\"predictionResult\").textContent = \"\ud83d\udd0e Detecting...\";\n",
        "\n",
        "  fetch(\"/predict\", {\n",
        "    method: \"POST\",\n",
        "    body: formData\n",
        "  }).then(res => res.json())\n",
        "    .then(data => {\n",
        "      if(data.error){\n",
        "        document.getElementById(\"predictionResult\").textContent = \"\u274c \" + data.error;\n",
        "      } else {\n",
        "        document.getElementById(\"predictionResult\").innerHTML = \"\ud83e\udde0 <strong>Prediction:</strong> \" + data.prediction;\n",
        "      }\n",
        "    }).catch(() => {\n",
        "      document.getElementById(\"predictionResult\").textContent = \"\u26a0\ufe0f Error during prediction.\";\n",
        "    });\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ChfYMM_FyU"
      },
      "source": [
        "##  Welcome Page \u2013 Diabetic Retinopathy Detection App\n",
        "\n",
        "This page serves as the **landing screen** of the application.\n",
        "\n",
        "###  Purpose\n",
        "- Introduces the **DR Detection System**\n",
        "- Briefly explains the **importance of early eye disease detection**\n",
        "- Provides a **navigation button** to the image upload page (`/upload`)\n",
        "\n",
        "###  Key Features\n",
        "- Simple **call-to-action button**\n",
        "- Clean **user-friendly introduction**\n",
        "- Styled using external **CSS via Flask (`url_for`)**\n",
        "\n",
        "###  Technologies Used\n",
        "- **HTML5** \u2192 Page structure  \n",
        "  https://developer.mozilla.org/en-US/docs/Web/HTML  \n",
        "- **Flask Jinja** \u2192 Static file linking  \n",
        "  https://flask.palletsprojects.com/\n",
        "\n",
        " This page acts as the **entry point for users before prediction**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxbwh15kIZXo"
      },
      "outputs": [],
      "source": [
        "%%writefile templates/welcome.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "  <title>\ud83d\udc4b Welcome to DR Detection</title>\n",
        "  <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\" />\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"welcome-container\">\n",
        "    <h1>\ud83d\udc41\ufe0f Welcome to Diabetic Retinopathy Detection App</h1>\n",
        "    <p class=\"subtitle\">Early detection helps protect your vision. Upload a retina image to get started!</p>\n",
        "    <button onclick=\"location.href='/upload'\" class=\"welcome-btn\">\u27a1\ufe0f Go to Upload Page</button>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wUgWdki_FyV"
      },
      "source": [
        "## \ud83c\udfa8 UI Styling \u2013 Diabetic Retinopathy Web App (CSS)\n",
        "\n",
        "This file designs the **entire visual theme** of your retina detection web application.\n",
        "\n",
        "###  What This CSS Controls\n",
        "- **Dark blue medical gradient theme** for a professional healthcare look  \n",
        "- **Upload card styling** with hover animations  \n",
        "- **Prediction result highlight box**  \n",
        "- **Image preview styling**  \n",
        "- **Welcome page layout & button animations**\n",
        "\n",
        "###  Key Design Features\n",
        "- Gradient backgrounds for **medical UI feel**\n",
        "- Animated transitions using:\n",
        "  - `fadeIn`\n",
        "  - `fadeInDown`\n",
        "- Responsive containers for **mobile & desktop**\n",
        "- Styled buttons for:\n",
        "  - Upload (`Detect`)\n",
        "  - Navigation (`Welcome` button)\n",
        "\n",
        "###  Technology Used\n",
        "- **Pure CSS3 Animations & Layouts**  \n",
        "  https://developer.mozilla.org/en-US/docs/Web/CSS  \n",
        "\n",
        " This CSS file ensures your **AI medical application looks clean, responsive, and professional**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWhNXW00IZVJ"
      },
      "outputs": [],
      "source": [
        "%%writefile static/style.css\n",
        "body {\n",
        "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "  background: linear-gradient(135deg, #001f4d 0%, #003366 100%); /* Navy blue gradient */\n",
        "  color: #e6eaf0;\n",
        "  padding: 20px;\n",
        "  min-height: 100vh;\n",
        "  margin: 0;\n",
        "}\n",
        "\n",
        "/* Container for upload page */\n",
        ".container {\n",
        "  max-width: 700px;\n",
        "  margin: 0 auto;\n",
        "  padding: 20px;\n",
        "}\n",
        "\n",
        ".header {\n",
        "  text-align: center;\n",
        "  margin-bottom: 30px;\n",
        "  animation: fadeInDown 1s ease forwards;\n",
        "}\n",
        "\n",
        ".header h1 {\n",
        "  font-size: 3rem;\n",
        "  margin-bottom: 10px;\n",
        "  letter-spacing: 1px;\n",
        "  text-shadow: 1px 1px 5px rgba(0,0,0,0.7);\n",
        "}\n",
        "\n",
        ".header p {\n",
        "  font-size: 1.3rem;\n",
        "  color: #a0b8d7;\n",
        "}\n",
        "\n",
        ".card {\n",
        "  background: #f0f4ff;\n",
        "  color: #222;\n",
        "  border-radius: 20px;\n",
        "  padding: 40px;\n",
        "  box-shadow: 0 15px 40px rgba(0,0,0,0.3);\n",
        "  animation: fadeIn 1s ease forwards;\n",
        "  margin-bottom: 25px;\n",
        "  transition: transform 0.3s ease;\n",
        "}\n",
        "\n",
        ".card:hover {\n",
        "  transform: translateY(-6px);\n",
        "  box-shadow: 0 20px 50px rgba(0,0,0,0.4);\n",
        "}\n",
        "\n",
        ".result-text {\n",
        "  background: #dde7f9;\n",
        "  padding: 20px;\n",
        "  border-radius: 15px;\n",
        "  border-left: 8px solid #3a5a99;\n",
        "  margin-top: 20px;\n",
        "  font-size: 1.4rem;\n",
        "  color: #1a2d59;\n",
        "  font-weight: 600;\n",
        "  text-align: center;\n",
        "  box-shadow: inset 0 0 10px rgba(0,0,0,0.08);\n",
        "  transition: background 0.3s, box-shadow 0.3s;\n",
        "}\n",
        "\n",
        "input[type='file'] {\n",
        "  width: 100%;\n",
        "  padding: 16px;\n",
        "  border: 3px dashed #3a5a99;\n",
        "  border-radius: 15px;\n",
        "  margin-bottom: 20px;\n",
        "  font-size: 1rem;\n",
        "  cursor: pointer;\n",
        "  background: #f7faff;\n",
        "  transition: border-color 0.3s;\n",
        "}\n",
        "\n",
        "input[type='file']:hover {\n",
        "  border-color: #2c4579;\n",
        "}\n",
        "\n",
        ".submit-btn, .welcome-btn {\n",
        "  width: 100%;\n",
        "  padding: 20px;\n",
        "  background: linear-gradient(135deg, #004080, #336699);\n",
        "  border: none;\n",
        "  color: #f0f4ff;\n",
        "  font-size: 1.2rem;\n",
        "  font-weight: 700;\n",
        "  border-radius: 15px;\n",
        "  cursor: pointer;\n",
        "  box-shadow: 0 8px 15px rgba(0, 64, 128, 0.7);\n",
        "  transition: transform 0.3s, box-shadow 0.3s;\n",
        "  margin-top: 10px;\n",
        "}\n",
        "\n",
        ".submit-btn:hover, .welcome-btn:hover {\n",
        "  transform: translateY(-4px);\n",
        "  box-shadow: 0 12px 25px rgba(0, 64, 128, 1);\n",
        "}\n",
        "\n",
        "#uploadedImage {\n",
        "  display: block;\n",
        "  max-width: 100%;\n",
        "  margin-top: 20px;\n",
        "  border-radius: 15px;\n",
        "  border: 4px solid #3a5a99;\n",
        "  box-shadow: 0 4px 8px rgba(0,0,0,0.2);\n",
        "  animation: fadeIn 1s ease forwards;\n",
        "}\n",
        "\n",
        ".welcome-container {\n",
        "  max-width: 600px;\n",
        "  margin: 5% auto;\n",
        "  background: rgba(10, 30, 70, 0.9);\n",
        "  padding: 50px;\n",
        "  border-radius: 25px;\n",
        "  text-align: center;\n",
        "  box-shadow: 0 20px 50px rgba(0,0,0,0.8);\n",
        "  animation: fadeIn 1s ease forwards;\n",
        "}\n",
        "\n",
        ".welcome-container h1 {\n",
        "  font-size: 4rem;\n",
        "  margin-bottom: 20px;\n",
        "  color: #c1d1f5;\n",
        "  text-shadow: 2px 2px 12px rgba(0,0,0,0.6);\n",
        "}\n",
        "\n",
        ".welcome-container .subtitle {\n",
        "  font-size: 1.6rem;\n",
        "  margin-bottom: 30px;\n",
        "  color: #a8bae0;\n",
        "  line-height: 1.4;\n",
        "}\n",
        "\n",
        "/* Animations */\n",
        "@keyframes fadeIn {\n",
        "  from {opacity: 0; transform: translateY(20px);}\n",
        "  to {opacity:1; transform: translateY(0);}\n",
        "}\n",
        "\n",
        "@keyframes fadeInDown {\n",
        "  from {opacity:0; transform: translateY(-30px);}\n",
        "  to {opacity:1; transform: translateY(0);}\n",
        "}\n",
        "\n",
        "@keyframes bounceIn {\n",
        "  0%, 20%, 40%, 60%, 80%, 100% {\n",
        "    animation-timing-function: cubic-bezier(0.215, 0.610, 0.355, 1.000);\n",
        "  }\n",
        "  0% {opacity: 0; transform: scale3d(.3, .3, .3);}\n",
        "  20% {transform: scale3d(1.1, 1.1, 1.1);}\n",
        "  40% {transform: scale3d(.9, .9, .9);}\n",
        "  60% {opacity: 1; transform: scale3d(1.03, 1.03, 1.03);}\n",
        "  80% {transform: scale3d(.97, .97, .97);}\n",
        "  100% {opacity: 1; transform: scale3d(1, 1, 1);}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNoGjyYm_FyW"
      },
      "source": [
        "##  Stop Running Flask & Ngrok Processes (Port Cleanup)\n",
        "\n",
        "This cell **safely terminates any previously running Flask or Ngrok services** to avoid:\n",
        "-  Port conflicts  \n",
        "-  Duplicate servers  \n",
        "-  Background process errors  \n",
        "\n",
        "### \ud83d\udd39 What Each Command Does\n",
        "- `pkill -f flask` \u2192 Stops any active Flask server  \n",
        "- `pkill -f ngrok` \u2192 Stops any running Ngrok tunnel  \n",
        "- `|| echo \"No ... running\"` \u2192 Prevents errors if nothing is running  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns0pgKBN233j"
      },
      "outputs": [],
      "source": [
        "# Kill any previous processes\n",
        "!pkill -f flask || echo \"No flask running\"\n",
        "!pkill -f ngrok || echo \"No ngrok running\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mQvFmOw_FyX"
      },
      "source": [
        "## \ud83d\udd0d Check Which Process Is Using Port 8000\n",
        "\n",
        "This command identifies the **running process currently using port 8000**.\n",
        "\n",
        "### \ud83d\udd39 What Each Part Means\n",
        "- `lsof` \u2192 Lists open files & network connections  \n",
        "- `-i` \u2192 Filters network processes  \n",
        "- `:8000` \u2192 Checks only **port 8000**  \n",
        "\n",
        "\u2705 Use this to:\n",
        "- Confirm whether your **Flask server is running**\n",
        "- Find the **Process ID (PID)** before stopping it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqESeFXK6U-p"
      },
      "outputs": [],
      "source": [
        "!lsof -i :8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEHPAhea6b-y"
      },
      "outputs": [],
      "source": [
        "!kill -9 7187 7242\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTEdUBRO_FyX"
      },
      "source": [
        "##  Run Flask App in Background (Production Mode)\n",
        "\n",
        "This command starts your **Flask web server in the background** so it keeps running even if the notebook cell finishes.\n",
        "\n",
        "### \ud83d\udd39 What Each Part Does\n",
        "- `nohup` \u2192 Keeps the server running after the session continues  \n",
        "- `python app.py` \u2192 Launches your Flask application  \n",
        "- `> flask.log` \u2192 Saves all server logs to a file  \n",
        "- `2>&1` \u2192 Captures both errors and outputs in the log  \n",
        "- `&` \u2192 Runs the process in the background  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro4Sq6CC23td"
      },
      "outputs": [],
      "source": [
        "# Run Flask in the background\n",
        "!nohup python app.py > flask.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq-x2JfK_FyX"
      },
      "source": [
        " Ngrok Setup\n",
        "\n",
        "Ngrok provides a public HTTPS link.\n",
        "\n",
        "Your ngrok token was removed for safety.\n",
        "\n",
        "To use ngrok:\n",
        "1. Get token \u2192 https://dashboard.ngrok.com/get-started/your-authtoken  \n",
        "2. Add inside notebook:\n",
        "\n",
        "conf.get_default().auth_token = \"YOUR_NGROK_TOKEN_HERE\"\n",
        "\n",
        "3. Start tunnel:\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "\n",
        "Shareable app link appears here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfDHeLqS2ucc"
      },
      "outputs": [],
      "source": [
        "# Start ngrok tunnel\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"place your ngrok token here\"\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\ud83c\udf0d Public URL:\", public_url)\n",
        "\n",
        "# Optional: check logs\n",
        "!sleep 3 && tail -n 20 flask.log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vhw8s0u_FyY"
      },
      "source": [
        "## \ud83d\udcc4 View Latest Flask Server Logs\n",
        "\n",
        "This command displays the **last 50 lines** of your Flask server log file.\n",
        "\n",
        "### \ud83d\udd39 What It Does\n",
        "- `tail` \u2192 Reads the last part of a file  \n",
        "- `-n 50` \u2192 Shows the **most recent 50 log entries**  \n",
        "- `flask.log` \u2192 Log file where Flask outputs are saved  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_buVfi83LO4"
      },
      "outputs": [],
      "source": [
        "!tail -n 50 flask.log"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4046394,
          "sourceId": 8960652,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}