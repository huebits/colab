{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83d\udea6 AI-Based Vehicle Monitoring and Counting System\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 1 \u2014 Project Introduction\n",
        "\n",
        "### \ud83d\ude97 AI-Based Vehicle Monitoring and Counting System\n",
        "\n",
        "This project provides:\n",
        "\n",
        "* \ud83d\ude98 **Real-Time Vehicle Detection using YOLOv5**\n",
        "* \ud83e\udde0 **Deep Learning\u2013based Object Detection**\n",
        "* \ud83d\udcca **Vehicle Counting per Frame**\n",
        "* \ud83c\udff7\ufe0f **Multi-Class Traffic Object Recognition**\n",
        "* \ud83d\uddbc\ufe0f **Annotated Output Visualization**\n",
        "* \u26a1 **High-Speed Inference using PyTorch**\n",
        "* \ud83c\udf10 **Scalable for Smart Traffic & Smart City Applications**\n",
        "\n",
        "---\n",
        "\n",
        "### \u2705 Supported Vehicle Classes\n",
        "\n",
        "The system detects **7 traffic-related object classes**:\n",
        "\n",
        "* Car\n",
        "* Number Plate\n",
        "* Blurred Number Plate\n",
        "* Two Wheeler\n",
        "* Auto\n",
        "* Bus\n",
        "* Truck\n",
        "\n",
        "For **counting**, the following classes are considered:\n",
        "\n",
        "* Car\n",
        "* Two Wheeler\n",
        "* Auto\n",
        "* Bus\n",
        "* Truck\n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udcd8 This Notebook Performs\n",
        "\n",
        "1. YOLOv5 Repository Setup\n",
        "2. Traffic Dataset Configuration\n",
        "3. YOLOv5 Model Training\n",
        "4. Object Detection on Test Images\n",
        "5. Vehicle Counting per Frame\n",
        "6. Batch Image Processing & Counting\n",
        "7. Result Visualization\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 2 \u2014 YOLOv5 Setup & Dependency Installation\n",
        "\n",
        "This step:\n",
        "\n",
        "* Clones the official **YOLOv5 repository**\n",
        "* Installs all required dependencies\n",
        "* Prepares the Kaggle runtime for training\n"
      ],
      "metadata": {
        "id": "3CRqNkmVYclI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 1: YOLOv5 Setup\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing YOLOv5 clone & install code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 3 \u2014 Traffic Dataset Path Configuration\n",
        "\n",
        "This step:\n",
        "\n",
        "* Defines dataset paths for:\n",
        "\n",
        "  * Training images\n",
        "  * Validation images\n",
        "  * Testing images\n",
        "* Uses Kaggle-hosted dataset (no Google Drive dependency)\n",
        "\n",
        "### \ud83d\udccc Dataset Structure\n",
        "\n",
        "```\n",
        "Traffic Dataset/\n",
        " \u2514\u2500\u2500 images/\n",
        "     \u251c\u2500\u2500 train/\n",
        "     \u251c\u2500\u2500 val/\n",
        "     \u2514\u2500\u2500 test/"
      ],
      "metadata": {
        "id": "YDC-H5IBZHPd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK-3REN-WAOK"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# \ud83d\udea6 YOLOv5 Training on Traffic Dataset (Correct Classes);\n",
        "# ==========================\n",
        "\n",
        "# 1. Clone YOLOv5 repo & install dependencies\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 2: Dataset Paths\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing dataset path definitions go here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 4 \u2014 Dataset YAML Configuration (YOLO Format)\n",
        "\n",
        "This step:\n",
        "\n",
        "* Creates a custom `.yaml` file for YOLOv5\n",
        "* Defines:\n",
        "\n",
        "  * Dataset paths\n",
        "  * Number of classes\n",
        "  * Class names\n",
        "* Enables YOLOv5 training with correct labels\n",
        "\n",
        "### \ud83e\udde0 Why YAML is Required?\n",
        "\n",
        "YOLOv5 uses YAML files to understand:\n",
        "\n",
        "* Where images are stored\n",
        "* How many classes exist\n",
        "* Class index \u2192 class name mapping"
      ],
      "metadata": {
        "id": "r-npZME4ZTRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# \ud83d\udcc2 2. Set Dataset Paths\n",
        "# ================================\n",
        "TRAIN_PATH = \"/kaggle/input/traffic-dataset/Traffic Dataset/images/train\"\n",
        "VAL_PATH   = \"/kaggle/input/traffic-dataset/Traffic Dataset/images/val\"\n",
        "TEST_PATH  = \"/kaggle/input/traffic-dataset/Traffic Dataset/images/test\""
      ],
      "metadata": {
        "id": "1gvapbvxWGHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 3: Dataset YAML Creation\n",
        "\n",
        "# ===============================\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 5 \u2014 YOLOv5 Model Training\n",
        "\n",
        "This step:\n",
        "\n",
        "* Trains YOLOv5 Large model (`yolov5l`)\n",
        "* Uses pretrained COCO weights\n",
        "* Fine-tunes the model for traffic objects\n",
        "\n",
        "### \u2699\ufe0f Training Configuration\n",
        "\n",
        "| Parameter  | Value        |\n",
        "| ---------- | ------------ |\n",
        "| Image Size | 640          |\n",
        "| Batch Size | 16           |\n",
        "| Epochs     | 50           |\n",
        "| Backbone   | YOLOv5 Large |\n",
        "| Cache      | Enabled      |\n"
      ],
      "metadata": {
        "id": "jNoG9V7oZdhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create YAML file for dataset\n",
        "import yaml, os\n",
        "\n",
        "yaml_content = {\n",
        "    \"train\": \"/kaggle/input/traffic-dataset/Traffic Dataset/images/train\",\n",
        "    \"val\": \"/kaggle/input/traffic-dataset/Traffic Dataset/images/val\",\n",
        "    \"test\": \"/kaggle/input/traffic-dataset/Traffic Dataset/images/test\",\n",
        "    \"nc\": 7,\n",
        "    \"names\": ['car', 'number_plate', 'blur_number_plate', 'two_wheeler', 'auto', 'bus', 'truck']\n",
        "}\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "with open(\"data/traffic_vehicles.yaml\", \"w\") as f:\n",
        "    yaml.dump(yaml_content, f)\n",
        "\n",
        "print(\"\u2705 Dataset YAML created with 7 classes!\")"
      ],
      "metadata": {
        "id": "YzQRnacvWK8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 4: Model Training\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing YOLOv5 training command goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 6 \u2014 Object Detection on Test Dataset\n",
        "\n",
        "This step:\n",
        "\n",
        "* Runs inference on unseen test images\n",
        "* Saves annotated results\n",
        "* Draws bounding boxes and class labels\n",
        "\n",
        "### \ud83d\udccc Output Location\n",
        "\n",
        "```\n",
        "runs/detect/traffic_veh_test_results/"
      ],
      "metadata": {
        "id": "yiUhJBnKZuXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train YOLOv5 model\n",
        "\n",
        "!python train.py --img 640 --batch 16 --epochs 50 \\\n",
        "--data data/traffic_vehicles.yaml --weights yolov5l.pt \\\n",
        "--name traffic_veh_correct_classes --cache"
      ],
      "metadata": {
        "id": "hlP84PclWQ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 5: Object Detection\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing detect.py code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 7 \u2014 Visualization of Detection Results\n",
        "\n",
        "This step:\n",
        "\n",
        "* Loads YOLOv5 output images\n",
        "* Displays selected annotated samples\n",
        "* Helps visually verify model performance\n",
        "\n",
        "\u2714 Useful for **project reviews and demos**"
      ],
      "metadata": {
        "id": "P86tY6_rZ7tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py \\\n",
        "  --weights runs/train/traffic_veh_correct_classes/weights/best.pt \\\n",
        "  --img 640 \\\n",
        "  --conf 0.25 \\\n",
        "  --source \"/kaggle/input/traffic-dataset/Traffic Dataset/images/test\" \\\n",
        "  --name traffic_veh_test_results"
      ],
      "metadata": {
        "id": "6hUR52AiWd68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 6: Display Detection Results\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing matplotlib visualization code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 8 \u2014 Vehicle Counting Logic (Single Image)\n",
        "\n",
        "This step:\n",
        "\n",
        "* Loads trained YOLOv5 model\n",
        "* Detects vehicles in a single image\n",
        "* Counts vehicles per class\n",
        "* Displays:\n",
        "\n",
        "  * Total vehicle count\n",
        "  * Class-wise count\n",
        "* Draws bounding boxes + labels\n",
        "\n",
        "### \ud83e\uddee Counting Classes Used\n",
        "\n",
        "```text\n",
        "car, two_wheeler, auto, bus, truck"
      ],
      "metadata": {
        "id": "iHRsDKbcaFzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the inference results folder (YOLOv5 saves labeled images here)\n",
        "results_path = \"runs/detect/traffic_veh_test_results\"\n",
        "\n",
        "# List all images in the results folder\n",
        "images = [os.path.join(results_path, f) for f in os.listdir(results_path) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Display first 5 images with labels\n",
        "plt.figure(figsize=(50, 50))\n",
        "for i, img_path in enumerate(images[4:7]):\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "35GFqyZwWop3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 7: Vehicle Counting (Single Image)\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing single-image counting code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 9 \u2014 Annotated Output Generation\n",
        "\n",
        "This step:\n",
        "\n",
        "* Saves final annotated image\n",
        "* Displays output with:\n",
        "\n",
        "  * Bounding boxes\n",
        "  * Class names\n",
        "  * Vehicle counts\n",
        "\n",
        "\ud83d\udcf8 **Output Example:**\n",
        "\n",
        "* Total vehicles in frame\n",
        "* Class-wise vehicle distribution"
      ],
      "metadata": {
        "id": "aCFwNlfeaQX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "0Gc3p9-mWscq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load(\n",
        "    'ultralytics/yolov5',\n",
        "    'custom',\n",
        "    path='runs/train/traffic_veh_correct_classes/weights/best.pt'\n",
        ")\n",
        "model.conf = 0.4"
      ],
      "metadata": {
        "id": "oiW6S0_6Wv38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COUNT_CLASSES = {\n",
        "    0: \"car\",\n",
        "    3: \"two_wheeler\",\n",
        "    4: \"auto\",\n",
        "    5: \"bus\",\n",
        "    6: \"truck\"\n",
        "}"
      ],
      "metadata": {
        "id": "Oa83DlYYWzbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 8: Save & Display Output\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing output save & display code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 10 \u2014 Batch Vehicle Counting (Multiple Frames)\n",
        "\n",
        "This step:\n",
        "\n",
        "* Processes all test images\n",
        "* Performs detection & counting for each frame\n",
        "* Saves annotated frames\n",
        "* Displays selected frames periodically\n",
        "\n",
        "### \u2699\ufe0f Batch Configuration\n",
        "\n",
        "| Parameter        | Value             |\n",
        "| ---------------- | ----------------- |\n",
        "| Display Interval | Every 20 frames   |\n",
        "| Output Folder    | `counted_frames1` |"
      ],
      "metadata": {
        "id": "2txcxdUHakUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = \"/kaggle/input/traffic-dataset/Traffic Dataset/images/test/00 (1).png\""
      ],
      "metadata": {
        "id": "Npsvw6_LW2T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "results = model(frame)\n",
        "detections = results.xyxy[0]\n",
        "\n",
        "current_frame_count = 0\n",
        "class_wise_count = {v: 0 for v in COUNT_CLASSES.values()}\n",
        "\n",
        "for *box, conf, cls in detections:\n",
        "    cls = int(cls)\n",
        "    if cls in COUNT_CLASSES:\n",
        "        label = COUNT_CLASSES[cls]\n",
        "        current_frame_count += 1\n",
        "        class_wise_count[label] += 1\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        cv2.putText(\n",
        "            frame,\n",
        "            label,\n",
        "            (x1, y1-10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.7,\n",
        "            (0,255,0),\n",
        "            2\n",
        "        )\n",
        "\n",
        "# Draw count text\n",
        "y = 30\n",
        "cv2.putText(frame, f\"Vehicles in frame: {current_frame_count}\",\n",
        "            (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
        "y += 35\n",
        "\n",
        "for k, v in class_wise_count.items():\n",
        "    cv2.putText(frame, f\"{k}: {v}\",\n",
        "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)\n",
        "    y += 30"
      ],
      "metadata": {
        "id": "zFMTtM8HW5Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_PATH = \"/kaggle/working/sample_detection.jpg\"\n",
        "cv2.imwrite(OUTPUT_PATH, frame)\n",
        "\n",
        "print(\"Saved at:\", OUTPUT_PATH)"
      ],
      "metadata": {
        "id": "RvCLJrpwW8Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename=OUTPUT_PATH))"
      ],
      "metadata": {
        "id": "glSrJdTcW_GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "ssPuDClVXDXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load(\n",
        "    'ultralytics/yolov5',\n",
        "    'custom',\n",
        "    path='runs/train/traffic_veh_correct_classes/weights/best.pt'\n",
        ")\n",
        "model.conf = 0.4"
      ],
      "metadata": {
        "id": "jkcW7nxxXGcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COUNT_CLASSES = {\n",
        "    0: \"car\",\n",
        "    3: \"two_wheeler\",\n",
        "    4: \"auto\",\n",
        "    5: \"bus\",\n",
        "    6: \"truck\"\n",
        "}"
      ],
      "metadata": {
        "id": "bIUoDBAYXJDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = \"/kaggle/input/traffic-dataset/Traffic Dataset/images/test\"\n",
        "\n",
        "image_files = sorted([\n",
        "    os.path.join(IMAGE_DIR, f)\n",
        "    for f in os.listdir(IMAGE_DIR)\n",
        "    if f.endswith(('.png', '.jpg', '.jpeg'))\n",
        "])\n",
        "\n",
        "print(\"Total images:\", len(image_files))"
      ],
      "metadata": {
        "id": "aZmiN5RAXMbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"/kaggle/working/counted_frames1\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "DZgX8iSnXPrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================\n",
        "\n",
        "# \u2705 CELL 9: Batch Processing\n",
        "\n",
        "# ===============================\n",
        "\n",
        "*(Your existing batch processing code goes here unchanged)*\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcd8 11 \u2014 Output Directory Structure\n",
        "\n",
        "After execution, results are stored as:\n",
        "\n",
        "```\n",
        "counted_frames1/\n",
        " \u251c\u2500\u2500 frame_0000.jpg\n",
        " \u251c\u2500\u2500 frame_0001.jpg\n",
        " \u251c\u2500\u2500 frame_0002.jpg\n",
        " \u2514\u2500\u2500 ...\n",
        "```\n",
        "\n",
        "Each frame contains:\n",
        "\u2714 Vehicle bounding boxes\n",
        "\u2714 Class labels\n",
        "\u2714 Total count\n",
        "\u2714 Class-wise count"
      ],
      "metadata": {
        "id": "1I2e1AEGa0ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "DISPLAY_EVERY = 20   # show 1 image every 20 frames\n",
        "\n",
        "for i, img_path in enumerate(image_files):\n",
        "    frame = cv2.imread(img_path)\n",
        "\n",
        "    results = model(frame)\n",
        "    detections = results.xyxy[0]\n",
        "\n",
        "    current_frame_count = 0\n",
        "    class_wise_count = {v: 0 for v in COUNT_CLASSES.values()}\n",
        "\n",
        "    for *box, conf, cls in detections:\n",
        "        cls = int(cls)\n",
        "        if cls in COUNT_CLASSES:\n",
        "            label = COUNT_CLASSES[cls]\n",
        "            current_frame_count += 1\n",
        "            class_wise_count[label] += 1\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "            cv2.putText(frame, label,\n",
        "                        (x1, y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.7, (0,255,0), 2)\n",
        "\n",
        "    # Draw count text\n",
        "    y = 30\n",
        "    cv2.putText(frame, f\"Vehicles in frame: {current_frame_count}\",\n",
        "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
        "    y += 35\n",
        "    for k, v in class_wise_count.items():\n",
        "        cv2.putText(frame, f\"{k}: {v}\",\n",
        "                    (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)\n",
        "        y += 30\n",
        "\n",
        "    # Save output\n",
        "    out_path = os.path.join(OUTPUT_DIR, f\"frame_{i:04d}.jpg\")\n",
        "    cv2.imwrite(out_path, frame)\n",
        "\n",
        "    # \ud83d\udd25 DISPLAY ONLY SELECTED FRAMES\n",
        "    if i % DISPLAY_EVERY == 0:\n",
        "        print(f\"Displaying frame {i}\")\n",
        "        display(Image(filename=out_path))"
      ],
      "metadata": {
        "id": "FOoksX8AXTC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\udcd8 12 \u2014 Final Project Summary\n",
        "\n",
        "\u2714 YOLOv5-based Vehicle Detection\n",
        "\n",
        "\u2714 Multi-Class Traffic Monitoring\n",
        "\n",
        "\u2714 Accurate Vehicle Counting\n",
        "\n",
        "\u2714 Scalable for Real-Time Systems\n",
        "\n",
        "\u2714 Suitable for Smart City Applications\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8ZxYjgB9YrZI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_MmOm0CYss4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}